<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>crossoverJie&#39;s Blog</title>
  
  <subtitle>baller</subtitle>
  <link href="http://crossoverjie.top/atom.xml" rel="self"/>
  
  <link href="http://crossoverjie.top/"/>
  <updated>2025-03-18T06:35:10.890Z</updated>
  <id>http://crossoverjie.top/</id>
  
  <author>
    <name>crossoverJie</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>StarRocks 升级注意事项</title>
    <link href="http://crossoverjie.top/2025/03/14/starrocks/StarRocks-upgrade/"/>
    <id>http://crossoverjie.top/2025/03/14/starrocks/StarRocks-upgrade/</id>
    <published>2025-03-14T09:16:35.000Z</published>
    <updated>2025-03-18T06:35:10.890Z</updated>
    
    <content type="html"><![CDATA[<p>前段时间升级了生产环境的 <code>StarRocks</code>，从 3.3.3 升级到了 3.3.9，期间还是踩了不少坑所以在这里记录下。</p><p><img src="https://s2.loli.net/2025/03/17/uGyo2HULqzQ1j7W.png"></p><p> 因为我们的集群使用的是存算分离的版本，也是使用官方提供的 operator 部署在 kubernetes 里的，所以没法按照官方的流程进入虚拟机手动启停对应的服务。</p><p>只能使用 operator 提供的方案手动修改对应组件的镜像版本，后续的升级操作交给 operator 去完成。</p><span id="more"></span><p><img src="https://s2.loli.net/2025/03/17/7YwRaKzbPo4dAEs.png"></p><p>理论上这个升级流程没什么问题，修改镜像版本之后只需要安静等待他滚动更新即可。</p><h1 id="元数据备份与恢复"><a href="#元数据备份与恢复" class="headerlink" title="元数据备份与恢复"></a>元数据备份与恢复</h1><p>但考虑到之前在社区看到有存算分离集群升级失败导致数据丢失的案例，我们的全量业务已经切换到 StarRocks，如果数据丢失那需要花几天时间进行数据同步，这在业务上是无法接受的，所以我们最好是可以在升级前备份数据，即便是升级失败数据依然还在。</p><p><img src="https://s2.loli.net/2025/03/17/g1q7NbX6H9t5oce.png"></p><p>原本官方社区是有提供数据备份与恢复能力的，但是我们使用的存算分离集群不支持😂，而想要获得社区版的支持应该还要等一段时间，即便是支持了我们升级到那个版本依然是需要备份的。</p><p><img src="https://s2.loli.net/2025/03/17/l6Dfcs4JYV52pQE.png"></p><blockquote><p>好消息，在最新的 3.4.1 版本中已经支持了快照备份了，只是作为一个新 feature，稳定性还有待观察。</p></blockquote><p>所以我们的计划是在当前这个版本（3.3.3）能否自己备份数据，由于我们是存算分离的版本，所以数据主要分为两部分：</p><ul><li>存储在所有 FE 节点里的 meta 元数据</li><li>存储在云存储里的业务数据</li></ul><p>备份的时候自然就需要备份这两部分的数据。</p><h2 id="备份元数据"><a href="#备份元数据" class="headerlink" title="备份元数据"></a>备份元数据</h2><p>在元数据里存放了所有的数据库、表、视图等信息，具体在磁盘的结构如下：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">|-- bdb</span><br><span class="line">|   |-- 00000000.jdb</span><br><span class="line">|   |-- je.config.csv</span><br><span class="line">|   |-- je.info.0</span><br><span class="line">|   |-- je.info.0.lck</span><br><span class="line">|   |-- je.lck</span><br><span class="line">|   `-- je.stat.csv</span><br><span class="line">|-- image</span><br><span class="line">|   |-- ROLE</span><br><span class="line">|   |-- VERSION</span><br><span class="line">|   |-- image.327375</span><br><span class="line">|   |-- starmgr</span><br><span class="line">|   |   `-- image.390</span><br><span class="line">|   `-- v2</span><br><span class="line">|       |-- checksum.327375</span><br><span class="line">|       `-- image.327375</span><br></pre></td></tr></table></figure><p>bdb 目录主要是用于 leader 选举的，理论上并不需要备份，真正需要的是 <code>image</code> 目录下的 <code>image.327375</code> 等元数据文件。</p><p><img src="https://s2.loli.net/2025/03/17/KpVCBqJGjXQctah.png"></p><p><img src="https://s2.loli.net/2025/03/17/CMAiILF3ZHaouY6.png"></p><p>里面是用 JSON 存储的各种类型的元数据，FE 在启动的时候会读取该文件，然后根据不同的类型取不同的偏移量读取其中的元数据加载到内存里。</p><p>我们的 FE 一共有三个节点，需要找到其中的 leader 节点（理论上只需要备份 leader 节点即可，其他节点会在 leader 启动后同步过去），直接将这个 meta 目录备份到本地即可：</p><p>在开始之前需要停掉所有的写入任务，暂停所有的物化视图刷新。</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"># inactive 所有的物化视图</span><br><span class="line"><span class="keyword">SELECT</span> CONCAT(<span class="string">&#x27;ALTER MATERIALIZED VIEW &#x27;</span>, TABLE_NAME, <span class="string">&#x27; INACTIVE;&#x27;</span>) <span class="keyword">FROM</span> information_schema.materialized_views;</span><br><span class="line"></span><br><span class="line"># 手动创建镜像</span><br><span class="line"><span class="keyword">ALTER</span> <span class="keyword">SYSTEM</span> <span class="keyword">CREATE</span> IMAGE;</span><br><span class="line"></span><br><span class="line"># 找到 leader 节点</span><br><span class="line"><span class="keyword">SHOW</span> FRONTENDS;</span><br></pre></td></tr></table></figure><p>然后进入 leader 节点备份元数据：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">k exec -it kube-starrocks-fe-0-n sr -- bash</span><br><span class="line"></span><br><span class="line">tar -zcvf meta.tar.gz meta/</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">下载备份元数据到本地</span></span><br><span class="line">k cp starrocks-fe-0:/opt/starrocks/fe/meta/image.tar.gz image.tar.gz -n starrocks -c fe --retries=5</span><br></pre></td></tr></table></figure><h2 id="备份云存储数据"><a href="#备份云存储数据" class="headerlink" title="备份云存储数据"></a>备份云存储数据</h2><p>云存储的备份就需要结合你使用的云厂商来备份了，通常他们都有提供对应的备份能力。</p><p>要注意的是我们再备份的时候需要记录在存储桶里的目录名称，之后还原的时候名称得保持一致才行。</p><h2 id="恢复元数据"><a href="#恢复元数据" class="headerlink" title="恢复元数据"></a>恢复元数据</h2><p>当出现极端情况升级失败的时候，我们需要把元数据覆盖回去；但由于我们的应用运行在容器里，不可以在应用启动之后再替换元数据。</p><p>只能在应用启动之前将之前备份的元数据覆盖回去，这里可以使用 kubernetes 中的 <code>initContainers</code> 提前将数据复制到应用容器里。</p><p>在开始之前我们需要先把备份的元数据打包为一个镜像。</p><figure class="highlight dockerfile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">FROM</span> busybox  </span><br><span class="line"><span class="keyword">ADD</span><span class="language-bash"> meta.tar.gz /temp</span></span><br></pre></td></tr></table></figure><p>然后我们需要手动修改 FE 的 <code>statefulset</code> 的资源，创建一个 initContainers。</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">initContainers:</span>  </span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">copy-file-init</span>  </span><br><span class="line">    <span class="attr">image:</span> <span class="string">meta:0.0.1</span>  </span><br><span class="line">    <span class="attr">command:</span> [<span class="string">&quot;/bin/sh&quot;</span>, <span class="string">&quot;-c&quot;</span>]  </span><br><span class="line">    <span class="attr">args:</span> [<span class="string">&quot;rm -rf /meta-target/* &amp;&amp; cp -r /temp/meta/. /meta-target&quot;</span>]  </span><br><span class="line">    <span class="attr">volumeMounts:</span>  </span><br><span class="line">      <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">fe-meta</span>  </span><br><span class="line">        <span class="attr">mountPath:</span> <span class="string">&quot;/meta-target&quot;</span></span><br></pre></td></tr></table></figure><p>原理就是在 initContainers 中挂载原本 FE 的元数据目录，这样就可以直接将之前备份的元数据覆盖过去。</p><blockquote><p>当然也可以直接使用 k8s 的 go client 用代码的方式来修改，会更容易维护。</p></blockquote><p>还原的时候需要先将云存储里的数据先还原之后再还原元数据。</p><h1 id="物化视图刷新策略"><a href="#物化视图刷新策略" class="headerlink" title="物化视图刷新策略"></a>物化视图刷新策略</h1><p>真正升级的时候倒是没有碰到升级失败的情况，所以没有走恢复流程；但是却碰到了一个更麻烦的事情。</p><h2 id="物化视图作为基表"><a href="#物化视图作为基表" class="headerlink" title="物化视图作为基表"></a>物化视图作为基表</h2><p>我们在升级前将所有的物化视图设置为了 <code>INACTIVE</code>，升级成功后需要将他们都改为 <code>ACTIVE</code>。</p><p>第一个问题是如果某个物化视图 <code>MV1</code> 的基表也是一个物化视图 <code>MV-base</code>，这样会导致 <code>MV1</code> 的全量刷新。</p><p>我之前在这个 <a href="https://github.com/StarRocks/starrocks/pull/50926">PR</a> 里新增了一个参数：<code>excluded_refresh_tables</code> 可以用于排除基表发生变化的时候刷新物化视图，但是忘记了基表也是物化视图的场景。</p><p><img src="https://s2.loli.net/2025/03/18/nf3QioRgc96ze2p.png"></p><p>所以在这个 <a href="https://github.com/StarRocks/starrocks/pull/56428">PR</a> 中修复了该问题，现在基表是物化视图的时候也可以使用了。</p><h2 id="物化视图手动-ACTIVE"><a href="#物化视图手动-ACTIVE" class="headerlink" title="物化视图手动 ACTIVE"></a>物化视图手动 ACTIVE</h2><p>前面提到在升级之前需要将所有的物化视图设置为 <code>INACTIVE</code>，升级成功后再手动设置为 ACTIVE。</p><p>我们在手动 ACTIVE 之后发现这些物化视图又在做全量刷新了，于是我们检查了代码。</p><p><img src="https://s2.loli.net/2025/03/18/DMNQsxH5ZqaKpFb.png"></p><p>发现在使用 <code>ALTER MATERIALIZED VIEW order_mv ACTIVE;</code> 修改视图状态的时候会强制刷新物化视图的所有分区。</p><p><img src="https://s2.loli.net/2025/03/18/GP6Bzl7Zxq29FoD.png"></p><blockquote><p>force: true 的时候会直接跳过基表的分区检查，导致分区的全量刷新。</p></blockquote><p><img src="https://s2.loli.net/2025/03/18/PG8WVKrpfoTz61I.png"></p><p>同时会在 ACTIVE 的时候将视图基表的 <code>baseTableVisibleVersionMap</code> 版本号缓存清空，FE 需要在刷新的时候判断当前需要刷新的分区是否存在与缓存中，如果存在的话说明不需要刷新，现在被清空后就一定会被刷新。</p><p>所以我提了一个 PR 可以在 <code>ACTIVE</code> 物化视图的时候人工判断是否需要刷新:</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">alter</span> materialized <span class="keyword">view</span> mv_test1 ACTIVE <span class="keyword">WITH</span> NO_VALIDATION</span><br></pre></td></tr></table></figure><p>这样带上 <code>NO_VALIDATION</code> 参数后就 <code>force=false</code> 也就不会全量刷新了。</p><p>如果在 ACTIVE 物化视图的时候碰到类似场景，可以在这个 <code>PR</code> 发布之后加上 <code>NO_VALIDATION</code> 来跳过刷新。</p><p>参考链接：</p><ul><li><a href="https://github.com/StarRocks/starrocks/pull/50926">https://github.com/StarRocks/starrocks/pull/50926</a></li><li><a href="https://github.com/StarRocks/starrocks/pull/56428">https://github.com/StarRocks/starrocks/pull/56428</a></li><li><a href="https://github.com/StarRocks/starrocks/pull/56864">https://github.com/StarRocks/starrocks/pull/56864</a></li></ul>]]></content>
    
    
    <summary type="html">&lt;p&gt;前段时间升级了生产环境的 &lt;code&gt;StarRocks&lt;/code&gt;，从 3.3.3 升级到了 3.3.9，期间还是踩了不少坑所以在这里记录下。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://s2.loli.net/2025/03/17/uGyo2HULqzQ1j7W.png&quot;&gt;&lt;/p&gt;
&lt;p&gt; 因为我们的集群使用的是存算分离的版本，也是使用官方提供的 operator 部署在 kubernetes 里的，所以没法按照官方的流程进入虚拟机手动启停对应的服务。&lt;/p&gt;
&lt;p&gt;只能使用 operator 提供的方案手动修改对应组件的镜像版本，后续的升级操作交给 operator 去完成。&lt;/p&gt;</summary>
    
    
    
    <category term="OB" scheme="http://crossoverjie.top/categories/OB/"/>
    
    
    <category term="StarRocks" scheme="http://crossoverjie.top/tags/StarRocks/"/>
    
  </entry>
  
  <entry>
    <title>我的 2024</title>
    <link href="http://crossoverjie.top/2025/03/03/annual-summary/2024/"/>
    <id>http://crossoverjie.top/2025/03/03/annual-summary/2024/</id>
    <published>2025-03-03T09:47:52.000Z</published>
    <updated>2025-03-10T06:07:24.193Z</updated>
    
    <content type="html"><![CDATA[<p>这些年我一直都是按照农历新年来写年终总结的，都说不出正月都是年，前些年一直都比较规律，今年确实是时间超了一些。</p><p>主要原因还是年末接了个活，需要在年初上线，导致这段时间都没太多时间写内容。</p><p>最近事情终于告一段落后才开始码字。</p><span id="more"></span><blockquote><p>本来打算用 AI 来写的，想想还是算了，现在 AI 大热的时代，越是手工打造的内容越是珍贵🐶</p></blockquote><h1 id="健身"><a href="#健身" class="headerlink" title="健身"></a>健身</h1><p><img src="https://s2.loli.net/2025/03/04/t6FN7hjiUdXYJTZ.jpg"></p><p><img src="https://s2.loli.net/2025/03/04/vdDmtrcTGAxXsyC.jpg"></p><p>回想起来 2024 年投入最多的还是健身，手上的老茧都换了几轮了；</p><p>以前还不信真有人一天没事就往健身房跑吗？现在回想起来在健身房的那 1～2 小时是一天最放松的时间，带个耳机听着播客，感受肌肉的发力（听着是有点油腻）完全进入心流的状态。</p><p>不过因为我大部分的时间都是自己练，所以对自己也不够狠，全是自己能接受的强度，加上也没啥天赋（从小体育就是我的弱项）所以肌肉线条也不是很明显。</p><p><img src="https://s2.loli.net/2025/03/04/dfIL87FvXVqy5Pk.png" alt="image.png"></p><p><img src="https://s2.loli.net/2025/03/04/8dxzbyH1PA7X2R4.jpg"></p><p>以上都是凹了半天造型才拍出来的，和健身大佬完全没法比；去年 11 月份从乐刻换到了一个有自由卧推和深蹲的健身房，动作基本上都是从零开始，现在卧推 70kg、深蹲 80kg 已经比较满意了。</p><p>我的要求不高，保证在不受伤的前提下卧推能到 80kg 做组就满意了。</p><blockquote><p>就像我朋友说的，看你也练了一年多了咋还这么菜？我的回复是：这一年多如果不练，那岂不是更菜，现在还在打基础的阶段🙂</p></blockquote><h1 id="工作"><a href="#工作" class="headerlink" title="工作"></a>工作</h1><p>今年的工作依然是按部就班的进行，在公司依然是负责基础架构，主要还是维护内部的消息队列 Pulsar、可观测性工具 OpenTelemetry、服务网格、StarRocks 等。</p><p>当然 24 年还是完成了一个小目标：成为了两个 Apache 项目的 Committer。</p><p><img src="https://s2.loli.net/2025/03/04/PCmnARseYq9DiaV.png"></p><p>为此我还写了一篇文章：<a href="https://mp.weixin.qq.com/s/YV31IjbFNd__U0cf70V4pQ">我是如何从零到成为 Apache 顶级项目的 Committer</a>，感兴趣的朋友可以看看详细过程。</p><h2 id="副业"><a href="#副业" class="headerlink" title="副业"></a>副业</h2><p>23 年的时候第一次接到了咨询相关的付费业务，也就是从那时候开始尝试做一些副业，目前咨询服务了几个客户，反馈都还不错：<br><img src="https://s2.loli.net/2025/03/05/FENVYphcQHuC7xa.png"><br><img src="https://s2.loli.net/2025/03/05/wRTvW5AVimYfjLb.png"><br><img src="https://s2.loli.net/2025/03/05/lxzBEsVGOkorNXq.png"></p><p>今年准备加大力度再宣传一下：<br><img src="https://s2.loli.net/2025/03/05/2iKaFwIoRr1tjHV.png"></p><p>同时 24 年在咨询的基础上开了知识星球，也没有认真宣传，目前有大约 90 个用户，非常感谢他们的支持：<br><img src="https://s2.loli.net/2025/03/05/E8xkw2HUWrQOL5D.jpg"></p><p>有需要的朋友也可以扫码关注下，等这段时间忙过之后会重点运营。</p><h2 id="掘金签约作者"><a href="#掘金签约作者" class="headerlink" title="掘金签约作者"></a>掘金签约作者</h2><p><img src="https://s2.loli.net/2025/03/05/SVoyfepc6umUl2X.jpg"></p><p>去年也和掘金签约了半年时间：也就是这半年期间写的文章需要首发在掘金平台，同时还能拿到相应的佣金；对创作者和平台来说确实是双赢的结果。</p><p>平台收获了优质的文章，作者也能获得一定的激励；希望国内越来越多的平台可以效仿，而不是往自家平台里倒垃圾（DDDD）。</p><h1 id="技能"><a href="#技能" class="headerlink" title="技能"></a>技能</h1><h2 id="博客"><a href="#博客" class="headerlink" title="博客"></a>博客</h2><p><img src="https://s2.loli.net/2025/03/05/uU8JDoKjSVdGbp5.png"></p><p>去年 24 年因为签约了掘金，所以写的还是比较积极，一共写了 53 篇博客，平均每个月写 4 篇+。</p><p>今年写的内容主要包含了：<br><img src="https://s2.loli.net/2025/03/06/5qp4uHWetQSlxvZ.png"></p><p>这里我问了下 AI，其实几乎都是我工作中接触到的技术问题，比如 Pulsar、OpenTelemetry、StarRocks 等。</p><h2 id="开源"><a href="#开源" class="headerlink" title="开源"></a>开源</h2><p><img src="https://s2.loli.net/2025/03/05/JWmG2ybEvrZswOx.jpg"></p><p><img src="https://s2.loli.net/2025/03/05/aF4lM51XgmZ9INd.png"></p><p>24年投入开源的时间还是蛮多的，毕竟我的工作中的有部分时间也是和开源相关的。</p><h3 id="Apache-Pulsar"><a href="#Apache-Pulsar" class="headerlink" title="Apache Pulsar"></a>Apache Pulsar</h3><p>Pulsar 的贡献主要是分为主仓库和 pulsar-client-go 两个。</p><p><img src="https://s2.loli.net/2025/03/05/N68UXVC2eqQksFM.png"><br>主仓库这边我的改动不是很多，比较大的就是重构了 cli，其他的都是些边角料。</p><p><img src="https://s2.loli.net/2025/03/05/LKXCBa8m1OVxboA.png"></p><p>其余在 pulsar-client-go 中主要是同步了一些 java-client 的 feature 过来，以及修复一些 bug。</p><hr><h3 id="Apache-HertzBeat"><a href="#Apache-HertzBeat" class="headerlink" title="Apache HertzBeat"></a>Apache HertzBeat</h3><p><img src="https://s2.loli.net/2025/03/05/ACvfe5dnRPhN1lp.png"></p><p>除此之外在空余时间我还参与了 Apache HertzBeat 项目（一个开源的实时监控项目），当时项目刚进入 Apache 孵化器不久，我主要是帮助完善了一些单元测试、优化了 CI 流程、代码 checkstyle 等工作。<br>后来由于时间限制参与的不多了，但也在一直有在关注着。</p><h3 id="OpenTelemetry"><a href="#OpenTelemetry" class="headerlink" title="OpenTelemetry"></a>OpenTelemetry</h3><p><img src="https://s2.loli.net/2025/03/06/pg3Be5s7A91GKLh.png"></p><p>去年年中的时候由于公司可观测的技术栈全面迁移到 OpenTelemetry，所以也花了一些时间学习并使用它，并结合我们的场景给社区提了一些 PR.</p><ul><li>Instrumentation<ul><li>Pulsar 相关的 metrics 埋点： <a href="https://github.com/open-telemetry/opentelemetry-java-instrumentation/pull/11591">https://github.com/open-telemetry/opentelemetry-java-instrumentation/pull/11591</a></li><li>支持 PowerJob: <a href="https://github.com/open-telemetry/opentelemetry-java-instrumentation/pull/12086">https://github.com/open-telemetry/opentelemetry-java-instrumentation/pull/12086</a></li></ul></li><li>Operator<ul><li>Operator 支持部署 java extensions: <a href="https://github.com/open-telemetry/opentelemetry-operator/pull/2761">https://github.com/open-telemetry/opentelemetry-operator/pull/2761</a></li></ul></li><li>Convention:<ul><li>完善了 RPC 的一些语义: <a href="https://github.com/open-telemetry/semantic-conventions/pull/1281">https://github.com/open-telemetry/semantic-conventions/pull/1281</a></li><li>补全了 Pulsar 的一些语义： <a href="https://github.com/open-telemetry/semantic-conventions/pull/1099">https://github.com/open-telemetry/semantic-conventions/pull/1099</a></li></ul></li></ul><p>本来准备下半年再接再厉多贡献一些，争取成为 Member，结果因为把重心切到 Starrocks 之后这边暂时就没在跟进了，今年也许会重启更新。</p><h3 id="StarRocks"><a href="#StarRocks" class="headerlink" title="StarRocks"></a>StarRocks</h3><p>这也是去年第一次接触到的技术栈，和大部分业务开发一样，以前顶多接触过关系型数据库，对这类大数据产品接触很少。</p><p>第一次参与是领导让我看看能否给它的物化视图加一个参数，好在我要修改的部分（FrontEnd)都是 Java 写的（BackEnd 是 cpp 写的），至少代码看起来无压力。</p><p><img src="https://s2.loli.net/2025/03/06/T61ny2uMZNk9Rxt.png"></p><p>所以就花了一些时间来从头研究，到目前为止也给社区提交了一些 feature 和修复了 bug，主要都是和物化视图相关的内容。</p><blockquote><p>这里也额外提一下：即便是对毫不熟悉的项目，哪怕看起来是数据库这种比较复杂的技术栈，只要能看懂代码、复现问题，那就都可以解决，首先心理上就不要害怕。</p></blockquote><h1 id="目标"><a href="#目标" class="headerlink" title="目标"></a>目标</h1><p><img src="https://s2.loli.net/2025/03/06/mVY5wcBpy7zJtux.png"></p><p>最后再看看去年的目标，完成率不说 100% 吧，80% 还是有的，今年目标看来要再定高一些了：</p><ul><li>卧推 PR 85kg</li><li>体脂达到一次 13%</li><li>国内游一次</li><li>再完成一个开源社区的 Member</li></ul><p>好了，流水账记完了，今年也要抓紧开始搬砖了，咱们明年再见。</p><h2 id="往年记录"><a href="#往年记录" class="headerlink" title="往年记录"></a>往年记录</h2><ul><li><p><a href="https://crossoverjie.top/2023/01/18/annual-summary/2023/">2023</a></p></li><li><p><a href="https://crossoverjie.top/2023/01/18/annual-summary/2022/">2022</a></p></li><li><p><a href="https://crossoverjie.top/2022/01/27/annual-summary/2021/">2021</a></p></li><li><p><a href="https://crossoverjie.top/2021/03/02/annual-summary/2020/">2020</a></p></li><li><p><a href="https://crossoverjie.top/2019/12/30/annual-summary/2019/">2019</a></p></li><li><p><a href="https://crossoverjie.top/2018/12/30/annual-summary/2018/">2018</a></p></li><li><p><a href="https://crossoverjie.top/2018/12/30/annual-summary/2018/">2016</a></p></li></ul>]]></content>
    
    
    <summary type="html">&lt;p&gt;这些年我一直都是按照农历新年来写年终总结的，都说不出正月都是年，前些年一直都比较规律，今年确实是时间超了一些。&lt;/p&gt;
&lt;p&gt;主要原因还是年末接了个活，需要在年初上线，导致这段时间都没太多时间写内容。&lt;/p&gt;
&lt;p&gt;最近事情终于告一段落后才开始码字。&lt;/p&gt;</summary>
    
    
    
    <category term="OB" scheme="http://crossoverjie.top/categories/OB/"/>
    
    
  </entry>
  
  <entry>
    <title>StarRocks 开发环境搭建踩坑指北之存算分离篇</title>
    <link href="http://crossoverjie.top/2025/02/26/ob/StarRocks-dev-shard-data-build/"/>
    <id>http://crossoverjie.top/2025/02/26/ob/StarRocks-dev-shard-data-build/</id>
    <published>2025-02-26T02:30:08.849Z</published>
    <updated>2025-02-26T02:30:08.849Z</updated>
    
    <content type="html"><![CDATA[<p>前段时间碰到一个 StarRocks 物化视图的 <a href="https://github.com/StarRocks/starrocks/issues/55301">bug</a>: <a href="https://github.com/StarRocks/starrocks/issues/55301">https://github.com/StarRocks/starrocks/issues/55301</a></p><p>但是这个问题只能在存算分离的场景下才能复现，为了找到问题原因我便尝试在本地搭建一个可以 Debug 的存算分离版本。</p><p>之前也分享过在<a href="https://crossoverjie.top/2024/10/09/ob/StarRocks-dev-env-build/">本地 Debug StarRocks</a>，不过那是存算一体的版本，而存算分离稍微要复杂一些。</p><blockquote><p>这里提到的本地 Debug 主要是指可以调试 FE，而 CN&#x2F;BE 则是运行在容器环境，避免本地打包和构建运行环境。</p></blockquote><hr><span id="more"></span><p>当前 StarRocks 以下的存算分离部署方式，在本地推荐直接使用 <code>MinIO</code> 部署。</p><p><img src="https://s2.loli.net/2025/02/14/pTWsfE6XUxuCeiL.png"></p><h2 id="启动-MinIO"><a href="#启动-MinIO" class="headerlink" title="启动 MinIO"></a>启动 MinIO</h2><p>首先第一步启动 MinIO:</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">docker run -d --rm --name minio \</span><br><span class="line">  -e MINIO_ROOT_USER=miniouser \</span><br><span class="line">  -e MINIO_ROOT_PASSWORD=miniopassword \</span><br><span class="line">  -p 9001:9001 \</span><br><span class="line">  -p 9000:9000 \</span><br><span class="line">  --entrypoint sh \</span><br><span class="line">  minio/minio:latest \</span><br><span class="line">  -c &#x27;mkdir -p /minio_data/starrocks &amp;&amp; minio server /minio_data --console-address &quot;:9001&quot;&#x27;</span><br></pre></td></tr></table></figure><p>进入 MinIO 容器设置 access token:</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">docker exec -it minio sh</span><br><span class="line">mc alias set myminio http://10.0.9.20:9000 miniouser miniopassword; mc admin user svcacct add --access-key AAAAAAAAAAAAAAAAAAAA --secret-key BBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBB myminio miniouser</span><br></pre></td></tr></table></figure><h2 id="启动-cn"><a href="#启动-cn" class="headerlink" title="启动 cn:"></a>启动 cn:</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker run -p 9060:9060 -p 8040:8040 -p 9050:9050 -p 8060:8060 -p 9070:9070 -itd --rm --name cn -e &quot;TZ=Asia/Shanghai&quot; starrocks/cn-ubuntu:3.4-latest</span><br></pre></td></tr></table></figure><p>修改 <code>cn.conf</code> :</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cd cn/config/</span><br><span class="line">echo &quot;priority_networks = 10.0.9.20/24&quot; &gt;&gt; cn.properties</span><br></pre></td></tr></table></figure><p> 使用脚本手动启动 cn:</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/start_cn.sh --daemon</span><br></pre></td></tr></table></figure><p>使用以下配置在本地 IDEA 中启动 FE:</p><figure class="highlight properties"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">LOG_DIR</span> = <span class="string">$&#123;STARROCKS_HOME&#125;/log  </span></span><br><span class="line">  </span><br><span class="line"><span class="attr">DATE</span> = <span class="string">&quot;$(date +%Y%m%d-%H%M%S)&quot;  </span></span><br><span class="line">  </span><br><span class="line"><span class="attr">sys_log_level</span> = <span class="string">INFO  </span></span><br><span class="line">  </span><br><span class="line"><span class="attr">http_port</span> = <span class="string">8030  </span></span><br><span class="line"><span class="attr">rpc_port</span> = <span class="string">9020  </span></span><br><span class="line"><span class="attr">query_port</span> = <span class="string">9030  </span></span><br><span class="line"><span class="attr">edit_log_port</span> = <span class="string">9010  </span></span><br><span class="line"><span class="attr">mysql_service_nio_enabled</span> = <span class="string">true  </span></span><br><span class="line">  </span><br><span class="line"><span class="attr">run_mode</span> = <span class="string">shared_data  </span></span><br><span class="line"><span class="attr">cloud_native_storage_type</span> = <span class="string">S3  </span></span><br><span class="line"><span class="attr">aws_s3_endpoint</span> = <span class="string">10.0.9.20:9000  </span></span><br><span class="line"><span class="comment"># set the path in MinIO  </span></span><br><span class="line"><span class="attr">aws_s3_path</span> = <span class="string">starrocks  </span></span><br><span class="line"><span class="comment"># credentials for MinIO object read/write  </span></span><br><span class="line"><span class="comment"># 这里的 key 为刚才设置的 access token</span></span><br><span class="line"><span class="attr">aws_s3_access_key</span> = <span class="string">AAAAAAAAAAAAAAAAAAAA  </span></span><br><span class="line"><span class="attr">aws_s3_secret_key</span> = <span class="string">BBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBB  </span></span><br><span class="line"><span class="attr">aws_s3_use_instance_profile</span> = <span class="string">false  </span></span><br><span class="line"><span class="attr">aws_s3_use_aws_sdk_default_behavior</span> = <span class="string">false  </span></span><br><span class="line"><span class="comment"># Set this to false if you do not want default  </span></span><br><span class="line"><span class="comment"># storage created in the object storage using  </span></span><br><span class="line"><span class="comment"># the details provided above  </span></span><br><span class="line"><span class="attr">enable_load_volume_from_conf</span> = <span class="string">true  </span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment"># 本机 IP，需要与 cn 中的配置对齐</span></span><br><span class="line"><span class="attr">priority_networks</span> = <span class="string">10.0.9.20/24</span></span><br></pre></td></tr></table></figure><p>启动 FE 之前最好先删除 <code>meta/.</code> 下的所有元数据文件然后再启动。</p><h2 id="添加-CN-节点"><a href="#添加-CN-节点" class="headerlink" title="添加 CN 节点"></a>添加 CN 节点</h2><p>FE 启动成功之后连接上 FE，然后手动添加 CN 节点。</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">ALTER</span> <span class="keyword">SYSTEM</span> <span class="keyword">ADD</span> COMPUTE NODE &quot;127.0.0.1:9050&quot;;</span><br><span class="line"><span class="keyword">show</span> compute nodes;</span><br></pre></td></tr></table></figure><p><img src="https://s2.loli.net/2025/01/20/OBXjoYAqP6DhMKs.png"></p><p>然后就可以创建存算分离的表了。</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> IF <span class="keyword">NOT</span> <span class="keyword">EXISTS</span> par_tbl1</span><br><span class="line">(</span><br><span class="line">    datekey DATETIME,</span><br><span class="line">    k1      <span class="type">INT</span>,</span><br><span class="line">    item_id STRING,</span><br><span class="line">    v2      <span class="type">INT</span></span><br><span class="line">)<span class="keyword">PRIMARY</span> KEY (`datekey`,`k1`)</span><br><span class="line"> <span class="keyword">PARTITION</span> <span class="keyword">BY</span> date_trunc(<span class="string">&#x27;day&#x27;</span>, `datekey`)</span><br><span class="line"> PROPERTIES (</span><br><span class="line">&quot;compression&quot; <span class="operator">=</span> &quot;LZ4&quot;,</span><br><span class="line">&quot;datacache.enable&quot; <span class="operator">=</span> &quot;true&quot;,</span><br><span class="line">&quot;enable_async_write_back&quot; <span class="operator">=</span> &quot;false&quot;,</span><br><span class="line">&quot;enable_persistent_index&quot; <span class="operator">=</span> &quot;true&quot;,</span><br><span class="line">&quot;persistent_index_type&quot; <span class="operator">=</span> &quot;LOCAL&quot;,</span><br><span class="line">&quot;replication_num&quot; <span class="operator">=</span> &quot;1&quot;,</span><br><span class="line">&quot;storage_volume&quot; <span class="operator">=</span> &quot;builtin_storage_volume&quot;</span><br><span class="line">);</span><br></pre></td></tr></table></figure><p>最终其实是参考官方提供的 docker-compose 的编排文件进行部署的：<br><a href="https://raw.githubusercontent.com/StarRocks/demo/master/documentation-samples/quickstart/docker-compose.yml">https://raw.githubusercontent.com/StarRocks/demo/master/documentation-samples/quickstart/docker-compose.yml</a></p><blockquote><p>如果只是想在本地搭建一个存算分离的版本，可以直接使用这个 docker compose.</p></blockquote><p>其中有两个坑需要注意：</p><h2 id="创建表超时"><a href="#创建表超时" class="headerlink" title="创建表超时"></a>创建表超时</h2><p>建表出现超时，提示需要配置时间:</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">admin <span class="keyword">set</span> frontend config(&quot;tablet_create_timeout_second&quot;<span class="operator">=</span>&quot;50&quot;)</span><br></pre></td></tr></table></figure><p>配置也不能解决问题，依然会超时，可以看看本地是否有开启代理，尝试关闭代理试试看。</p><h2 id="unknown-compression-type-0-backend-id-x3D-10002"><a href="#unknown-compression-type-0-backend-id-x3D-10002" class="headerlink" title="unknown compression type(0) backend [id&#x3D;10002]"></a>unknown compression type(0) backend [id&#x3D;10002]</h2><p>不支持的压缩类型：这个问题我在使用 main 分支的 FE 与最新的 <code>starrocks/cn-ubuntu:3.4-latest</code> 的镜像会触发，当我把 FE 降低到具体到 tag 分支，比如 3.3.9 的时候就可以了。</p><p>具体原因就没有细究了，如果要本地 debug 使用最新的 tag 也能满足调试的需求。</p><p>参考链接：</p><ul><li><a href="https://github.com/StarRocks/starrocks/issues/55301">https://github.com/StarRocks/starrocks/issues/55301</a></li><li><a href="https://docs.starrocks.io/zh/docs/deployment/shared_data/minio/">https://docs.starrocks.io/zh/docs/deployment/shared_data/minio/</a></li></ul>]]></content>
    
    
    <summary type="html">&lt;p&gt;前段时间碰到一个 StarRocks 物化视图的 &lt;a href=&quot;https://github.com/StarRocks/starrocks/issues/55301&quot;&gt;bug&lt;/a&gt;: &lt;a href=&quot;https://github.com/StarRocks/starrocks/issues/55301&quot;&gt;https://github.com/StarRocks/starrocks/issues/55301&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;但是这个问题只能在存算分离的场景下才能复现，为了找到问题原因我便尝试在本地搭建一个可以 Debug 的存算分离版本。&lt;/p&gt;
&lt;p&gt;之前也分享过在&lt;a href=&quot;https://crossoverjie.top/2024/10/09/ob/StarRocks-dev-env-build/&quot;&gt;本地 Debug StarRocks&lt;/a&gt;，不过那是存算一体的版本，而存算分离稍微要复杂一些。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;这里提到的本地 Debug 主要是指可以调试 FE，而 CN&amp;#x2F;BE 则是运行在容器环境，避免本地打包和构建运行环境。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;hr&gt;</summary>
    
    
    
    <category term="OB" scheme="http://crossoverjie.top/categories/OB/"/>
    
    <category term="StarRocks" scheme="http://crossoverjie.top/categories/OB/StarRocks/"/>
    
    
    <category term="StarRocks" scheme="http://crossoverjie.top/tags/StarRocks/"/>
    
  </entry>
  
  <entry>
    <title>k8s 云原生应用如何接入监控</title>
    <link href="http://crossoverjie.top/2025/01/02/ob/k8s-monitor-pod/"/>
    <id>http://crossoverjie.top/2025/01/02/ob/k8s-monitor-pod/</id>
    <published>2025-01-02T06:00:50.000Z</published>
    <updated>2025-01-02T06:44:07.208Z</updated>
    
    <content type="html"><![CDATA[<p>前段时间有朋友问我如何在 kubernetes 里搭建监控系统，恰好在公司也在维护内部的可观测平台，正好借这个机会整理下目前常见的自建监控方案。</p><p>一个完整的监控系统通常包含以下的内容：</p><ul><li>指标暴露：将系统内部需要关注的指标暴露出去</li><li>指标采集：收集并存储暴露出来的指标</li><li>指标展示：以各种图表展示和分析收集到的数据</li><li>监控告警：当某些关键指标在一定时间周期内出现异常时，可以及时通知相关人员</li></ul><p><img src="https://s2.loli.net/2024/12/20/nAOS5E1YzWDoZyF.png" alt="image.png"></p><p>对于 k8s 的监控通常分为两个部分：</p><ul><li>k8s 自带的系统组建</li><li>业务 Pod 暴露出来的监控指标</li></ul><span id="more"></span><h1 id="系统组建"><a href="#系统组建" class="headerlink" title="系统组建"></a>系统组建</h1><p>对于 kubernetes 系统组建可以由 <code>cAdvisor</code> 提供监控能力，默认情况下这个功能是开箱即用的，我们只需要在 Prometheus 中配置相关的任务抓取即可：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="bullet">-</span> <span class="attr">job_name:</span> <span class="string">nodeScrape/monitoring/cadvisor-scrape/0</span></span><br><span class="line">  <span class="attr">scrape_interval:</span> <span class="string">30s</span></span><br><span class="line">  <span class="attr">scrape_timeout:</span> <span class="string">15s</span></span><br><span class="line">  <span class="attr">scheme:</span> <span class="string">https</span></span><br><span class="line">  <span class="attr">bearer_token_file:</span> <span class="string">/var/run/secrets/kubernetes.io/serviceaccount/token</span></span><br><span class="line">  <span class="attr">tls_config:</span></span><br><span class="line">    <span class="attr">insecure_skip_verify:</span> <span class="literal">true</span></span><br><span class="line">  <span class="attr">relabel_configs:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">source_labels:</span> [<span class="string">__meta_kubernetes_node_name</span>]</span><br><span class="line">    <span class="attr">target_label:</span> <span class="string">node</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">action:</span> <span class="string">replace</span></span><br><span class="line">    <span class="attr">source_labels:</span> [<span class="string">__meta_kubernetes_node_name</span>]</span><br><span class="line">    <span class="attr">separator:</span> <span class="string">;</span></span><br><span class="line">    <span class="attr">target_label:</span> <span class="string">__address__</span></span><br><span class="line">    <span class="attr">regex:</span> <span class="string">(.*)</span></span><br><span class="line">    <span class="attr">replacement:</span> <span class="string">kubernetes.default.svc:443</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">action:</span> <span class="string">replace</span></span><br><span class="line">    <span class="attr">source_labels:</span> [<span class="string">__meta_kubernetes_node_name</span>]</span><br><span class="line">    <span class="attr">separator:</span> <span class="string">;</span></span><br><span class="line">    <span class="attr">target_label:</span> <span class="string">__metrics_path__</span></span><br><span class="line">    <span class="attr">regex:</span> <span class="string">(.+)</span></span><br><span class="line">    <span class="attr">replacement:</span> <span class="string">/api/v1/nodes/$&#123;1&#125;/proxy/metrics/cadvisor</span></span><br><span class="line"></span><br><span class="line">  <span class="attr">kubernetes_sd_configs:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">role:</span> <span class="string">node</span></span><br></pre></td></tr></table></figure><p><img src="https://s2.loli.net/2024/12/20/RhKZGp94sUTbvFa.png" alt="image.png"><br>这样的话就可以监控 k8s 的内存、CPU 之类的数据。</p><p>具体提供了哪些指标可以参考这里：<br><a href="https://github.com/google/cadvisor/blob/master/docs/storage/prometheus.md#prometheus-container-metrics">https://github.com/google/cadvisor/blob/master/docs/storage/prometheus.md#prometheus-container-metrics</a></p><p>也可以找一些常用的监控面板:<br><a href="https://grafana.com/grafana/dashboards/13077-kubernetes-monitoring-dashboard-kubelet-cadvisor-node-exporter/">https://grafana.com/grafana/dashboards/13077-kubernetes-monitoring-dashboard-kubelet-cadvisor-node-exporter/</a></p><p>k8s 不但提供了 cAdvisor 的数据，还有其他类似的 endpoint: <code>/metrics/resource &amp; /metrics/probes</code> </p><p>具体暴露出来的指标可以参考官方文档：<br><a href="https://kubernetes.io/docs/concepts/cluster-administration/system-metrics/">https://kubernetes.io/docs/concepts/cluster-administration/system-metrics/</a></p><h1 id="业务指标"><a href="#业务指标" class="headerlink" title="业务指标"></a>业务指标</h1><p>对于业务应用来说第一步也是需要将自己的指标暴露出去，如果是 Java 的话可以使用 Prometheus 提供的库：</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">&lt;!-- The client --&gt;</span>  </span><br><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span>  </span><br><span class="line">  <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>io.prometheus<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span>  </span><br><span class="line">  <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>simpleclient<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span>  </span><br><span class="line">  <span class="tag">&lt;<span class="name">version</span>&gt;</span>0.16.0<span class="tag">&lt;/<span class="name">version</span>&gt;</span>  </span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span>  </span><br><span class="line"><span class="comment">&lt;!-- Hotspot JVM metrics--&gt;</span>  </span><br><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span>  </span><br><span class="line">  <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>io.prometheus<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span>  </span><br><span class="line">  <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>simpleclient_hotspot<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span>  </span><br><span class="line">  <span class="tag">&lt;<span class="name">version</span>&gt;</span>0.16.0<span class="tag">&lt;/<span class="name">version</span>&gt;</span>  </span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure><p> 它会自动将 JVM 相关的指标暴露出去，如果是在 VM 中的应用，那只需要简单的配置下 <code>static_configs</code> 就可以抓取指标了：</p> <figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"> <span class="attr">scrape_configs:</span>  </span><br><span class="line"><span class="bullet">-</span> <span class="attr">job_name:</span> <span class="string">&#x27;springboot&#x27;</span>  </span><br><span class="line"><span class="attr">scrape_interval:</span> <span class="string">10s</span>  </span><br><span class="line"><span class="attr">static_configs:</span>  </span><br><span class="line"><span class="bullet">-</span> <span class="attr">targets:</span> [<span class="string">&#x27;localhost:8080&#x27;</span>] <span class="comment"># Spring Boot ip+port</span></span><br></pre></td></tr></table></figure><p>但在 kubernetes 中这个 IP 是不固定的，每次重建应用的时候都会发生变化，所以我们需要一种服务发现机制来动态的找到 Pod 的 IP。</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="bullet">-</span> <span class="attr">job_name:</span> <span class="string">&#x27;kubernetes-pods&#x27;</span></span><br><span class="line">  <span class="attr">kubernetes_sd_configs:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">role:</span> <span class="string">pod</span></span><br><span class="line">  <span class="attr">relabel_configs:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">source_labels:</span> [<span class="string">__meta_kubernetes_pod_annotation_prometheus_io_scrape</span>]</span><br><span class="line">    <span class="attr">action:</span> <span class="string">keep</span></span><br><span class="line">    <span class="attr">regex:</span> <span class="literal">true</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">source_labels:</span> [<span class="string">__meta_kubernetes_pod_annotation_prometheus_io_path</span>]</span><br><span class="line">    <span class="attr">action:</span> <span class="string">replace</span></span><br><span class="line">    <span class="attr">target_label:</span> <span class="string">__metrics_path__</span></span><br><span class="line">    <span class="attr">regex:</span> <span class="string">(.+)</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">source_labels:</span> [<span class="string">__address__</span>, <span class="string">__meta_kubernetes_pod_annotation_prometheus_io_port</span>]</span><br><span class="line">    <span class="attr">action:</span> <span class="string">replace</span></span><br><span class="line">    <span class="attr">regex:</span> <span class="string">([^:]+)(?::\d+)?;(\d+)</span></span><br><span class="line">    <span class="attr">replacement:</span> <span class="string">$1:$2</span></span><br><span class="line">    <span class="attr">target_label:</span> <span class="string">__address__</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">action:</span> <span class="string">labelmap</span></span><br><span class="line">    <span class="attr">regex:</span> <span class="string">__meta_kubernetes_pod_label_(.+)</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">source_labels:</span> [<span class="string">__meta_kubernetes_namespace</span>]</span><br><span class="line">    <span class="attr">action:</span> <span class="string">replace</span></span><br><span class="line">    <span class="attr">target_label:</span> <span class="string">kubernetes_namespace</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">source_labels:</span> [<span class="string">__meta_kubernetes_pod_label_component</span>]</span><br><span class="line">    <span class="attr">action:</span> <span class="string">replace</span></span><br><span class="line">    <span class="attr">target_label:</span> <span class="string">job</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">source_labels:</span> [<span class="string">__meta_kubernetes_pod_name</span>]</span><br><span class="line">    <span class="attr">action:</span> <span class="string">replace</span></span><br><span class="line">    <span class="attr">target_label:</span> <span class="string">kubernetes_pod_name</span></span><br></pre></td></tr></table></figure><p>Prometheus 提供了一个 <code>kubernetes_sd_configs</code> 的服务发现机制，他会在 kubernetes 中查找 Pod 中是否有配置以下的注解：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">template:</span></span><br><span class="line">  <span class="attr">metadata:</span></span><br><span class="line">    <span class="attr">annotations:</span></span><br><span class="line">      <span class="attr">prometheus.io/path:</span> <span class="string">/metrics</span></span><br><span class="line">      <span class="attr">prometheus.io/port:</span> <span class="string">&quot;8082&quot;</span></span><br><span class="line">      <span class="attr">prometheus.io/scrape:</span> <span class="string">&quot;true&quot;</span></span><br></pre></td></tr></table></figure><p>都配置成功后我们便可以在 Prometheus 的管理后台查看到具体的服务信息：<br><img src="https://s2.loli.net/2024/12/23/9tZ3uJTpvQY278D.png" alt="image.png"><br>状态是 UP 则表明抓取数据成功，这样我们就可以在 Prometheus 中查询到数据了。</p><p><img src="https://s2.loli.net/2024/12/23/rM7nDiWgTUmA8h3.png" alt="image.png"></p><p>Prometheus 除了支持 k8s 的服务发现之外还支持各种各样的服务发现，比如你已经使用了  Consul 或者是 Erueka 作为注册中心，也可以直接配置他们的地址然后进行服务发现，这样应用信息发生变化时 Prometheus 也能及时感知到。</p><p>当然 <code>docker/http/docker</code> 等都是支持的，可以按需选择。</p><h2 id="OpenTelemetry"><a href="#OpenTelemetry" class="headerlink" title="OpenTelemetry"></a>OpenTelemetry</h2><p>随着这两年可观测性标准的完善，许多厂商都在往 <code>OpenTelemetry</code> 上进行迁移，接入 OpenTelemetry 与直接使用 Prometheus 最大的不同是：</p><blockquote><p>不再由 Prometheus 主动抓取应用指标，而是由应用给 <code>OpenTelemetry-Collector</code> 推送标准化的可观测数据（包含日志、trace、指标），再由它远程写入 Prometheus 这类时序数据库中。</p></blockquote><p>整体流程图如下：<br><img src="https://s2.loli.net/2024/07/22/oUPjd4KlX7niBaI.png" alt="image.png"></p><p>对应用的最大的区别就是可以不再使用刚才提到 Prometheus 依赖，而是只需要挂载一个 javaagent 即可：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">java -javaagent:opentelemetry-javaagent-2.4.0-SNAPSHOT.jar \  </span><br><span class="line">-Dotel.traces.exporter=otlp \  </span><br><span class="line">-Dotel.metrics.exporter=otlp \  </span><br><span class="line">-Dotel.logs.exporter=none \  </span><br><span class="line">-Dotel.service.name=java-demo \  </span><br><span class="line">-Dotel.exporter.otlp.protocol=grpc \  </span><br><span class="line">-Dotel.propagators=tracecontext,baggage \  </span><br><span class="line">-Dotel.exporter.otlp.endpoint=http://127.0.0.1:5317 -jar target/demo-0.0.1-SNAPSHOT.jar</span><br></pre></td></tr></table></figure><p>而其中会新增的一个 <code>OpenTelemetry-Collector</code>项目，由它将收到的指标数据转发给 Prometheus，所以在它的配置里会配置 Prometheus 的地址：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">exporters:</span></span><br><span class="line">  <span class="attr">otlphttp/prometheus:</span></span><br><span class="line">    <span class="attr">endpoint:</span> <span class="string">http://prometheus:9292/api/v1/otlp</span></span><br><span class="line">    <span class="attr">tls:</span></span><br><span class="line">      <span class="attr">insecure:</span> <span class="literal">true</span></span><br></pre></td></tr></table></figure><p>之前也写过两篇 <code>OpenTelemetry</code> 和监控相关的文章，可以一起阅读体验更佳：</p><ul><li><a href="https://crossoverjie.top/2024/06/13/ob/OpenTelemetry-metrics-concept/">从 Prometheus 到 OpenTelemetry：指标监控的演进与实践</a></li><li><a href="https://crossoverjie.top/2024/08/27/ob/OpenTelemetry-02-metrics/">OpenTelemetry 实战：从零实现应用指标监控</a></li></ul><h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>关于 Prometheus 的安装可以参考官方的 operator 或者是 helm：<br><a href="https://github.com/prometheus-operator/kube-prometheus">https://github.com/prometheus-operator/kube-prometheus</a></p><p>当然如果不想使用 Prometheus 也推荐使用 <a href="https://victoriametrics.com/">VictoriaMetrics</a>，是一个完全兼容 Prometheus 但是资源占用更少的时序数据库。</p><p>参考链接：</p><ul><li><a href="https://kubernetes.io/docs/concepts/cluster-administration/system-metrics/">https://kubernetes.io/docs/concepts/cluster-administration/system-metrics/</a></li><li><a href="https://github.com/google/cadvisor/blob/master/docs/storage/prometheus.md">https://github.com/google/cadvisor/blob/master/docs/storage/prometheus.md</a></li><li><a href="https://prometheus.io/docs/prometheus/latest/configuration/configuration/">https://prometheus.io/docs/prometheus/latest/configuration/configuration/</a></li></ul>]]></content>
    
    
    <summary type="html">&lt;p&gt;前段时间有朋友问我如何在 kubernetes 里搭建监控系统，恰好在公司也在维护内部的可观测平台，正好借这个机会整理下目前常见的自建监控方案。&lt;/p&gt;
&lt;p&gt;一个完整的监控系统通常包含以下的内容：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;指标暴露：将系统内部需要关注的指标暴露出去&lt;/li&gt;
&lt;li&gt;指标采集：收集并存储暴露出来的指标&lt;/li&gt;
&lt;li&gt;指标展示：以各种图表展示和分析收集到的数据&lt;/li&gt;
&lt;li&gt;监控告警：当某些关键指标在一定时间周期内出现异常时，可以及时通知相关人员&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&quot;https://s2.loli.net/2024/12/20/nAOS5E1YzWDoZyF.png&quot; alt=&quot;image.png&quot;&gt;&lt;/p&gt;
&lt;p&gt;对于 k8s 的监控通常分为两个部分：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;k8s 自带的系统组建&lt;/li&gt;
&lt;li&gt;业务 Pod 暴露出来的监控指标&lt;/li&gt;
&lt;/ul&gt;</summary>
    
    
    
    <category term="OB" scheme="http://crossoverjie.top/categories/OB/"/>
    
    <category term="kubernetes" scheme="http://crossoverjie.top/categories/OB/kubernetes/"/>
    
    
    <category term="kubernetes" scheme="http://crossoverjie.top/tags/kubernetes/"/>
    
  </entry>
  
  <entry>
    <title>Istio 安装过程中遇到的坑</title>
    <link href="http://crossoverjie.top/2024/12/25/ob/istio-install-problem/"/>
    <id>http://crossoverjie.top/2024/12/25/ob/istio-install-problem/</id>
    <published>2024-12-25T05:48:35.000Z</published>
    <updated>2024-12-26T03:52:47.449Z</updated>
    
    <content type="html"><![CDATA[<h1 id="安装-Istio"><a href="#安装-Istio" class="headerlink" title="安装 Istio"></a>安装 Istio</h1><p>最近这段时间一直在做服务网格（Istio）相关的工作，背景是我们准备自建 Istio，首先第一件事情就是要安装。</p><p>我这里直接使用官网推荐的 <a href="https://istio.io/v1.18/docs/setup/install/istioctl">istioctl</a> 进行安装：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">$ <span class="built_in">cat</span> &lt;&lt;<span class="string">EOF &gt; ./my-config.yaml</span></span><br><span class="line"><span class="string">apiVersion: install.istio.io/v1alpha1  </span></span><br><span class="line"><span class="string">kind: IstioOperator  </span></span><br><span class="line"><span class="string">metadata:  </span></span><br><span class="line"><span class="string">  namespace: istio-1-18-5  </span></span><br><span class="line"><span class="string">spec:  </span></span><br><span class="line"><span class="string">  profile: minimal  </span></span><br><span class="line"><span class="string">  revision: istio-1-18-5  </span></span><br><span class="line"><span class="string">  meshConfig:  </span></span><br><span class="line"><span class="string">    accessLogFile: /dev/stdout</span></span><br><span class="line"><span class="string">EOF</span></span><br><span class="line">$ istioctl install -f my-config.yaml -n istio-1-18-5</span><br></pre></td></tr></table></figure><p>这里我使用的 profile 是 minimal，它只会安装核心的控制面，具体差异见下图：<br><img src="https://s2.loli.net/2024/12/25/KBu5w4WjLU9zTH3.png" alt="image.png"></p><span id="more"></span><p>输出以下内容时代表安装成功：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">This will install the Istio 1.18.5 minimal profile with [<span class="string">&quot;Istio core&quot;</span> <span class="string">&quot;Istiod&quot;</span>] components into the cluster. Proceed? (y/N) y</span><br><span class="line">✔ Istio core installed                                                                                                                                   </span><br><span class="line">✔ Istiod installed                                                                         </span><br><span class="line">✔ Installation complete  </span><br></pre></td></tr></table></figure><p>之后我们便可以在指定的 <code>namespace</code> 下查询到控制面的 Pod：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">k get pod -n istio-1-18-5</span><br><span class="line">NAME                                   READY   STATUS    RESTARTS   AGE</span><br><span class="line">istiod-istio-1-18-5-6cb9898585-64jtg   1/1     Running   0          22h</span><br></pre></td></tr></table></figure><p>然后只需要将需要注入 sidecar 的 namespace 中开启相关的配置即可，比如我这里将 test 这个 namespace 开启 sidecar 注入：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Namespace</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">labels:</span></span><br><span class="line">    <span class="attr">istio.io/rev:</span> <span class="string">istio-1-18-5</span></span><br><span class="line">    <span class="attr">kubernetes.io/metadata.name:</span> <span class="string">test</span></span><br></pre></td></tr></table></figure><p>最主要的就是加上 <code>istio.io/rev: istio-1-18-5</code> 的标签，标签的值就是我们在安装 istio 时指定的值：<code>revision: istio-1-18-5</code>。</p><p>此时只要我们在这个 namespace 下部署一个 Pod 就会为这个 Pod 挂载一个 sidecar。</p><p><img src="https://s2.loli.net/2024/12/25/Jdrx47cosVtqBv3.png" alt="image.png"></p><h1 id="更新配置的坑"><a href="#更新配置的坑" class="headerlink" title="更新配置的坑"></a>更新配置的坑</h1><p><img src="https://s2.loli.net/2024/12/25/WJjBgqIxCMN1Tz3.png" alt="image.png"><br><img src="https://s2.loli.net/2024/12/25/n4bQDHys9hMoR6c.png" alt="image.png"></p><p><a href="https://istio.io/latest/docs/ops/integrations/prometheus/#option-1-metrics-merging">默认情况</a>下 Istio 会将应用 Pod 的暴露出来的 metrics 和 sidecar 的指标合并在一起，然后暴露为 <code>:15020/stats/prometheus</code> 这个 endpoint。</p><p>而我们自己在 Pod 上定义的注解则是被覆盖掉了：<br><img src="https://s2.loli.net/2024/12/25/vCpUEJgnTYI5rje.png" alt="image.png"></p><p>但我们是将应用和 sidecar 的指标分开采集的，所以我们不需要这个自动合并。</p><p><img src="https://s2.loli.net/2024/12/25/5bQ71OYxmkBFXh6.png"></p><blockquote><p>会单独配置 15090 端口的采集任务</p></blockquote><p>所以我需要将这个功能关闭，安装文档的说明只需要在控制面中将 <code>enablePrometheusMerge</code> 修改为 false 即可。</p><p>安装好 Istio 控制面之后会创建一个 IstioOperator 的 CRD 资源：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">k get IstioOperator -A</span><br><span class="line">NAMESPACE      NAME                           REVISION       STATUS   AGE</span><br><span class="line">istio-1-18-5   installed-state-istio-1-18-5   istio-1-18-5            27h</span><br></pre></td></tr></table></figure><p>所有控制面的配置都可以在这里面修改，所以我想当然的在这里加入了 <code>enablePrometheusMerge: false</code> 的配置。</p><p><img src="https://s2.loli.net/2024/12/25/bCdUxLRQDFEOI6j.png" alt="image.png"></p><p>加上之后我重启了 Pod 发现依然还是 Istio 的注解：</p><p><img src="https://s2.loli.net/2024/12/25/n4bQDHys9hMoR6c.png" alt="image.png"></p><p>也就是说这个配置并没有生效，即便是我把控制面也重启了也没有效果。</p><p>按照原理来说，这些配置应该是控制面下发给数据面的，大胆猜测下也就是控制面没有拿到最新的配置。</p><p>但是我卸载控制面，再安装的时候就指定这个配置确是生效的，也就是说配置没问题，只是我在安装完成后再修改就没法同步。</p><p>之后我在 <a href="https://stackoverflow.com/questions/70076326/how-to-update-istio-configuration-after-installation">stackoverflow</a> 上找到了类似的问题：<br><img src="https://s2.loli.net/2024/12/25/SybMZeG6fc1pjhd.png" alt="image.png"></p><p>简单来说安装好 istio 之后我们也可以继续使用 <code>istioctl install -f xx.yaml</code> 进行更新。</p><h1 id="原理"><a href="#原理" class="headerlink" title="原理"></a>原理</h1><p>后来我仔细看了下 istioctl 这个命令的 help 文档，发现其实已经在描述里写清楚了：<br><img src="https://s2.loli.net/2024/12/26/rv9nkiIO6wgbj5s.png" alt="image.png"><br>甚至还有个别名就叫 <code>apply</code> 这就和 <code>kubectl apply</code> 的命令非常类似了，也更容易理解了，任何的修改只需要 <code>apply</code> 执行一次就可以了。</p><p>不过我也在好奇，既然创建的是一个 <code>IstioOperator</code> 的 CRD，理论上是需要一个 Operator 来读取这里的数据然后再创建一个控制面，同步配置之类的操作。</p><p>但当我安装好 Istio 之后并没看到有一个 Operator 的 Pod 在运行，所以就比较好奇 <code>install</code> 这个命令是如何实现配置同步的。</p><p>经过对 <code>istioctl</code> 的 debug 找到了具体的原因：</p><p><img src="https://s2.loli.net/2024/12/26/2bWSIDsf5gXdkHt.png" alt="WeChatWorkScreenshot_bab3706b-2815-46a6-961e-408439b81841.png"><br><img src="https://s2.loli.net/2024/12/26/XNtGeqnvZiEomfc.png" alt="WeChatWorkScreenshot_8f421734-f1e7-4a07-a676-84300187485d.png"></p><p>在 <code>istioctl install -f xx.yaml</code> 执行之后会直接解析 <code>xx.yaml</code> 里的 <code>IstioOperator</code> 生成所有的 <code>manifest</code> 资源，在这个过程中也会生成一个 <code>ConfigMap</code>，所有的配置都是存放在其中的。</p><p>所以其实我手动修改这个 <code>ConfigMap</code> 也可以动态更新控制面的配置，之前我只是修改了 CRD，我以为还有一个 Operator 来监听这里的变化然后同步数据；实际上并不存在这个逻辑，而是直接应用的 <code>manifest</code>。</p><p>参考链接：</p><ul><li><a href="https://istio.io/v1.18/docs/setup/install/istioctl">https://istio.io/v1.18/docs/setup/install/istioctl</a></li><li><a href="https://istio.io/latest/docs/ops/integrations/prometheus/#option-1-metrics-merging">https://istio.io/latest/docs/ops/integrations/prometheus/#option-1-metrics-merging</a></li><li><a href="https://stackoverflow.com/questions/70076326/how-to-update-istio-configuration-after-installation">https://stackoverflow.com/questions/70076326/how-to-update-istio-configuration-after-installation</a></li></ul>]]></content>
    
    
    <summary type="html">&lt;h1 id=&quot;安装-Istio&quot;&gt;&lt;a href=&quot;#安装-Istio&quot; class=&quot;headerlink&quot; title=&quot;安装 Istio&quot;&gt;&lt;/a&gt;安装 Istio&lt;/h1&gt;&lt;p&gt;最近这段时间一直在做服务网格（Istio）相关的工作，背景是我们准备自建 Istio，首先第一件事情就是要安装。&lt;/p&gt;
&lt;p&gt;我这里直接使用官网推荐的 &lt;a href=&quot;https://istio.io/v1.18/docs/setup/install/istioctl&quot;&gt;istioctl&lt;/a&gt; 进行安装：&lt;/p&gt;
&lt;figure class=&quot;highlight bash&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;12&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;$ &lt;span class=&quot;built_in&quot;&gt;cat&lt;/span&gt; &amp;lt;&amp;lt;&lt;span class=&quot;string&quot;&gt;EOF &amp;gt; ./my-config.yaml&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;string&quot;&gt;apiVersion: install.istio.io/v1alpha1  &lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;string&quot;&gt;kind: IstioOperator  &lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;string&quot;&gt;metadata:  &lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;string&quot;&gt;  namespace: istio-1-18-5  &lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;string&quot;&gt;spec:  &lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;string&quot;&gt;  profile: minimal  &lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;string&quot;&gt;  revision: istio-1-18-5  &lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;string&quot;&gt;  meshConfig:  &lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;string&quot;&gt;    accessLogFile: /dev/stdout&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;string&quot;&gt;EOF&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;$ istioctl install -f my-config.yaml -n istio-1-18-5&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;

&lt;p&gt;这里我使用的 profile 是 minimal，它只会安装核心的控制面，具体差异见下图：&lt;br&gt;&lt;img src=&quot;https://s2.loli.net/2024/12/25/KBu5w4WjLU9zTH3.png&quot; alt=&quot;image.png&quot;&gt;&lt;/p&gt;</summary>
    
    
    
    <category term="Istio" scheme="http://crossoverjie.top/categories/Istio/"/>
    
    <category term="k8s" scheme="http://crossoverjie.top/categories/Istio/k8s/"/>
    
    
    <category term="Istio" scheme="http://crossoverjie.top/tags/Istio/"/>
    
  </entry>
  
  <entry>
    <title>如何在平淡的工作中整理出有价值的简历</title>
    <link href="http://crossoverjie.top/2024/12/10/ob/%E5%A6%82%E4%BD%95%E5%9C%A8%E5%B9%B3%E6%B7%A1%E7%9A%84%E5%B7%A5%E4%BD%9C%E4%B8%AD%E6%95%B4%E7%90%86%E5%87%BA%E6%9C%89%E4%BB%B7%E5%80%BC%E7%9A%84%E7%AE%80%E5%8E%86/"/>
    <id>http://crossoverjie.top/2024/12/10/ob/%E5%A6%82%E4%BD%95%E5%9C%A8%E5%B9%B3%E6%B7%A1%E7%9A%84%E5%B7%A5%E4%BD%9C%E4%B8%AD%E6%95%B4%E7%90%86%E5%87%BA%E6%9C%89%E4%BB%B7%E5%80%BC%E7%9A%84%E7%AE%80%E5%8E%86/</id>
    <published>2024-12-10T07:07:10.000Z</published>
    <updated>2024-12-09T07:09:39.100Z</updated>
    
    <content type="html"><![CDATA[<p>今天在 HackNews 上看到一个<a href="https://news.ycombinator.com/item?id=41937892">帖子</a>：你们是否很难回忆起在工作中做了哪些贡献？</p><p><img src="https://s2.loli.net/2024/10/25/ItaHwFoWzG3ASZV.png"></p><p>我觉得挺多人都有类似的问题，通常都是在需要面试或者内部晋升的时候才开始思考这些问题，这时候在想的话难免会有遗漏。</p><p>结合帖子里的回答我整理了以下以下方法。</p><span id="more"></span><h2 id="每日记录"><a href="#每日记录" class="headerlink" title="每日记录"></a>每日记录</h2><p>好记性不如烂笔头，每日做好工作记录，周末再做一次汇总；<br>有部分公司应该就有类似的制度（日报、周报），但那是写给公司看的，这是写给自己整理的；<br>对自己来说只需要整理有用的内容，去掉那些工作中需要的废话。</p><p>这里推荐可以使用 Obsidian 的 daily 插件，每天点击一下日历就会生成一份文档，周末的时候再点击就会自动将周一到周五的内容进行汇总。<br><img src="https://s2.loli.net/2024/10/25/vQVkq34zCsTMDZh.png"><br><img src="https://s2.loli.net/2024/10/25/RvtwnAP4DQmbYWz.png"><br><img src="https://s2.loli.net/2024/10/25/iCV5YKoyXOmxhsA.png"></p><blockquote><p>建议是在做之前就记录下来，而不是等到今天结束了再记录，此时要么不想记，要么已经忘了。<br>周末汇总的时候可以提炼下，如果是要写到简历里应该怎么写？</p></blockquote><p>同样的观点我在播客<a href="https://www.xiaoyuzhoufm.com/episode/65954bca6d045a7f5e7a9286">代码之外</a>中也有听到，每天在下班的时候进行总结有以下的好处：</p><ul><li>更有仪式感，做完这个后一天的工作就结束了。</li><li>可以学会将任务切分，提高对工作的掌控感。</li><li>长期坚持下来可以增强对任务完成时间的准确预估。</li></ul><h2 id="Git-log-汇总"><a href="#Git-log-汇总" class="headerlink" title="Git log 汇总"></a>Git log 汇总</h2><p>还可以使用 <code>git log --author=&#39;&lt;Your Name&gt;</code> 汇总你对提交记录，然后交给 AI 帮我们总结，这个感觉更适合做工作汇报。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git log --pretty=format:&quot;%h - %an, %ar : %s&quot; --author=&#x27;crossoverJie&#x27; | pbcopy</span><br></pre></td></tr></table></figure><p>在 macOS 中可以使用 <code>pbcopy</code> 命令将输出内容复制到粘贴板，然后我们只需要复制到 chatgpt 中就可以帮我们提炼总结了（但这里的前提是自己的每次提交都是有意义的备注）</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git log --author=&quot;your_username&quot; --since=&quot;2024-01-01&quot; --until=&quot;2024-12-31&quot;</span><br></pre></td></tr></table></figure><p>也可以加上时间筛选，更加精确的统计。</p><h2 id="定时更新简历"><a href="#定时更新简历" class="headerlink" title="定时更新简历"></a>定时更新简历</h2><p>我个人是建议每个季度都更新一下自己的简历，看看有哪些新的东西可以写上去，这也是回顾自己这段时间工作的有效手段，毕竟简历就是要给人看的美化版自己。</p><p><img src="https://s2.loli.net/2024/10/25/BpqVocTehZbUFD6.png"><br> <br>这个帖子还有提到面试时不要害怕写自己不熟的技术栈，即便是只在自己的个人项目中使用过（看来国外和我们也类似）</p><p>这个我觉得得是面试情况而定，如果应聘的 1~3 年的初中级岗位，也不是大厂，那可以这么写，但对于业界都知道的一些大厂（比如阿里、字节）这些面试大概率不会只问表面问题，技术栈写的越多对自己也越没有好处。</p><p>本质上就是需要大家多总结，多参考。</p><p>参考链接：</p><ul><li><a href="https://news.ycombinator.com/item?id=41937892">https://news.ycombinator.com/item?id=41937892</a></li><li><a href="https://www.xiaoyuzhoufm.com/episode/65954bca6d045a7f5e7a9286">https://www.xiaoyuzhoufm.com/episode/65954bca6d045a7f5e7a9286</a></li></ul>]]></content>
    
    
    <summary type="html">&lt;p&gt;今天在 HackNews 上看到一个&lt;a href=&quot;https://news.ycombinator.com/item?id=41937892&quot;&gt;帖子&lt;/a&gt;：你们是否很难回忆起在工作中做了哪些贡献？&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://s2.loli.net/2024/10/25/ItaHwFoWzG3ASZV.png&quot;&gt;&lt;/p&gt;
&lt;p&gt;我觉得挺多人都有类似的问题，通常都是在需要面试或者内部晋升的时候才开始思考这些问题，这时候在想的话难免会有遗漏。&lt;/p&gt;
&lt;p&gt;结合帖子里的回答我整理了以下以下方法。&lt;/p&gt;</summary>
    
    
    
    <category term="OB" scheme="http://crossoverjie.top/categories/OB/"/>
    
    
  </entry>
  
  <entry>
    <title>如何选择可以搞钱的技术栈</title>
    <link href="http://crossoverjie.top/2024/11/26/ob/%E5%A6%82%E4%BD%95%E9%80%89%E6%8B%A9%E5%8F%AF%E4%BB%A5%E6%90%9E%E9%92%B1%E7%9A%84%E6%8A%80%E6%9C%AF%E6%A0%88/"/>
    <id>http://crossoverjie.top/2024/11/26/ob/%E5%A6%82%E4%BD%95%E9%80%89%E6%8B%A9%E5%8F%AF%E4%BB%A5%E6%90%9E%E9%92%B1%E7%9A%84%E6%8A%80%E6%9C%AF%E6%A0%88/</id>
    <published>2024-11-26T14:50:58.000Z</published>
    <updated>2024-11-26T14:57:10.858Z</updated>
    
    <content type="html"><![CDATA[<h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>之前在公司主要负责可观测性和 Pulsar 消息队列相关的内容，最近系统比较稳定，只需要做日常运维，所以就抽出时间逐步在接触 OLAP 相关的技术栈。</p><p>我们用的是 <a href="https://www.starrocks.io/">StarRocks</a>，也是目前比较流行的 OLAP 数据库；在接触的这段时间以来，让我越发感觉到选对一个靠谱的技术方向的重要性。</p><span id="more"></span><p>这里以 <a href="https://pulsar.apache.org/">Pulsar</a> 举例，Pulsar 也是 Apache 的顶级项目，有一定的技术门槛，同时也解决以往消息队列的一些问题（多租户、低延迟、存算分离等） 但如果把它作为一个商业产品的话，相对来说付费能力还不够强。</p><p>其实也能想得到，就单纯的消息中间件在市场上能讲的故事不多，可以将它融入到其他的生态里，比如数据处理、业务解耦等，但总归是配角，没有它虽然没那么优雅，但也可以玩。</p><p>同理 OpenTelemetry 也是类似的，它用于可观测性系统，主要是就是拿来排查问题的，对于企业来说也谈不上刚需。</p><p>他们两个都有一个共同的特点：小公司不需要（或者自己维护开源版，量小也不容易暴露问题），大公司选择单独的团队自己维护，市场蛋糕较小。</p><p>即便是部分中厂可能选择购买云服务，一般也会选择和自己现有技术栈配套的云厂商，比如已经用了大部分阿里云的产品，这种周边服务也会尽可能的在阿里云上选择替代方案，毕竟这样的风险更小，而且国内的产品大多都写还 ALL IN。</p><blockquote><p>可能更多的还是一些政企、金融等业务会选择这些开源产品的企业版，大部分因为需要私有化部署，不太方便直接使用公有云。</p></blockquote><p>而更刚需的往往都是和数据相关的，比如数据库、MongoDB、ElasticSearch 、kubernetes 等，如果想要提升下非业务水平，倒是可以深入一下这些技术栈。</p><h1 id="举例"><a href="#举例" class="headerlink" title="举例"></a>举例</h1><p>拿数据库来说，任何公司都需要，即便是小公司也不敢在生产环境自己维护数据库，一般也会购买云产品，或者是招一个 DBA。</p><p>同理还有云原生相关的基础技术栈，比如 kubernetes 以及围绕着 kubernetes 周边的生态。</p><p>k8s 作为云原生的基础底座，只要涉及到上云就离不开它，不管小厂选择云服务还是大厂自己托管都得需要相关技能。</p><p>即便不是直接做 kubernetes 开发也得需要了解相关的知识，对自己理解整个系统是如何运转的很大的帮助。</p><p>除此之外还有也有个简单的方法：就是看看你们公司为哪些服务买单。</p><p>以我最近接触到的 StarRocks 为例，也是和数据处理相关的公司，他们在疫情期间成立的商业化公司，这几年非但没受到影响反而还在增长。</p><p><img src="https://s2.loli.net/2024/10/10/26uepDnY1yPzBaV.png"></p><blockquote><p>看到他们的招聘还蛮活跃。</p></blockquote><p>即便是厂商更倾向于选择云厂商的数据服务，StarRocks 这类原厂公司或多或少也会参与进去提供一些技术支持。</p><p>不过可能有人的第一反应是这些产品的技术门槛较高，上手比较困难，但其实这些往往都是自己给自己上的难度。</p><p>以我最近提交的一个 PR 来说:<br><a href="https://github.com/StarRocks/starrocks/pull/50926">https://github.com/StarRocks/starrocks/pull/50926</a></p><p>我之前根本就没有接触过 OLAP 相关的内容，但只要有场景，可以在本地 debug 复现，任何问题都很好解决，即便是这是你不熟的技术栈。</p><p>比如 ES 也是 Java 写的，如果你们公司为它付费了，那不如多花时间研究一下，不一定是需要改它的核心逻辑，上层也有很多东西可以参与的。</p><p>而一旦我们对这些技术栈熟悉之后，今后在换工作时就有着其他人不具备的优势，甚至可以加入这些技术背后的商业公司。</p><p>而这些公司大部分都是满足开发者的喜好：比如远程办公、技术驱动等，大家不妨从现在就可以试试。</p><h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>不管是哪种技术最终都是要转换为我们到手的收入，所以选择对收入更加敏感的技术栈还是很有必要的。</p><p>以上的内容主要是针对后端开发，当然这里并不包含想要做独立开发的技术栈，主要还是用于求职。</p><p>大家可以看看自己公司以及曾经的公司有对哪些技术付费，或者是一些都需要的刚需通用的技术栈，深入这些技能对搞钱或多或少都有好处。</p>]]></content>
    
    
    <summary type="html">&lt;h1 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h1&gt;&lt;p&gt;之前在公司主要负责可观测性和 Pulsar 消息队列相关的内容，最近系统比较稳定，只需要做日常运维，所以就抽出时间逐步在接触 OLAP 相关的技术栈。&lt;/p&gt;
&lt;p&gt;我们用的是 &lt;a href=&quot;https://www.starrocks.io/&quot;&gt;StarRocks&lt;/a&gt;，也是目前比较流行的 OLAP 数据库；在接触的这段时间以来，让我越发感觉到选对一个靠谱的技术方向的重要性。&lt;/p&gt;</summary>
    
    
    
    <category term="OB" scheme="http://crossoverjie.top/categories/OB/"/>
    
    
  </entry>
  
  <entry>
    <title>推荐一些值得学习的开源项目和框架</title>
    <link href="http://crossoverjie.top/2024/11/20/ob/%E6%8E%A8%E8%8D%90%E4%B8%80%E4%BA%9B%E5%80%BC%E5%BE%97%E5%AD%A6%E4%B9%A0%E7%9A%84%E5%BC%80%E6%BA%90%E9%A1%B9%E7%9B%AE%E5%92%8C%E6%A1%86%E6%9E%B6/"/>
    <id>http://crossoverjie.top/2024/11/20/ob/%E6%8E%A8%E8%8D%90%E4%B8%80%E4%BA%9B%E5%80%BC%E5%BE%97%E5%AD%A6%E4%B9%A0%E7%9A%84%E5%BC%80%E6%BA%90%E9%A1%B9%E7%9B%AE%E5%92%8C%E6%A1%86%E6%9E%B6/</id>
    <published>2024-11-20T09:06:46.000Z</published>
    <updated>2024-11-20T09:07:50.027Z</updated>
    
    <content type="html"><![CDATA[<p><img src="https://s2.loli.net/2024/11/06/YtoOV3dMNEsqw4u.png" alt="image.png"><br>今天收到球友的问题，让推荐一些值得看的开源项目，觉得 netty 这些太复杂了不太好上手。</p><p>确实如此，我们日常常用的 Spring、Netty 确实由于发展了多年，看起来比较头大。</p><p>下面我来推荐一些我看过同时觉得不错的项目(几乎都是我参与过的），由易到难，其中也会包含 Java 和 Go 的项目，包含主流的中间件和云原生项目。</p><span id="more"></span><h1 id="Java-项目"><a href="#Java-项目" class="headerlink" title="Java 项目"></a>Java 项目</h1><h2 id="xxl-job"><a href="#xxl-job" class="headerlink" title="xxl-job"></a>xxl-job</h2><p>难度：🌟🌟<br>推荐指数：🌟🌟🌟</p><p><img src="https://s2.loli.net/2024/11/06/xuLRoCfVhiFcjbz.png"></p><p><a href="https://github.com/xuxueli/xxl-job">xxl-job</a> 是一个很经典的调度框架，目前在 GitHub 上也有 27k star 的关注，因为功能不复杂所以最近也没有怎么更新了。</p><p>大家日常都会使用这类调度框架，所以理解难度非常低，加上他的实现也比较简单，比如：</p><ul><li>使用 MySQL 的锁来简单粗暴的解决分布式锁的问题</li><li>线程池的使用：因为每个任务的调度都需要尽可能的互相不影响，所以里面大量使用了线程池，同时对如何获取异步任务结果也有一些最佳实践。</li><li>RPC 调用：里面内置了一个 <a href="https://github.com/xuxueli/xxl-rpc">RPC</a> 框架，也是作者编写的，其中的实现原理也不复杂，建议看看源码，可以更好的理解我们在工作中用到 rpc 框架。</li></ul><h2 id="cim"><a href="#cim" class="headerlink" title="cim"></a>cim</h2><p>难度：🌟🌟🌟<br>推荐指数：🌟🌟🌟<br>这里夹了一点私货，就是我自己开源的一个<a href="https://github.com/crossoverJie/cim">分布式即时通讯系统</a>，其实现在来看上一个版本的代码写的挺烂的，不过好在最近发布了 v2.0.0，提升了不少代码质量。</p><p><img src="https://s2.loli.net/2024/10/14/pBvDML4HVgyYZxS.gif" alt="Oct-14-2024 11-09-54-min.gif"><br>它具备 IM 即时通讯的基本功能，同时基于它可以实现：</p><ul><li>即时通讯</li><li>消息推送</li><li>IOT 消息平台</li></ul><p>通过 cim 你可以学习到分布式系统中：</p><ul><li>元数据是如何存放和同步的。</li><li>RPC 调用如何实现。</li><li>长链接系统如何实现。</li><li>复杂的分布式系统如何做集成测试等。</li></ul><p>详细的介绍可以查看项目首页的 <a href="https://github.com/crossoverJie/cim">readme</a>，发现有什么需要优化的地方（其实还蛮多 todo 没有做）都欢迎提交 PR。</p><h2 id="PowerJob"><a href="#PowerJob" class="headerlink" title="PowerJob"></a>PowerJob</h2><p>难度：🌟🌟🌟<br>推荐指数：🌟🌟🌟🌟<br><a href="https://github.com/PowerJob/PowerJob">PowerJob</a> 也是一个调度框架，只是他有后发优势，结合了市面上其他调度系统的优点同时也新增了一些功能，以下是他功能的官方对比图：<br><img src="https://s2.loli.net/2024/11/07/Ngab96HlYstJOyT.png"><br>社区相对于 xxl-job 也更加活跃，目前刚发布了 <code>5.1.0</code> 版本，同时社区也整理许多学习的文章和<a href="https://www.yuque.com/powerjob/guidence/wu2e93">资料</a>：</p><p><img src="https://s2.loli.net/2024/11/07/aGUzAwhX5CE2Lbj.png" alt="image.png"></p><p>它使用了 Akka 来实现远程通信，对这部分内容感兴趣的朋友不容错过，可以看到一些最佳实践。<br>其中的代码写的也很规范，一些类的设计很好，可扩展性很高，比如常用的执行器都是通过一个<br><code>MapProcessor</code> 扩展而来的。<br><img src="https://s2.loli.net/2024/11/07/SO2eRbvqrI5EGyU.png" alt="image.png"><br><img src="https://s2.loli.net/2024/11/07/rvabkCdo4g3FTyU.png" alt="image.png"></p><p>推荐大家从任务调度那一块开始看：<code>tech.powerjob.worker.actors.TaskTrackerActor#onReceiveServerScheduleJobReq</code></p><h2 id="Pulsar"><a href="#Pulsar" class="headerlink" title="Pulsar"></a>Pulsar</h2><p>难度：🌟🌟🌟🌟<br>推荐指数：🌟🌟🌟🌟<br><img src="https://s2.loli.net/2024/11/07/2MFiE1vPSfl69ty.png" alt="image.png"><br>Pulsar 是目前主流的云原生消息队列中间件，现在使用的公司也非常多，通过他你可以学习到：</p><ul><li>API 设计：Pulsar 的 client 是直接面向开发者的，在易用性的前提下每次迭代升级还要考虑到兼容性。</li><li>异步调用：Pulsar 里几乎所有的请求都是异步的，所以大量使用了异步➕回调（虽然也有一些坑），可以学到一些高性能代码的编写方式。</li><li>Netty 的最佳用法：消息收发的底层网络框架也是 Netty 支撑的，Pulsar 对它做了封装。</li><li>基于 protocol 的多语言客户端。<ul><li>因为 Pulsar 的通信编解码使用的是 protocol，本身是可以基于它生成各种语言的 API，所以在此基础上编写其他语言的客户端就非常方便。</li></ul></li></ul><p>不过由于 Pulsar 本身的复杂性，上手起来门槛还是不低，推荐先从客户端的代码（Java 和  Go 的都可以）上手。</p><h2 id="StarRocks"><a href="#StarRocks" class="headerlink" title="StarRocks"></a>StarRocks</h2><p>难度：🌟🌟🌟🌟🌟<br>推荐指数：🌟🌟🌟🌟<br><img src="https://s2.loli.net/2024/11/08/zZ8jD9JU1tSkm6A.png" alt="image.png"></p><p>StarRocks 也是我最近才接触到的 OLAP 数据库项目，以前对这个领域的积累几乎为零，所以也是从头学习。</p><p>好在这段时间因为有需求也给它提交了几个 PR，逐渐熟悉起来了。<br><img src="https://s2.loli.net/2024/11/08/gVb15UWrwXHq8YI.png" alt="image.png"></p><p>我接触下来这些开源项目，发现 StarRocks 这类数据库项目是最有前（钱）景的，毕竟和数据打交道的产品公司的付费意愿会更高一些。</p><p>不过该项目确实对新手不太友好，最好是已经接触过大数据领域再学习会更合适一些，但也不要怕，我就是一个纯小白，没基础就跟着代码 debug，反正都是 Java 写的总能看懂。</p><p>这里推荐先看看我之前写的<a href="https://crossoverjie.top/2024/10/09/ob/StarRocks-dev-env-build/">本地搭建开发环境</a>，这样就可以在 idea 里 debug 了。</p><h2 id="OpenTelemetry"><a href="#OpenTelemetry" class="headerlink" title="OpenTelemetry"></a>OpenTelemetry</h2><p>难度：🌟🌟🌟🌟<br>推荐指数：🌟🌟🌟🌟🌟<br><img src="https://s2.loli.net/2024/08/08/p5WkVbSarUdIQwT.png"><br>OpenTelemetry 现在作为云原生可观测性的事实标准，现在已经逐步成为各大公司必备的技术栈了。</p><p>通过一个 <code>javaagent</code> 就可以自动采集应用的 trace、metrics、logs 等数据，这里先推荐 <a href="https://github.com/open-telemetry/opentelemetry-java-instrumentation/">opentelemetry-java-instrumentation</a>，因为我们日常使用最多的就是基于这个项目打包出来的 <code>javaagent</code>，通过它可以学习到：</p><ul><li>如何编写任意函数的拦截器</li><li>trace 信息是如何在线程和进程之间传递的</li><li>一些常用框架是如何运行的<ul><li>比如你需要了解 <a href="https://github.com/open-telemetry/opentelemetry-java-instrumentation/tree/main/instrumentation/grpc-1.6">gRPC</a> 的原理，就可以查看 OpenTelemetry 是如何对他埋点的，从而知晓他的核心原理。</li></ul></li><li>优雅的 API 设计</li></ul><p><img src="https://s2.loli.net/2024/11/08/1yenwuxJ9C6tOSb.png" alt="image.png"><br>同时 OpenTelemetry 算是我看过最优雅的代码之一了，非常建议大家都看看。</p><p>如果对 OpenTelemetry 还不太熟悉，可以先看看我<a href="https://crossoverjie.top/tags/OpenTelemetry/">之前写过的文章</a>。</p><h1 id="Go（云原生项目）"><a href="#Go（云原生项目）" class="headerlink" title="Go（云原生项目）"></a>Go（云原生项目）</h1><h2 id="cprobe"><a href="#cprobe" class="headerlink" title="cprobe"></a>cprobe</h2><p>难度：🌟🌟🌟<br>推荐指数：🌟🌟🌟</p><p><a href="https://github.com/cprobe/cprobe">cprobe</a> 属于可观测性项目，他的目的是可以把各种 exporter 都整合在一起，比如 <code>kafka_exporter</code>, <code>nginx_exporter</code>, <code>mysql_exporter</code> 等。</p><p>同时还做了上层抽象，可以统一管理各种监控对象的配置，这样就可以部署一个进程监控所有的应用了。</p><p>通过这个项目可以学到：</p><ul><li>监控体系的基础知识，比如 Prometheus 和 metrics 等</li><li>Go 语言的基本用法</li></ul><p>我之前写过一篇 <a href="https://crossoverjie.top/2024/01/25/ob/create-a-plugin-for-cprobe/">手把手教你为开源项目贡献代码</a>就是以 cprobe 为例来介绍的。</p><h2 id="VictoriaLogs"><a href="#VictoriaLogs" class="headerlink" title="VictoriaLogs"></a>VictoriaLogs</h2><p>难度：🌟🌟🌟🌟<br>推荐指数：🌟🌟🌟🌟</p><p>这是一个属于 <a href="https://github.com/VictoriaMetrics/VictoriaMetrics/tree/master/app/victoria-logs">VictoriaMetrics</a> 的一个子项目，通过这个名字应该会知道他主要用于处理日志，可以把他理解为 ElasticSearch 的简易版，虽然功能简单了但资源消耗也会比 ES 低很多，具体可以看下面的压测图：</p><p><img src="https://s2.loli.net/2023/08/23/3Epxdzie8q5tVmY.png" alt="image.png"></p><p>通过这个项目可以学到：</p><ul><li>数据在磁盘中是如何存储和查询的</li><li>Go 语言中关于 <code>goroutine</code> 和 <code>channel</code> 的一些最佳实践<br>目前的版本还比较早，所以代码都不太复杂，建议大家可以从查询的入口开始<a href="https://github.com/VictoriaMetrics/VictoriaMetrics/blob/master/lib/logstorage/storage_search.go">看起</a>。</li></ul><h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>以上都是我正经接触过的项目，如果是想长期耕耘同时搞钱的话，推荐 <code>StarRocks</code>，目前也很火。</p><p>如果只是想提升在 Java 领域的水平，那推荐 Pulsar 和 OpenTelemetry，都有很多代码最佳实践。</p><p>如果想要入坑云原生和 Go 项目，那 cprobe 是比较合适的。</p><p>当然不管是哪个项目最主要的还是坚持，很多项目如果只是偶尔看一下很容易忘记，起码要做到真正运行起来然后 debug 过代码。</p><p>参考链接：</p><ul><li><a href="https://www.yuque.com/powerjob/guidence/wu2e93">https://www.yuque.com/powerjob/guidence/wu2e93</a></li><li><a href="https://github.com/VictoriaMetrics/VictoriaMetrics/blob/master/lib/logstorage/storage_search.go">https://github.com/VictoriaMetrics/VictoriaMetrics/blob/master/lib/logstorage/storage_search.go</a></li><li><a href="https://crossoverjie.top/tags/OpenTelemetry/">https://crossoverjie.top/tags/OpenTelemetry/</a></li><li><a href="https://crossoverjie.top/2024/10/09/ob/StarRocks-dev-env-build/">https://crossoverjie.top/2024/10/09/ob/StarRocks-dev-env-build/</a></li></ul>]]></content>
    
    
    <summary type="html">&lt;p&gt;&lt;img src=&quot;https://s2.loli.net/2024/11/06/YtoOV3dMNEsqw4u.png&quot; alt=&quot;image.png&quot;&gt;&lt;br&gt;今天收到球友的问题，让推荐一些值得看的开源项目，觉得 netty 这些太复杂了不太好上手。&lt;/p&gt;
&lt;p&gt;确实如此，我们日常常用的 Spring、Netty 确实由于发展了多年，看起来比较头大。&lt;/p&gt;
&lt;p&gt;下面我来推荐一些我看过同时觉得不错的项目(几乎都是我参与过的），由易到难，其中也会包含 Java 和 Go 的项目，包含主流的中间件和云原生项目。&lt;/p&gt;</summary>
    
    
    
    <category term="OpenSource" scheme="http://crossoverjie.top/categories/OpenSource/"/>
    
    
    <category term="OpenSource" scheme="http://crossoverjie.top/tags/OpenSource/"/>
    
  </entry>
  
  <entry>
    <title>StarRocks 物化视图刷新流程和原理</title>
    <link href="http://crossoverjie.top/2024/11/18/ob/StarRocks-MV-refresh-Principle/"/>
    <id>http://crossoverjie.top/2024/11/18/ob/StarRocks-MV-refresh-Principle/</id>
    <published>2024-11-18T14:35:25.000Z</published>
    <updated>2024-11-18T10:46:12.231Z</updated>
    
    <content type="html"><![CDATA[<p>前段时间给 StarRocks 的物化视图新增了一个<a href="https://github.com/StarRocks/starrocks/pull/50926">特性</a>，那也是我第一次接触 StarRocks，因为完全不熟悉这个数据库，所以很多东西都是从头开始了解概念。</p><p>为了能顺利的新增这个特性（具体内容可以见后文），我需要把整个物化视图的流程串联一遍，于是便有了这篇文章。</p><p>在开始之前简单了解下物化视图的基本概念：</p><p><img src="https://s2.loli.net/2024/11/13/TMAjuUsEZGJiFDS.png" alt="image.png"></p><p>简单来说，视图和 MySQL 这类传统数据库的概念类似，也是用于解决大量消耗性能的 SQL 的，可以提前将这些数据查询好然后放在一张单独的表中，这样再查询的时候性能消耗就比较低了。</p><span id="more"></span><h1 id="刷新条件"><a href="#刷新条件" class="headerlink" title="刷新条件"></a>刷新条件</h1><p>为了保证视图数据的实时性，还需要在数据发生变化的时候能够及时刷新视图里的数据，目前有这几个地方会触发视图刷新：<br><img src="https://s2.loli.net/2024/11/13/vJFQBAyfus5ZwIT.png" alt="image.png"></p><ul><li>手动刷新视图，使用 <code>REFRESH MATERIALIZED VIEW order_mv;</code> 语句</li><li>将视图设置为 active 状态：<code>ALTER MATERIALIZED VIEW order_mv ACTIVE;</code></li><li>基表数据发生变化时触发刷新。<ul><li><img src="https://s2.loli.net/2024/11/13/6QCojHZEJcUL4t2.png" alt="image.png"></li></ul></li><li>truncate 基表时触发刷新：<code>truncate table trunc_db.t1;</code> </li><li>drop partition 时触发：<code>ALTER TABLE &lt;tbl_name&gt; DROP PARTITION(S) p0, p1 [, ...];</code></li></ul><p>这里的 truncate table  和 drop partition 目前的版本还存在 bug：当基表和物化视图不在一个数据库时不会触发自动刷新，目前已经修复了。</p><p><img src="https://s2.loli.net/2024/11/13/2wtZfnFTUbsHaY4.png" alt="image.png"></p><ul><li><a href="https://github.com/StarRocks/starrocks/pull/52618">https://github.com/StarRocks/starrocks/pull/52618</a></li><li><a href="https://github.com/StarRocks/starrocks/pull/52295">https://github.com/StarRocks/starrocks/pull/52295</a></li></ul><h1 id="刷新流程"><a href="#刷新流程" class="headerlink" title="刷新流程"></a>刷新流程</h1><p><img src="https://s2.loli.net/2024/11/14/QljDLmRrx97EIK6.png" alt="image.png"></p><p>如图所示，当触发一次刷新之后主要就是需要计算出需要刷新的分区。</p><p>第一次触发刷新的时候是不会带上周期（比如时间范围），然后根据过滤计算出来的周期，默认情况下只会使用第一个周期（我们可以通过 <code>partition_refresh_number</code> 参数来调整单次刷新的分区数量）。</p><p><img src="https://s2.loli.net/2024/11/14/3QFtkXRfvhCdNrS.png"></p><p>然后如果还有其余的周期，会将这些周期重新触发一次刷新任务（会带上刚才剩余的周期数据），这样进行递归执行。</p><p><img src="https://s2.loli.net/2024/11/15/OqjuMl1LNkWh39g.png"></p><p>通过日志会看到返回的分区数据。</p><h1 id="新增优化参数"><a href="#新增优化参数" class="headerlink" title="新增优化参数"></a>新增优化参数</h1><p>我们在使用物化视图的时候，碰到一个场景：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> IF <span class="keyword">NOT</span> <span class="keyword">EXISTS</span> test.par_tbl1</span><br><span class="line">(</span><br><span class="line">    datekey DATETIME,</span><br><span class="line">    k1      <span class="type">INT</span>,</span><br><span class="line">    item_id STRING,</span><br><span class="line">    v2      <span class="type">INT</span></span><br><span class="line">)<span class="keyword">PRIMARY</span> KEY (`datekey`,`k1`)</span><br><span class="line"> <span class="keyword">PARTITION</span> <span class="keyword">BY</span> date_trunc(<span class="string">&#x27;day&#x27;</span>, `datekey`);</span><br><span class="line"></span><br><span class="line"> <span class="keyword">CREATE</span> <span class="keyword">TABLE</span> IF <span class="keyword">NOT</span> <span class="keyword">EXISTS</span> test.par_tbl2</span><br><span class="line">(</span><br><span class="line">    datekey DATETIME,</span><br><span class="line">    k1      <span class="type">INT</span>,</span><br><span class="line">    item_id STRING,</span><br><span class="line">    v2      <span class="type">INT</span></span><br><span class="line">)<span class="keyword">PRIMARY</span> KEY (`datekey`,`k1`)</span><br><span class="line"> <span class="keyword">PARTITION</span> <span class="keyword">BY</span> date_trunc(<span class="string">&#x27;day&#x27;</span>, `datekey`);</span><br><span class="line"></span><br><span class="line"> <span class="keyword">CREATE</span> <span class="keyword">TABLE</span> IF <span class="keyword">NOT</span> <span class="keyword">EXISTS</span> test.par_tbl3</span><br><span class="line">(</span><br><span class="line">    datekey DATETIME,</span><br><span class="line">    k1      <span class="type">INT</span>,</span><br><span class="line">    item_id STRING,</span><br><span class="line">    v2      <span class="type">INT</span></span><br><span class="line">)</span><br><span class="line"> <span class="keyword">PRIMARY</span> KEY (`datekey`,`k1`);</span><br></pre></td></tr></table></figure><p>但我们有三张基表，其中 1 和 2 都是分区表，但是 3 是非分区表。</p><p>此时基于他们新建了一个物化视图：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE</span></span><br><span class="line">MATERIALIZED <span class="keyword">VIEW</span> test.mv_test</span><br><span class="line">REFRESH ASYNC</span><br><span class="line"><span class="keyword">PARTITION</span> <span class="keyword">BY</span> a_time</span><br><span class="line">PROPERTIES (</span><br><span class="line">&quot;excluded_trigger_tables&quot; <span class="operator">=</span> &quot;par_tbl3&quot;</span><br><span class="line">)</span><br><span class="line"><span class="keyword">AS</span></span><br><span class="line"><span class="keyword">select</span> date_trunc(&quot;day&quot;, a.datekey) <span class="keyword">as</span> a_time, date_trunc(&quot;day&quot;, b.datekey) <span class="keyword">as</span> b_time,date_trunc(&quot;day&quot;, c.datekey) <span class="keyword">as</span> c_time</span><br><span class="line"><span class="keyword">from</span> test.par_tbl1 a</span><br><span class="line">         <span class="keyword">left</span> <span class="keyword">join</span> test.par_tbl2 b <span class="keyword">on</span> a.datekey <span class="operator">=</span> b.datekey <span class="keyword">and</span> a.k1 <span class="operator">=</span> b.k1</span><br><span class="line">         <span class="keyword">left</span> <span class="keyword">join</span> test.par_tbl3 c <span class="keyword">on</span> a.k1 <span class="operator">=</span> c.k1;</span><br></pre></td></tr></table></figure><p>当我同时更新了分区表和非分区表的数据时：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">UPDATE</span> `par_tbl1` <span class="keyword">SET</span> `v2` <span class="operator">=</span> <span class="number">2</span> <span class="keyword">WHERE</span> `datekey` <span class="operator">=</span> <span class="string">&#x27;2024-08-05 01:00:00&#x27;</span> <span class="keyword">AND</span> `k1` <span class="operator">=</span> <span class="number">3</span>;</span><br><span class="line"><span class="keyword">UPDATE</span> `par_tbl3` <span class="keyword">SET</span> `item_id` <span class="operator">=</span> <span class="string">&#x27;3&#x27;</span> <span class="keyword">WHERE</span> `datekey` <span class="operator">=</span> <span class="string">&#x27;2024-10-01 01:00:00&#x27;</span> <span class="keyword">AND</span> `k1` <span class="operator">=</span> <span class="number">3</span>;</span><br></pre></td></tr></table></figure><p>预期的结果是只有 <code>par_tbl1</code> 表里修改的数据会被同步到视图（<code>&quot;excluded_trigger_tables&quot; = &quot;par_tbl3&quot;</code>已经被设置为不会触发视图刷新），但实际情况是 <code>par_tbl1</code> 和 <code>par_tbl2</code> 表里所有的数据都会被刷新到物化视图中。</p><p>我们可以使用这个 SQL 查询无刷视图任务的运行状态：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> information_schema.task_runs <span class="keyword">order</span> <span class="keyword">by</span> create_time <span class="keyword">desc</span>;</span><br></pre></td></tr></table></figure><p>这样就会造成资源损耗，如果这两张基表的数据非常大，本次刷新会非常耗时。</p><p>所以我们的需求是在这样的场景下也只刷新修改的数据。</p><p>因此我们在新建物化视图的时候新增了一个参数：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE</span></span><br><span class="line">MATERIALIZED <span class="keyword">VIEW</span> test.mv_test</span><br><span class="line">REFRESH ASYNC</span><br><span class="line"><span class="keyword">PARTITION</span> <span class="keyword">BY</span> a_time</span><br><span class="line">PROPERTIES (</span><br><span class="line">&quot;excluded_trigger_tables&quot; <span class="operator">=</span> &quot;par_tbl3&quot;,</span><br><span class="line">&quot;excluded_refresh_tables&quot;<span class="operator">=</span>&quot;par_tbl3&quot;</span><br><span class="line">)</span><br><span class="line"><span class="keyword">AS</span></span><br><span class="line"><span class="keyword">select</span> date_trunc(&quot;day&quot;, a.datekey) <span class="keyword">as</span> a_time, date_trunc(&quot;day&quot;, b.datekey) <span class="keyword">as</span> b_time,date_trunc(&quot;day&quot;, c.datekey) <span class="keyword">as</span> c_time</span><br><span class="line"><span class="keyword">from</span> test.par_tbl1 a</span><br><span class="line">         <span class="keyword">left</span> <span class="keyword">join</span> test.par_tbl2 b <span class="keyword">on</span> a.datekey <span class="operator">=</span> b.datekey <span class="keyword">and</span> a.k1 <span class="operator">=</span> b.k1</span><br><span class="line">         <span class="keyword">left</span> <span class="keyword">join</span> test.par_tbl3 c <span class="keyword">on</span> a.k1 <span class="operator">=</span> c.k1;</span><br></pre></td></tr></table></figure><p>这样当在刷新数据的时候，会判断 <code>excluded_refresh_tables</code> 配置的表是否有发生数据变化，如果有的话则不能将当前计算出来的分区（1,2 两张表的全量数据）全部刷新，而是继续求一个交集，只计算基表发生变化的数据。</p><p>这样就可以避免 par_tbl1、par_tbl2 的数据全量刷新，而只刷新修改的数据。</p><p>这样的场景通常是在关联的基表中有一张字典表，通常数据量不大，所以也不需要分区的场景。</p><p>这样在创建物化视图的时候就可以使用这两个参数 <code>excluded_trigger_tables，excluded_refresh_tables</code> 将它排除掉了。</p><p><img src="https://s2.loli.net/2024/11/15/lrGJEnRgyQDd2Pc.png"></p><p>整体的刷新逻辑并不复杂，主要就是几个不同的刷新入口以及刷新过程中计算分区的逻辑。</p><p>参考链接：</p><ul><li><a href="https://docs.starrocks.io/zh/docs/using_starrocks/async_mv/Materialized_view/#%E7%90%86%E8%A7%A3-starrocks-%E7%89%A9%E5%8C%96%E8%A7%86%E5%9B%BE">https://docs.starrocks.io/zh/docs/using_starrocks/async_mv/Materialized_view/#%E7%90%86%E8%A7%A3-starrocks-%E7%89%A9%E5%8C%96%E8%A7%86%E5%9B%BE</a></li><li><a href="https://docs.starrocks.io/zh/docs/using_starrocks/async_mv/use_cases/data_modeling_with_materialized_views/#%E5%88%86%E5%8C%BA%E5%BB%BA%E6%A8%A1">https://docs.starrocks.io/zh/docs/using_starrocks/async_mv/use_cases/data_modeling_with_materialized_views/#%E5%88%86%E5%8C%BA%E5%BB%BA%E6%A8%A1</a></li><li><a href="https://github.com/StarRocks/starrocks/pull/52295">https://github.com/StarRocks/starrocks/pull/52295</a></li><li><a href="https://github.com/StarRocks/starrocks/pull/52618">https://github.com/StarRocks/starrocks/pull/52618</a></li></ul>]]></content>
    
    
    <summary type="html">&lt;p&gt;前段时间给 StarRocks 的物化视图新增了一个&lt;a href=&quot;https://github.com/StarRocks/starrocks/pull/50926&quot;&gt;特性&lt;/a&gt;，那也是我第一次接触 StarRocks，因为完全不熟悉这个数据库，所以很多东西都是从头开始了解概念。&lt;/p&gt;
&lt;p&gt;为了能顺利的新增这个特性（具体内容可以见后文），我需要把整个物化视图的流程串联一遍，于是便有了这篇文章。&lt;/p&gt;
&lt;p&gt;在开始之前简单了解下物化视图的基本概念：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://s2.loli.net/2024/11/13/TMAjuUsEZGJiFDS.png&quot; alt=&quot;image.png&quot;&gt;&lt;/p&gt;
&lt;p&gt;简单来说，视图和 MySQL 这类传统数据库的概念类似，也是用于解决大量消耗性能的 SQL 的，可以提前将这些数据查询好然后放在一张单独的表中，这样再查询的时候性能消耗就比较低了。&lt;/p&gt;</summary>
    
    
    
    <category term="StarRocks" scheme="http://crossoverjie.top/categories/StarRocks/"/>
    
    
    <category term="StarRocks" scheme="http://crossoverjie.top/tags/StarRocks/"/>
    
  </entry>
  
  <entry>
    <title>深入理解 StarRocks 的元数据管理</title>
    <link href="http://crossoverjie.top/2024/11/11/ob/StarRocks-meta/"/>
    <id>http://crossoverjie.top/2024/11/11/ob/StarRocks-meta/</id>
    <published>2024-11-11T10:44:37.000Z</published>
    <updated>2024-11-11T13:54:42.770Z</updated>
    
    <content type="html"><![CDATA[<h1 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h1><p>最近在排查 <code>starrocks</code> 线上的一个告警日志：</p><p><img src="https://s2.loli.net/2024/09/26/QtMIBdmL7OciVJa.png"></p><p>每隔一段时间都会打印 <code>base-table</code> 也就是物化视图的基表被删除了，但其实表还在，也没人去删除；我们就怀疑是否真的表被删除了（可能是 bug）。</p><p>与此同时还有物化视图 inactive 的日志，也怀疑如果视图是 inactive 之后会导致业务使用有问题。</p><p>为了确认这个日志是否对使用影响，就得需要搞清楚它出现的原因；于是我就着手从日志打印的地方开始排查。</p><span id="more"></span><h1 id="问题排查"><a href="#问题排查" class="headerlink" title="问题排查"></a>问题排查</h1><p><img src="https://s2.loli.net/2024/09/26/2T4sGfw1YC63EuP.png"><br>从这个代码可以看出，是在查询表的信息的时候没有查到，从而导致日志打印 base-table 被 dropped 了。</p><p>而我查询了几天的 <code>drop table</code> 的日志，依然没有找到可能是程序 bug 导致被删除的痕迹。</p><blockquote><p>好在 starrocks 的日志打印非常详细，包含了线程名称、类+方法名称，还有具体的代码函数，很容易就定位日志输出的地方。</p></blockquote><h2 id="元数据"><a href="#元数据" class="headerlink" title="元数据"></a>元数据</h2><p>只是为何会调用到这里还需要阅读源码从而找到原因，在开始之前需要先了解一下 starrocks 元数据的一些基本概念。</p><blockquote><p>其实在这篇文章：<a href="https://xie.infoq.cn/article/6f2f9f56916f0eb2fdb6b001a">StarRocks 元数据管理及 FE 高可用机制</a>中已经有全面的介绍，只是这篇文章有点早了，和现在最新的代码不太匹配。</p></blockquote><p>在 StarRocks 元数据中会保存 Database、Table 等信息。</p><p>这些数据定期保存在 <code>fe/meta</code> 目录中。<br><img src="https://s2.loli.net/2024/09/27/3C4GaXM5BlWmNIw.png"></p><p>StarRocks 对元数据的每一次操作（增删改查数据库、表、物化视图）都会生成 editLog 的操作日志。</p><p><img src="https://s2.loli.net/2024/09/27/5hbDBHGwtarE8fj.png" alt="image.png"></p><blockquote><p>新建数据库、修改表名称等</p></blockquote><p>当 StarRocks 的 FE 集群部署时，会由 leader 的 FE 启动一个 checkpoint 线程，定时扫描当前的元数据是否需要生成一个 <code>image.$&#123;JournalId&#125;</code> 的文件。</p><p><img src="https://s2.loli.net/2024/09/20/lQCkBnNWIZ4GwuV.png"></p><blockquote><p>其实就是判断当前日志数量是否达到上限（默认是 5w）生成一次。</p></blockquote><p>具体的流程如下：<br><img src="https://s2.loli.net/2024/09/27/zgy6ZaQ7b1ceWkm.png"></p><ul><li>判断当前是否需要将日志生成 image</li><li>加载当前 image 里的元数据到内存</li><li>从 bdb 中读取最新的 Journal，然后进行重放（replay）：其实就是更新刚才加载到内存中的元数据。</li><li>基于内存中的元数据重新生成一份 image 文件</li><li>删除历史的 image 文件</li><li>将生成的 image 文件名称通知 FE 的 follower 节点，让他们下载到本地，从而可以实现 image 同步。</li></ul><p><img src="https://s2.loli.net/2024/09/27/Hd1NRzgfSy2xECW.png"><br><img src="https://s2.loli.net/2024/09/27/QiTHLpOfJ19oAam.png"></p><blockquote><p>通知 follower 下载 image。</p></blockquote><h2 id="元数据同步流程"><a href="#元数据同步流程" class="headerlink" title="元数据同步流程"></a>元数据同步流程</h2><p>完整的流程图如下图：<br><img src="https://i.imgur.com/txqTt0U.png"></p><p>在这个流程图有一个关键 <code>loadImage</code> 流程：<br><img src="https://s2.loli.net/2024/09/27/MoWjm8SKsgx2GXh.png"></p><p>他会读取 image 这个文件里的数据，然后反序列化后加载到内存里，主要就是恢复数据库和表。</p><p>还会对每个表调用一次 <code>onReload()</code> 函数，而这个函数会只 MV(<code>MATERIALIZED VIEWS</code>) 生效。</p><p>这个函数正好就是在文初提到的这个函数 <code>com.starrocks.catalog.MaterializedView#onReloadImpl</code>：<br><img src="https://s2.loli.net/2024/09/26/2T4sGfw1YC63EuP.png"></p><p>从他的实现来看就是判断视图所依赖的基表是否存在，如果有一个不存在就会将当前基表置为 inactive。</p><p>如果碰到视图的基表也是视图，那就递归再 reload 一次。</p><h2 id="复现问题"><a href="#复现问题" class="headerlink" title="复现问题"></a>复现问题</h2><p>既然知晓了这个加载流程，再结合源码应该不难看出这里的问题所在了。</p><p><img src="https://s2.loli.net/2024/09/27/MoWjm8SKsgx2GXh.png"><br>从这里的加载数据库可以看出端倪，如果我的视图和基表不在同一个数据库里，此时先加载视图是不是就会出现问题？</p><p>加载视图的时候会判断基表是否存在，而此时基表所在的数据库还没加载到内存里，自然就会查询不到从而出现那个日志。</p><p>我之前一直在本地模拟，因为都是在同一个数据库里的基表和视图，所以一直不能复现。</p><p>只要将基表和视图分开在不同的数据库中，让视图先于数据库前加载就会触发这个日志。</p><h1 id="修复问题"><a href="#修复问题" class="headerlink" title="修复问题"></a>修复问题</h1><p>要修复这个问题也很简单，只要等到所有的数据库都表都加载完毕后再去 reload 物化视图就可以了。</p><p>当我回到 main 分支准备着手修改时，发现这个问题已经被修复了：<br><a href="https://github.com/StarRocks/starrocks/pull/51002">https://github.com/StarRocks/starrocks/pull/51002</a></p><p><img src="https://s2.loli.net/2024/09/27/pzWPnoF2MIji9Kw.png"></p><p>修复过程也很简单，就是 reload 时跳过了 MV，等到所有的数据都加载完之后会在 <code>com.starrocks.server.GlobalStateMgr#postLoadImage</code> 手动加载 <code>MV</code>。</p><p><img src="https://s2.loli.net/2024/09/27/7JCLyU6umlRnqvE.png"></p><p>这个 PR 修复的问题也是我一开始提到的，会打印许多令人误解的日志。</p><p>到这里就可以解释文章开头的那个问题了：打印的这个 base-table 被删除的日志对业务来说没有影响，只是一个 bug 导致出现了这个日志。</p><p>额外提一句，这个日志也比较迷，没有打印数据库名称，如果有数据库名称的话可能会更快定位到这个问题。</p><p>参考文章：</p><ul><li><a href="https://xie.infoq.cn/article/6f2f9f56916f0eb2fdb6b001a">https://xie.infoq.cn/article/6f2f9f56916f0eb2fdb6b001a</a></li><li><a href="https://github.com/StarRocks/starrocks/pull/51002">https://github.com/StarRocks/starrocks/pull/51002</a></li></ul>]]></content>
    
    
    <summary type="html">&lt;h1 id=&quot;背景&quot;&gt;&lt;a href=&quot;#背景&quot; class=&quot;headerlink&quot; title=&quot;背景&quot;&gt;&lt;/a&gt;背景&lt;/h1&gt;&lt;p&gt;最近在排查 &lt;code&gt;starrocks&lt;/code&gt; 线上的一个告警日志：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://s2.loli.net/2024/09/26/QtMIBdmL7OciVJa.png&quot;&gt;&lt;/p&gt;
&lt;p&gt;每隔一段时间都会打印 &lt;code&gt;base-table&lt;/code&gt; 也就是物化视图的基表被删除了，但其实表还在，也没人去删除；我们就怀疑是否真的表被删除了（可能是 bug）。&lt;/p&gt;
&lt;p&gt;与此同时还有物化视图 inactive 的日志，也怀疑如果视图是 inactive 之后会导致业务使用有问题。&lt;/p&gt;
&lt;p&gt;为了确认这个日志是否对使用影响，就得需要搞清楚它出现的原因；于是我就着手从日志打印的地方开始排查。&lt;/p&gt;</summary>
    
    
    
    <category term="StarRocks" scheme="http://crossoverjie.top/categories/StarRocks/"/>
    
    
    <category term="StarRocks" scheme="http://crossoverjie.top/tags/StarRocks/"/>
    
  </entry>
  
  <entry>
    <title>时隔五年 9K star 的 IM 项目发布 v2.0.0 了</title>
    <link href="http://crossoverjie.top/2024/11/04/ob/cim-2.0.0/"/>
    <id>http://crossoverjie.top/2024/11/04/ob/cim-2.0.0/</id>
    <published>2024-11-04T03:11:48.000Z</published>
    <updated>2024-11-04T10:28:18.438Z</updated>
    
    <content type="html"><![CDATA[<p>最近业余时间花了小三个月重构了 <a href="https://github.com/crossoverJie/cim">cim</a>，也将版本和升级到了 <a href="https://github.com/crossoverJie/cim/releases/tag/v2.0.0">v2.0.0</a>，合并了十几个 PR 同时也新增了几位开发者。</p><p><img src="https://s2.loli.net/2024/10/12/yKzedUZ8DQlVwTC.png" alt="image.png"></p><blockquote><p>其中有两位也是咱们星球里的小伙伴🎉</p></blockquote><span id="more"></span><h1 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h1><p>上次发版还是在五年前了：<br><img src="https://s2.loli.net/2024/10/12/WCP1Vn62SeBNAmZ.png"></p><p>因为确实已经很久没有更新了，在开始之前还是先介绍 <a href="https://github.com/crossoverJie/cim/">cim</a> 是什么。</p><p>这里有一张简单的使用图片：<br><img src="https://s2.loli.net/2024/10/14/pBvDML4HVgyYZxS.gif" alt="Oct-14-2024 11-09-54-min.gif"><br>同时以前也有录过相关的视频：</p><p>通过 <a href="https://github.com/crossoverJie/cim">cim</a> 这个名字和视频可以看出，它具备 IM 即时通讯的基本功能，同时基于它可以实现：</p><ul><li>即时通讯</li><li>消息推送</li><li>IOT 消息平台</li></ul><p>现在要在本地运行简单许多了，前提是有 docker 就可以了。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">docker run --<span class="built_in">rm</span> --name zookeeper -d -p 2181:2181 zookeeper:3.9.2</span><br><span class="line">docker run --<span class="built_in">rm</span> --name redis -d -p 6379:6379 redis:7.4.0</span><br><span class="line"></span><br><span class="line">git <span class="built_in">clone</span> https://github.com/crossoverJie/cim.git</span><br><span class="line"><span class="built_in">cd</span> cim</span><br><span class="line">mvn clean package -DskipTests=<span class="literal">true</span></span><br><span class="line"><span class="built_in">cd</span> cim-server &amp;&amp; cim-client &amp;&amp; cim-forward-route</span><br><span class="line">mvn clean package spring-boot:repackage -DskipTests=<span class="literal">true</span></span><br></pre></td></tr></table></figure><h2 id="架构"><a href="#架构" class="headerlink" title="架构"></a>架构</h2><p><a href="https://github.com/crossoverJie/cim">cim</a> 的架构图如下：<br><img src="https://s2.loli.net/2024/10/13/O7wVi8QYr3lMFJo.png"><br>主要分为三个部分：</p><ul><li>Client 基本交互功能<ul><li>消息收发</li><li>消息查询</li><li>延迟消息</li></ul></li><li>Route 提供了消息路由以及相关的管理功能<ul><li>API 转发</li><li>消息推送</li><li>会话管理</li><li>可观测性</li></ul></li><li>Server 主要就提供长链接能力，以及真正的消息推送</li></ul><p>同时还有元数据中心（支持扩展实现）、消息存储等组件；</p><p>不管是客户端、route、server 都是支持集群：</p><ul><li>route 由于是无状态，可以任意扩展</li><li>server 通过注册中心也支持集群部署，当发生宕机或者是扩容时，客户端会通过心跳和重连机制保证可用性。</li></ul><p>所以整个架构不存在<strong>单点</strong>，同时比较简单清晰的，大部分组件都支持可扩展。</p><h2 id="流程"><a href="#流程" class="headerlink" title="流程"></a>流程</h2><p><img src="https://s2.loli.net/2024/10/13/8teMn7BSa5VWuvi.png"></p><p>为了更方便理解，花了一个流程图。</p><ul><li>server 在启动之后会先在元数据中心注册</li><li>同时 route 会订阅元数据中的 server 信息</li><li>客户端登陆时会调用 route 获取一个 server 的节点信息</li><li>然后发起登陆请求。<ul><li>成功之后会保持长链接。</li></ul></li><li>客户端向发送消息时会调用 route 接口来发起消息<ul><li>route 根据长链接关系选择 server 进行消息推送</li></ul></li></ul><h2 id="v2-0-0"><a href="#v2-0-0" class="headerlink" title="v2.0.0"></a>v2.0.0</h2><p>接下来介绍下本次 <a href="https://github.com/crossoverJie/cim/releases/tag/v2.0.0">v2.0.0</a> 有哪些重大变更，毕竟是修改了大的版本号。</p><p>这里列举一些重大的改动：<br><img src="https://s2.loli.net/2024/10/12/mRGDV6hBCTAblcI.png" alt="image.png"></p><ul><li>首先是支持了元数据中心，解耦了 zookeeper，也支持自定义实现。</li><li>支持了集成测试，可以保证提交的 PR 对现有功能的影响降到最低，代码质量有一定保证；review 代码时更加放心。</li><li>单独抽离了 <code>client-sdk</code>，代码耦合性更好且更易维护。</li><li>服务之间调用的 RPC 完成了重构<ul><li>支持了动态 URL</li><li>泛型数据解析</li></ul></li><li>还有社区小伙伴贡献的一些 bug 修复、<code>RpcProxyManager</code> 的 IOC 支持等特性。</li></ul><h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>更多的部署和使用可以参考项目首页的 README，有详细的介绍。</p><p><a href="https://github.com/crossoverJie/cim">cim</a> 目前还需要优化的地方非常多；接下来的重点是实现 ACK，同时会完善一下通讯协议。<br><img src="https://s2.loli.net/2024/10/14/l7RIZfYOsmM1N3P.png" alt="image.png"></p><p>todo 列表我也添加了很多，所以非常推荐感兴趣的朋友可以先看看 todo 列表，说不定就有你感兴趣的可以参与一下。</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;最近业余时间花了小三个月重构了 &lt;a href=&quot;https://github.com/crossoverJie/cim&quot;&gt;cim&lt;/a&gt;，也将版本和升级到了 &lt;a href=&quot;https://github.com/crossoverJie/cim/releases/tag/v2.0.0&quot;&gt;v2.0.0&lt;/a&gt;，合并了十几个 PR 同时也新增了几位开发者。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://s2.loli.net/2024/10/12/yKzedUZ8DQlVwTC.png&quot; alt=&quot;image.png&quot;&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;其中有两位也是咱们星球里的小伙伴🎉&lt;/p&gt;
&lt;/blockquote&gt;</summary>
    
    
    
    <category term="IM" scheme="http://crossoverjie.top/categories/IM/"/>
    
    
    <category term="IM" scheme="http://crossoverjie.top/tags/IM/"/>
    
  </entry>
  
  <entry>
    <title>💢线上高延迟请求排查</title>
    <link href="http://crossoverjie.top/2024/10/29/ob/%F0%9F%92%A2%E7%BA%BF%E4%B8%8A%E9%AB%98%E5%BB%B6%E8%BF%9F%E8%AF%B7%E6%B1%82%E6%8E%92%E6%9F%A5/"/>
    <id>http://crossoverjie.top/2024/10/29/ob/%F0%9F%92%A2%E7%BA%BF%E4%B8%8A%E9%AB%98%E5%BB%B6%E8%BF%9F%E8%AF%B7%E6%B1%82%E6%8E%92%E6%9F%A5/</id>
    <published>2024-10-29T10:21:42.000Z</published>
    <updated>2024-10-28T10:29:17.642Z</updated>
    
    <content type="html"><![CDATA[<p>前几天排查了一个业务接口执行高延迟的问题，也挺有参考意义的，分享一下排查过程。</p><p>现象是业务反馈有一个接口业务逻辑其实很简单，但是调用一次耗时，如下图所示：<br><img src="https://s2.loli.net/2024/10/16/Am9VkNZ5Ep4Uj6G.png"></p><span id="more"></span><h1 id="排查应用运行状态"><a href="#排查应用运行状态" class="headerlink" title="排查应用运行状态"></a>排查应用运行状态</h1><p>首先第一步需要查看当时的应用运行状态，包含当时的日志、JVM 的各种监控等。</p><p>因为我们接入了 <code>OpenTelemetry</code>，所以 <code>trace</code> 和日志是可以关联起来的。</p><blockquote><p>点击链路系统旁边的日志按钮可以直接跳转。</p></blockquote><p>可以通过 <code>trace_id</code> 查询到相关日志：<br><img src="https://s2.loli.net/2024/10/16/W5ow6KpdCaOk2f7.png"></p><p>通过日志可以看出耗时大约在 4s 多一点，然后结合代码发现这两段日志分别是在进入一个核心业务方法之前和方法内打印的。</p><p><img src="https://s2.loli.net/2024/10/16/XeqoaGPx8kEmSrD.png"></p><p>而第一行日志是在一个自定义限流器中打印的，这个限流器是使用 <code>Guava</code> 的 <code>RateLimiter</code>实现的。</p><p>我的第一反应是不是这个限流器当时限流了，从而导致阻塞了；但查看了当时的 QPS 发现完全低于限流器的配置，所以基本可以排除它的嫌疑了。</p><h2 id="JVM-监控"><a href="#JVM-监控" class="headerlink" title="JVM 监控"></a>JVM 监控</h2><p><img src="https://s2.loli.net/2024/10/16/f3H6VBFRpCN7Yza.png"></p><p><img src="https://s2.loli.net/2024/10/16/zvKPyXuScQwmiYN.png"></p><p>之后我们查询当时的 JVM 监控发现当时的 GC  频繁，而堆内存也正好发生了一次回收，初步判断是 GC 导致的本次问题。</p><p>但为啥会导致频繁的 GC 呢，还需要继续排查。</p><h2 id="内存排查"><a href="#内存排查" class="headerlink" title="内存排查"></a>内存排查</h2><p>我们在应用诊断中集成了 <a href="https://github.com/grafana/pyroscope">Pyroscope</a>的持续剖析，可以实时查看内存的占用情况。<br><img src="https://s2.loli.net/2024/10/16/Ow5WksxJan9G8py.png"></p><p><img src="https://s2.loli.net/2024/10/16/CbPhVJ4mDyFxicX.png" alt="image.png"></p><p>通过内存分析发现有大量的 JSON 序列化占用了大量的内存，同时还发现 Pod 已经被重启好几次了：<br><img src="https://s2.loli.net/2024/10/16/iKHCFodeVPM9A68.png" alt="image.png"></p><p><img src="https://s2.loli.net/2024/10/16/31aTS7yqNCKlFJQ.png" alt="image.png"></p><p>查看原因发现是 Pod OOM 导致的。</p><p>因此非常有可能是 GC 导致的，恰好那段时间发生了 GC 内存也有明显变化。</p><p><img src="https://s2.loli.net/2024/10/16/f3H6VBFRpCN7Yza.png"></p><p><img src="https://s2.loli.net/2024/10/16/zvKPyXuScQwmiYN.png"></p><p><img src="https://s2.loli.net/2024/10/16/hsXUAZCIGY12gFk.png"></p><p>最后再通过 arthas 确认了 GC 非常频繁，可以确认目前的资源是是非常紧张的，咨询业务之后得知该应用本身占用的资源就比较大，没有太多优化空间，所以最终决定还是加配置。<br><img src="https://s2.loli.net/2024/10/16/VGyrCAZgjx64wHP.png"><br><img src="https://s2.loli.net/2024/10/17/zIEjeMxvkgLomZ4.png" alt="image.png"><br>还是提高硬件效率最高，目前运行半个月之后 Pod 内存表现稳定，没有出现一次 OOM 的异常。</p><h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>虽然最后的处理的方式是简单粗暴的，但其中的过程还是有意义的，遇到不同的情况也有不同的处理方式。</p><p>比如在排查过程中发现内存消耗异常，通过内存分析发现代码可以优化，那就优化代码逻辑。</p><p>如果是堆内存占用不大，但是 Pod 还是 OOM 导致重启，那就要看看 JVM 的内存分配是否合理，应该多预留一些内存给堆外使用。</p><p>但这个过程需要有<strong>完善的可观测系统的</strong>支撑，比如日志、监控等，如果没有这些数据，再回头排查问题就会比较困难。</p><p>总之这个排查过程才是最主要的，大家还有什么排查问题的小 tips 也欢迎在评论区分享。</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;前几天排查了一个业务接口执行高延迟的问题，也挺有参考意义的，分享一下排查过程。&lt;/p&gt;
&lt;p&gt;现象是业务反馈有一个接口业务逻辑其实很简单，但是调用一次耗时，如下图所示：&lt;br&gt;&lt;img src=&quot;https://s2.loli.net/2024/10/16/Am9VkNZ5Ep4Uj6G.png&quot;&gt;&lt;/p&gt;</summary>
    
    
    
    <category term="问题排查" scheme="http://crossoverjie.top/categories/%E9%97%AE%E9%A2%98%E6%8E%92%E6%9F%A5/"/>
    
    
    <category term="Java" scheme="http://crossoverjie.top/tags/Java/"/>
    
  </entry>
  
  <entry>
    <title>IM系统重构到 SDK 设计的最佳实践</title>
    <link href="http://crossoverjie.top/2024/10/13/ob/cim-client-sdk/"/>
    <id>http://crossoverjie.top/2024/10/13/ob/cim-client-sdk/</id>
    <published>2024-10-13T14:04:45.000Z</published>
    <updated>2024-10-13T06:00:43.572Z</updated>
    
    <content type="html"><![CDATA[<p><img src="https://s2.loli.net/2024/10/13/PW1J2bXx39cfpnC.png"></p><h1 id="SDK-设计"><a href="#SDK-设计" class="headerlink" title="SDK 设计"></a>SDK 设计</h1><p><img src="https://s2.loli.net/2024/09/17/Ck6AfdGOPISDrVN.png"></p><p>在之前提到了 <a href="https://github.com/crossoverJie/cim">cim</a> 在做集成测试的时候遇到的问题，需要提供一个 SDK 来解决，于是我花了一些时间编写了 SDK，同时也将 cim-client 重构了。</p><span id="more"></span><p>重构后的代码长这个样子：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Bean</span></span><br><span class="line"><span class="keyword">public</span> Client <span class="title function_">buildClient</span><span class="params">(<span class="meta">@Qualifier(&quot;callBackThreadPool&quot;)</span> ThreadPoolExecutor callbackThreadPool,</span></span><br><span class="line"><span class="params">                          Event event)</span> &#123;</span><br><span class="line">    <span class="type">OkHttpClient</span> <span class="variable">okHttpClient</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">OkHttpClient</span>.Builder().connectTimeout(<span class="number">3</span>, TimeUnit.SECONDS)</span><br><span class="line">            .readTimeout(<span class="number">3</span>, TimeUnit.SECONDS)</span><br><span class="line">            .writeTimeout(<span class="number">3</span>, TimeUnit.SECONDS)</span><br><span class="line">            .retryOnConnectionFailure(<span class="literal">true</span>).build();</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> Client.builder()</span><br><span class="line">            .auth(ClientConfigurationData.Auth.builder()</span><br><span class="line">                    .userName(appConfiguration.getUserName())</span><br><span class="line">                    .userId(appConfiguration.getUserId())</span><br><span class="line">                    .build())</span><br><span class="line">            .routeUrl(appConfiguration.getRouteUrl())</span><br><span class="line">            .loginRetryCount(appConfiguration.getReconnectCount())</span><br><span class="line">            .event(event)</span><br><span class="line">            .reconnectCheck(client -&gt; !shutDownSign.checkStatus())</span><br><span class="line">            .okHttpClient(okHttpClient)</span><br><span class="line">            .messageListener(<span class="keyword">new</span> <span class="title class_">MsgCallBackListener</span>(msgLogger))</span><br><span class="line">            .callbackThreadPool(callbackThreadPool)</span><br><span class="line">            .build();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>配合 <code>springboot</code> 使用时只需要创建一个 <code>Client</code> 即可，这个 <code>Client</code> 里维护了核心的：</p><ul><li>长链接创建、状态维护</li><li>心跳检测</li><li>超时、网络异常重连等</li></ul><p>同时也提供了简易的 API 可以直接收发消息：<br><img src="https://s2.loli.net/2024/09/17/2tCXEo9nLvIrNTf.png"></p><p>这样在集成到业务代码中时会更方便。</p><p>以前的代码耦合度非常高，同时因为基础代码是 18 年写的，现在真的没有眼看了；</p><p>重构的过程中使用一些 Java8+ 的一些语法糖精简了许多代码，各个模块间的组织关系也重新梳理，现在会更易维护了。</p><p>比如由于创建客户端需要许多可选参数，于是就提供了 Builder 模式的创建选项：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">interface</span> <span class="title class_">ClientBuilder</span> &#123;  </span><br><span class="line">  </span><br><span class="line">    Client <span class="title function_">build</span><span class="params">()</span>;  </span><br><span class="line">    ClientBuilder <span class="title function_">auth</span><span class="params">(ClientConfigurationData.Auth auth)</span>;  </span><br><span class="line">    ClientBuilder <span class="title function_">routeUrl</span><span class="params">(String routeUrl)</span>;  </span><br><span class="line">    ClientBuilder <span class="title function_">loginRetryCount</span><span class="params">(<span class="type">int</span> loginRetryCount)</span>;  </span><br><span class="line">    ClientBuilder <span class="title function_">event</span><span class="params">(Event event)</span>;  </span><br><span class="line">    ClientBuilder <span class="title function_">reconnectCheck</span><span class="params">(ReconnectCheck reconnectCheck)</span>;  </span><br><span class="line">    ClientBuilder <span class="title function_">okHttpClient</span><span class="params">(OkHttpClient okHttpClient)</span>;  </span><br><span class="line">    ClientBuilder <span class="title function_">messageListener</span><span class="params">(MessageListener messageListener)</span>;  </span><br><span class="line">    ClientBuilder <span class="title function_">callbackThreadPool</span><span class="params">(ThreadPoolExecutor callbackThreadPool)</span>;  </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><blockquote><p>以上部分 API 的设计借鉴了 Pulsar。</p></blockquote><h1 id="Proxy-优化"><a href="#Proxy-优化" class="headerlink" title="Proxy 优化"></a>Proxy 优化</h1><p>除此之外还优化了请求代理，这个 Proxy 主要是用于方便在各个服务中发起 rest 调用，我这里为了轻量也没有使用 Dubbo、SpringCloud 这类服务框架。</p><p>但如果都硬编码 http client 去请求时会有许多重复冗余的代码，比如创建连接、请求参数、响应解析、异常处理等。</p><p>于是在之前的版本中就提供了一个 <code>ProxyManager</code> 的基本实现：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Override</span>  </span><br><span class="line"><span class="keyword">public</span> List&lt;OnlineUsersResVO.DataBodyBean&gt; onlineUsers() <span class="keyword">throws</span> Exception&#123;  </span><br><span class="line">    <span class="type">RouteApi</span> <span class="variable">routeApi</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">ProxyManager</span>&lt;&gt;(RouteApi.class, routeUrl, okHttpClient).getInstance();  </span><br><span class="line">  </span><br><span class="line">    <span class="type">Response</span> <span class="variable">response</span> <span class="operator">=</span> <span class="literal">null</span>;  </span><br><span class="line">    <span class="type">OnlineUsersResVO</span> <span class="variable">onlineUsersResVO</span> <span class="operator">=</span> <span class="literal">null</span>;  </span><br><span class="line">    <span class="keyword">try</span> &#123;  </span><br><span class="line">        response = (Response) routeApi.onlineUser();  </span><br><span class="line">        <span class="type">String</span> <span class="variable">json</span> <span class="operator">=</span> response.body().string() ;  </span><br><span class="line">        onlineUsersResVO = JSON.parseObject(json, OnlineUsersResVO.class);  </span><br><span class="line">  </span><br><span class="line">    &#125;<span class="keyword">catch</span> (Exception e)&#123;  </span><br><span class="line">        log.error(<span class="string">&quot;exception&quot;</span>,e);  </span><br><span class="line">    &#125;<span class="keyword">finally</span> &#123;  </span><br><span class="line">        response.body().close();  </span><br><span class="line">    &#125;  </span><br><span class="line">    <span class="keyword">return</span> onlineUsersResVO.getDataBody();  </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>虽然提供了一些连接管理和参数封装等基础功能，但只实现了一半。</p><p>从上面的代码也可以看出序列化都得自己实现，这些代码完全是冗余的。</p><p>经过重构后以上的代码可以精简到如下：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 声明接口</span></span><br><span class="line"><span class="meta">@Request(method = Request.GET)</span>  </span><br><span class="line">BaseResponse&lt;Set&lt;CIMUserInfo&gt;&gt; <span class="title function_">onlineUser</span><span class="params">()</span> <span class="keyword">throws</span> Exception;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 初始化</span></span><br><span class="line">routeApi = RpcProxyManager.create(RouteApi.class, routeUrl, okHttpClient);</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> Set&lt;CIMUserInfo&gt; <span class="title function_">onlineUser</span><span class="params">()</span> <span class="keyword">throws</span> Exception &#123;  </span><br><span class="line">    BaseResponse&lt;Set&lt;CIMUserInfo&gt;&gt; onlineUsersResVO = routeApi.onlineUser();  </span><br><span class="line">    <span class="keyword">return</span> onlineUsersResVO.getDataBody();  </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这个调整之后就非常类似于 Dubbo gRPC 这类 RPC 框架的使用，只需要把接口定义好，就和调用本地函数一样的简单。</p><p>为了方便后续可能调用一些外部系统，在此基础上还支持了指定多种请求 method、指定 URL 、返回结果嵌套泛型等。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Request(url = &quot;sample-request?author=beeceptor&quot;)</span>  </span><br><span class="line">EchoGeneric&lt;EchoResponse.HeadersDTO&gt; echoGeneric(EchoRequest message);</span><br><span class="line"></span><br><span class="line"><span class="meta">@Test</span>  </span><br><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">testGeneric</span><span class="params">()</span> &#123;  </span><br><span class="line">    <span class="type">OkHttpClient</span> <span class="variable">client</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">OkHttpClient</span>();  </span><br><span class="line">    <span class="type">String</span> <span class="variable">url</span> <span class="operator">=</span> <span class="string">&quot;http://echo.free.beeceptor.com&quot;</span>;  </span><br><span class="line">    <span class="type">Echo</span> <span class="variable">echo</span> <span class="operator">=</span> RpcProxyManager.create(Echo.class, url, client);  </span><br><span class="line">    <span class="type">EchoRequest</span> <span class="variable">request</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">EchoRequest</span>();  </span><br><span class="line">    request.setName(<span class="string">&quot;crossoverJie&quot;</span>);  </span><br><span class="line">    request.setAge(<span class="number">18</span>);  </span><br><span class="line">    request.setCity(<span class="string">&quot;shenzhen&quot;</span>);  </span><br><span class="line">    <span class="comment">// 支持泛型解析</span></span><br><span class="line">    EchoGeneric&lt;EchoResponse.HeadersDTO&gt; response = echo.echoGeneric(request);  </span><br><span class="line">    Assertions.assertEquals(response.getHeaders().getHost(), <span class="string">&quot;echo.free.beeceptor.com&quot;</span>);  </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="支持动态-URL-调用"><a href="#支持动态-URL-调用" class="headerlink" title="支持动态 URL 调用"></a>支持动态 URL 调用</h2><p><img src="https://s2.loli.net/2024/09/19/v8NgprfJ5PWAsER.png"></p><p>还有一个 todo：希望可以将 <code>ProxyManager</code> 交给 <code>Spring</code> 去管理，之前是在每次调用的地方都会创建一个 Proxy 对象，完全没有必要，代码也很冗余。</p><p>但有网友在实现过程中发现，有个场景的请求地址是动态的，如果是交给 Spring 管理为单例后是没法修改 URL 地址的，因为这个地址是在创建对象的时候初始化的。</p><p>所以我就在这里新增了一个动态 URL 的特性：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">EchoResponse <span class="title function_">echoTarget</span><span class="params">(EchoRequest message, <span class="meta">@DynamicUrl(useMethodEndpoint = false)</span> String url)</span>;</span><br><span class="line"></span><br><span class="line"><span class="type">Echo</span> <span class="variable">echo</span> <span class="operator">=</span> RpcProxyManager.create(Echo.class, client);</span><br><span class="line"><span class="type">String</span> <span class="variable">url</span> <span class="operator">=</span> <span class="string">&quot;http://echo.free.beeceptor.com/sample-request?author=beeceptor&quot;</span>;</span><br><span class="line"><span class="type">EchoResponse</span> <span class="variable">response</span> <span class="operator">=</span> echo.echoTarget(request, url);</span><br></pre></td></tr></table></figure><p>在声明接口的时候使用 <code>@DynamicUrl</code> 的方法参数注解，告诉代理这个参数是 URL。<br>这样就可以允许在创建  <code>Proxy</code> 对象的时候不指定 URL，而是在实际调用时候再传入具体的 URL，更方便创建单例了。</p><h1 id="集成测试优化"><a href="#集成测试优化" class="headerlink" title="集成测试优化"></a>集成测试优化</h1><p>同时还优化了集成测试，支持了 server 的集群版测试。</p><p><a href="https://github.com/crossoverJie/cim/blob/4c149f8bda78718e3ecae2c5759aa9732eff9132/cim-client-sdk/src/test/java/com/crossoverjie/cim/client/sdk/ClientTest.java#L210">https://github.com/crossoverJie/cim/blob/4c149f8bda78718e3ecae2c5759aa9732eff9132/cim-client-sdk/src/test/java/com/crossoverjie/cim/client/sdk/ClientTest.java#L210</a></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Test</span>  </span><br><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">testReconnect</span><span class="params">()</span> <span class="keyword">throws</span> Exception &#123;  </span><br><span class="line">    <span class="built_in">super</span>.startTwoServer();  </span><br><span class="line">    <span class="built_in">super</span>.startRoute();  </span><br><span class="line">  </span><br><span class="line">    <span class="type">String</span> <span class="variable">routeUrl</span> <span class="operator">=</span> <span class="string">&quot;http://localhost:8083&quot;</span>;  </span><br><span class="line">    <span class="type">String</span> <span class="variable">cj</span> <span class="operator">=</span> <span class="string">&quot;cj&quot;</span>;  </span><br><span class="line">    <span class="type">String</span> <span class="variable">zs</span> <span class="operator">=</span> <span class="string">&quot;zs&quot;</span>;  </span><br><span class="line">    <span class="type">Long</span> <span class="variable">cjId</span> <span class="operator">=</span> <span class="built_in">super</span>.registerAccount(cj);  </span><br><span class="line">    <span class="type">Long</span> <span class="variable">zsId</span> <span class="operator">=</span> <span class="built_in">super</span>.registerAccount(zs);  </span><br><span class="line">    <span class="type">var</span> <span class="variable">auth1</span> <span class="operator">=</span> ClientConfigurationData.Auth.builder()  </span><br><span class="line">            .userName(cj)  </span><br><span class="line">            .userId(cjId)  </span><br><span class="line">            .build();  </span><br><span class="line">    <span class="type">var</span> <span class="variable">auth2</span> <span class="operator">=</span> ClientConfigurationData.Auth.builder()  </span><br><span class="line">            .userName(zs)  </span><br><span class="line">            .userId(zsId)  </span><br><span class="line">            .build();  </span><br><span class="line">  </span><br><span class="line">    <span class="meta">@Cleanup</span>  </span><br><span class="line">    <span class="type">Client</span> <span class="variable">client1</span> <span class="operator">=</span> Client.builder()  </span><br><span class="line">            .auth(auth1)  </span><br><span class="line">            .routeUrl(routeUrl)  </span><br><span class="line">            .build();  </span><br><span class="line">    TimeUnit.SECONDS.sleep(<span class="number">3</span>);  </span><br><span class="line">    ClientState.<span class="type">State</span> <span class="variable">state</span> <span class="operator">=</span> client1.getState();  </span><br><span class="line">    Awaitility.await().atMost(<span class="number">10</span>, TimeUnit.SECONDS)  </span><br><span class="line">            .untilAsserted(() -&gt; Assertions.assertEquals(ClientState.State.Ready, state));  </span><br><span class="line">  </span><br><span class="line">  </span><br><span class="line">    AtomicReference&lt;String&gt; client2Receive = <span class="keyword">new</span> <span class="title class_">AtomicReference</span>&lt;&gt;();  </span><br><span class="line">    <span class="meta">@Cleanup</span>  </span><br><span class="line">    <span class="type">Client</span> <span class="variable">client2</span> <span class="operator">=</span> Client.builder()  </span><br><span class="line">            .auth(auth2)  </span><br><span class="line">            .routeUrl(routeUrl)  </span><br><span class="line">            .messageListener((client, message) -&gt; client2Receive.set(message))  </span><br><span class="line">            .build();  </span><br><span class="line">    TimeUnit.SECONDS.sleep(<span class="number">3</span>);  </span><br><span class="line">    ClientState.<span class="type">State</span> <span class="variable">state2</span> <span class="operator">=</span> client2.getState();  </span><br><span class="line">    Awaitility.await().atMost(<span class="number">10</span>, TimeUnit.SECONDS)  </span><br><span class="line">            .untilAsserted(() -&gt; Assertions.assertEquals(ClientState.State.Ready, state2));  </span><br><span class="line">  </span><br><span class="line">    Optional&lt;CIMServerResVO&gt; serverInfo2 = client2.getServerInfo();  </span><br><span class="line">    Assertions.assertTrue(serverInfo2.isPresent());  </span><br><span class="line">    System.out.println(<span class="string">&quot;client2 serverInfo = &quot;</span> + serverInfo2.get());  </span><br><span class="line">  </span><br><span class="line">    <span class="comment">// send msg  </span></span><br><span class="line">    <span class="type">String</span> <span class="variable">msg</span> <span class="operator">=</span> <span class="string">&quot;hello&quot;</span>;  </span><br><span class="line">    client1.sendGroup(msg);  </span><br><span class="line">    Awaitility.await()  </span><br><span class="line">            .untilAsserted(() -&gt; Assertions.assertEquals(String.format(<span class="string">&quot;cj:%s&quot;</span>, msg), client2Receive.get()));  </span><br><span class="line">    client2Receive.set(<span class="string">&quot;&quot;</span>);  </span><br><span class="line">  </span><br><span class="line">  </span><br><span class="line">    System.out.println(<span class="string">&quot;ready to restart server&quot;</span>);  </span><br><span class="line">    TimeUnit.SECONDS.sleep(<span class="number">3</span>);  </span><br><span class="line">    Optional&lt;CIMServerResVO&gt; serverInfo = client1.getServerInfo();  </span><br><span class="line">    Assertions.assertTrue(serverInfo.isPresent());  </span><br><span class="line">    System.out.println(<span class="string">&quot;server info = &quot;</span> + serverInfo.get());  </span><br><span class="line">  </span><br><span class="line">    <span class="built_in">super</span>.stopServer(serverInfo.get().getCimServerPort());  </span><br><span class="line">    System.out.println(<span class="string">&quot;stop server success! &quot;</span> + serverInfo.get());  </span><br><span class="line">  </span><br><span class="line">  </span><br><span class="line">    <span class="comment">// Waiting server stopped, and client reconnect.  </span></span><br><span class="line">    TimeUnit.SECONDS.sleep(<span class="number">30</span>);  </span><br><span class="line">    System.out.println(<span class="string">&quot;reconnect state: &quot;</span> + client1.getState());  </span><br><span class="line">    Awaitility.await().atMost(<span class="number">15</span>, TimeUnit.SECONDS)  </span><br><span class="line">            .untilAsserted(() -&gt; Assertions.assertEquals(ClientState.State.Ready, state));  </span><br><span class="line">    serverInfo = client1.getServerInfo();  </span><br><span class="line">    Assertions.assertTrue(serverInfo.isPresent());  </span><br><span class="line">    System.out.println(<span class="string">&quot;client1 reconnect server info = &quot;</span> + serverInfo.get());  </span><br><span class="line">  </span><br><span class="line">    <span class="comment">// Send message again.  </span></span><br><span class="line">    log.info(<span class="string">&quot;send message again, client2Receive = &#123;&#125;&quot;</span>, client2Receive.get());  </span><br><span class="line">    client1.sendGroup(msg);  </span><br><span class="line">    Awaitility.await()  </span><br><span class="line">            .untilAsserted(() -&gt; Assertions.assertEquals(String.format(<span class="string">&quot;cj:%s&quot;</span>, msg), client2Receive.get()));  </span><br><span class="line">    <span class="built_in">super</span>.stopTwoServer();  </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>比如在这里编写了一个客户端重连的单测，代码有点长，但它的主要流程如下：</p><ul><li>启动两个 Server：Server1，Server2</li><li>启动 Route</li><li>在启动两个 Client 发送消息<ul><li>校验消息发送是否成功</li></ul></li><li><strong>停止 Client1 连接的 Server</strong></li><li><strong>等待 Client 自动重连到另一个 Server</strong></li><li>再次发送消息<ul><li>校验消息发送是否成功</li></ul></li></ul><p>这样就可以验证在服务端 Server 宕机后整个服务是否可用，消息收发是否正常。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">startTwoServer</span><span class="params">()</span> &#123;  </span><br><span class="line">    <span class="keyword">if</span> (!zooKeeperContainer.isRunning())&#123;  </span><br><span class="line">        zooKeeperContainer.start();  </span><br><span class="line">    &#125;    zookeeperAddr = String.format(<span class="string">&quot;%s:%d&quot;</span>, zooKeeperContainer.getHost(), zooKeeperContainer.getMappedPort(ZooKeeperContainer.DEFAULT_CLIENT_PORT));  </span><br><span class="line">    <span class="type">SpringApplication</span> <span class="variable">server</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">SpringApplication</span>(CIMServerApplication.class);  </span><br><span class="line">    String[] args1 = <span class="keyword">new</span> <span class="title class_">String</span>[]&#123;  </span><br><span class="line">            <span class="string">&quot;--cim.server.port=11211&quot;</span>,  </span><br><span class="line">            <span class="string">&quot;--server.port=8081&quot;</span>,  </span><br><span class="line">            <span class="string">&quot;--app.zk.addr=&quot;</span> + zookeeperAddr,  </span><br><span class="line">    &#125;;    <span class="type">ConfigurableApplicationContext</span> <span class="variable">run1</span> <span class="operator">=</span> server.run(args1);  </span><br><span class="line">    runMap.put(Integer.parseInt(<span class="string">&quot;11211&quot;</span>), run1);  </span><br><span class="line">  </span><br><span class="line">  </span><br><span class="line">    <span class="type">SpringApplication</span> <span class="variable">server2</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">SpringApplication</span>(CIMServerApplication.class);  </span><br><span class="line">    String[] args2 = <span class="keyword">new</span> <span class="title class_">String</span>[]&#123;  </span><br><span class="line">            <span class="string">&quot;--cim.server.port=11212&quot;</span>,  </span><br><span class="line">            <span class="string">&quot;--server.port=8082&quot;</span>,  </span><br><span class="line">            <span class="string">&quot;--app.zk.addr=&quot;</span> + zookeeperAddr,  </span><br><span class="line">    &#125;;    <span class="type">ConfigurableApplicationContext</span> <span class="variable">run2</span> <span class="operator">=</span> server2.run(args2);  </span><br><span class="line">    runMap.put(Integer.parseInt(<span class="string">&quot;11212&quot;</span>), run2);  </span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">stopServer</span><span class="params">(Integer port)</span> &#123;  </span><br><span class="line">    runMap.get(port).close();  </span><br><span class="line">    runMap.remove(port);  </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这里的启动两个 Server 就是创建了两个 Server 应用，然后保存好端口和应用之间的映射关系。</p><p>这样就可以根据客户端连接的 Server 信息指定停止哪一个 Server，更方便做测试。</p><p>这次重启 <a href="https://github.com/crossoverJie/cim">cim</a> 的维护后会尽量维护下去，即便更新时间慢一点。</p><p>后续还会加上消息 ack、离线消息等之前呼声很高的功能，感兴趣的完全可以一起参与。</p><p>源码地址：<br><a href="https://github.com/crossoverJie/cim">https://github.com/crossoverJie/cim</a></p>]]></content>
    
    
    <summary type="html">&lt;p&gt;&lt;img src=&quot;https://s2.loli.net/2024/10/13/PW1J2bXx39cfpnC.png&quot;&gt;&lt;/p&gt;
&lt;h1 id=&quot;SDK-设计&quot;&gt;&lt;a href=&quot;#SDK-设计&quot; class=&quot;headerlink&quot; title=&quot;SDK 设计&quot;&gt;&lt;/a&gt;SDK 设计&lt;/h1&gt;&lt;p&gt;&lt;img src=&quot;https://s2.loli.net/2024/09/17/Ck6AfdGOPISDrVN.png&quot;&gt;&lt;/p&gt;
&lt;p&gt;在之前提到了 &lt;a href=&quot;https://github.com/crossoverJie/cim&quot;&gt;cim&lt;/a&gt; 在做集成测试的时候遇到的问题，需要提供一个 SDK 来解决，于是我花了一些时间编写了 SDK，同时也将 cim-client 重构了。&lt;/p&gt;</summary>
    
    
    
    <category term="cim" scheme="http://crossoverjie.top/categories/cim/"/>
    
    
    <category term="cim" scheme="http://crossoverjie.top/tags/cim/"/>
    
  </entry>
  
  <entry>
    <title>StarRocks 开发环境搭建踩坑指北</title>
    <link href="http://crossoverjie.top/2024/10/09/ob/StarRocks-dev-env-build/"/>
    <id>http://crossoverjie.top/2024/10/09/ob/StarRocks-dev-env-build/</id>
    <published>2024-10-09T09:20:19.000Z</published>
    <updated>2024-10-08T14:21:33.221Z</updated>
    
    <content type="html"><![CDATA[<h1 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h1><p>最近这段时间在处理一个 <code>StarRocks</code> 的关于物化视图优化的一个问题，在此之前其实我也没有接触过 <code>StarRocks</code> 这类主要处理数据分析的数据库，就更别提在这上面做优化了。</p><p>在解决问题之前我先花了一两天时间熟悉了一下 <code>StarRocks</code> 的一些概念和使用方法，然后又花了一些时间搭建环境然后复现了该问题。</p><p>之后便开始阅读源码，大概知道了相关代码的执行流程，但即便是反复阅读了多次代码也没有找到具体出现问题的地方。</p><p>所以便考虑在本地 Debug 源码，最终调试半天之后知道了问题所以，也做了相关修改，给社区提交了 PR，目前还在推进过程中。</p><span id="more"></span><h1 id="环境搭建"><a href="#环境搭建" class="headerlink" title="环境搭建"></a>环境搭建</h1><p>这里比较麻烦的是如何在本地 debug 代码。<br><img src="https://s2.loli.net/2024/09/16/uqKGRIJXZB3pbMy.png"><br>根据官方的架构图会发现 <code>StarRocks</code> 主要分为两个部分：</p><ul><li>FE：也就是常说的前端部分，主要负责元数据管理和构建执行计划。</li><li>BE：后端存储部分，执行查询计划并存储数据。</li></ul><p>其中 FE 是 Java 写的，而存储的 BE 则是 C++ 写的，我这次需要修改的是 FE 前端的部分，所以本篇文章主要讨论的是 FE 相关的内容。</p><p>好在社区已经有关于如何编译和构建源码的教程，这里我列举一些重点，FE 首先需要安装以下一些工具：</p><ul><li>Thrift</li><li>Protobuf</li><li>Python3</li><li>JDK8+</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">brew install alberttwong/thrift/thrift@0.13</span><br><span class="line">$ thrift -version  </span><br><span class="line">Thrift version 0.13.0</span><br><span class="line"></span><br><span class="line">brew install protobuf</span><br></pre></td></tr></table></figure><p>以上默认是在  Mac 平台上安装的流程，所以全程使用 <code>brew</code> 最方便了，如果是其他平台也是同理，只要安装好这些工具即可。</p><p>紧接着便是编译 FE，我们需要先下载源码，然后进入 FE 的目录：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">git <span class="built_in">clone</span> https://github.com/StarRocks/starrocks.git</span><br><span class="line"><span class="built_in">cd</span> fe</span><br><span class="line">mvn install -DskipTests</span><br></pre></td></tr></table></figure><p>然后直接使用 <code>maven</code> 编译安装即可。</p><p>这里需要注意⚠️，因为编译过程中需要使用 <code>Python3</code> 来执行一些构建任务，新版本的 Mac 都是内置 <code>Python3</code> 的，但如果是老版本的 <code>Mac</code> 内置的则是 Python2。</p><p>这时就需要我们将 Python3 的命令手动在构建任务里指定一下：</p><p><img src="https://s2.loli.net/2024/09/16/ouLglsXJEm1TpSh.png"></p><p>比如我这里的 Python3  命令为 <code>python3</code></p><p>我们需要在 <code>fe/fe-core/pom.xml</code> 目录里修改下 Python 的命令名称：<br><img src="https://s2.loli.net/2024/09/16/tcfwoilyDdTQpxX.png"></p><p>修改之后再 <code>mvn install</code> 编译一次，如果一切顺利的话便会编译成功。</p><h2 id="搭建本地集群"><a href="#搭建本地集群" class="headerlink" title="搭建本地集群"></a>搭建本地集群</h2><h3 id="启动-FE"><a href="#启动-FE" class="headerlink" title="启动 FE"></a>启动 FE</h3><p>我的最终目的是可以在本地 IDEA 中启动 FE 然后再配合启动一个 BE，这样就可以在 IDEA 中调试 FE 的源码了。</p><p>在启动 FE 之前还需要创建一些目录：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cp</span> -r conf fe/conf</span><br><span class="line"><span class="built_in">cp</span> -r bin fe/bin</span><br><span class="line"><span class="built_in">cp</span> -r webroot fe/webroot</span><br><span class="line"></span><br><span class="line"><span class="built_in">cd</span> fe  </span><br><span class="line"><span class="built_in">mkdir</span> <span class="built_in">log</span>  </span><br><span class="line"><span class="built_in">mkdir</span> meta</span><br></pre></td></tr></table></figure><p>主要就是要在 FE 的目录下创建配置文件、执行脚本、日志、元数据等目录。</p><p>接着便可以打开 <code>com.starrocks.StarRocksFE</code> 类在 IDEA 中运行了，在启动之前还需要配置一下环境变量：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 修改为自己的目录</span></span><br><span class="line"><span class="built_in">export</span> PID_DIR=/Users/smith/Code/starrocks/fe/bin</span><br><span class="line"><span class="built_in">export</span> STARROCKS_HOME=/Users/smith/Code/starrocks/fe</span><br><span class="line"><span class="built_in">export</span> LOG_DIR=/Users/smith/Code/starrocks/fe/log</span><br></pre></td></tr></table></figure><p>同时需要配置下 <code>fe.conf</code> 中的 <code>priority_networks</code> 网络配置：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">priority_networks = 10.10.10.0/24</span><br></pre></td></tr></table></figure><p>这个 IP 得是<strong>宿主机的 IP</strong>，后续我们使用 docker 启动 BE 的时候也需要用到。</p><p><img src="https://s2.loli.net/2024/09/16/Lgrl4YSaD1GdzIZ.png"></p><p>如果启动失败，可以在日志目录下查看日志：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">2024-09-16 21:21:59.942+08:00 ERROR (main|1) [NodeMgr.getCheckedSelfHostPort():642] edit_log_port 9010 is already in use. will exit.</span><br></pre></td></tr></table></figure><p>碰到这个异常：提示端口被占用，那可以尝试关闭代理之后再试试。</p><p>启动成功后我们便可以使用 <code>MySQL</code> 兼容的客户端进行连接了，这里我使用的是 <code>tableplus</code>:<br><img src="https://s2.loli.net/2024/09/16/8XMI1DdjGkOKVPy.png"></p><p>然后我们使用以下 sql  可以查询 fe 的节点状态：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SHOW</span> PROC <span class="string">&#x27;/frontends&#x27;</span>;</span><br></pre></td></tr></table></figure><p><img src="https://s2.loli.net/2024/09/16/Jg5TIMtpKoknq4Z.png"></p><p>看到类似的输出则代表启动成功了。</p><h3 id="启动-BE"><a href="#启动-BE" class="headerlink" title="启动 BE"></a>启动 BE</h3><p>之后我们便可以使用 Docker 来启动 BE 了，之所以用 docker 启动，是因为 BE 是 C++ 编写的，想要在 Mac 上运行比较麻烦，最好是得有一台 <code>Ubuntu22</code> 的虚拟机。</p><p>如果我们不需要调试 BE 的话，只使用 docker 启动是再合适不过了。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker run -p 9060:9060 -p 8040:8040 -p 9050:9050 -p 8060:8060 -p 9070:9070 -itd --<span class="built_in">rm</span> --name be -e <span class="string">&quot;TZ=Asia/Shanghai&quot;</span> starrocks/be-ubuntu</span><br></pre></td></tr></table></figure><p>我们需要将 FE 需要连接 BE 的端口暴露出来，启动成功后该镜像并不会直接启动 BE，我们需要进入容器手动启动。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker <span class="built_in">exec</span> -it be bash</span><br></pre></td></tr></table></figure><p>在启动之前我们依然需要修改下 be.conf 中的 <code>priority_networks</code> 配置：</p><p><img src="https://s2.loli.net/2024/09/16/mcFCo24Kyxui8gt.png"><br>修改为和 fe.conf 中相同的配置。</p><p>之后使用以下命令启动 be:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/start_be.sh --daemon</span><br></pre></td></tr></table></figure><p>启动日志我们可以在 logs 目录中查看。</p><h3 id="绑定-FE-和-BE"><a href="#绑定-FE-和-BE" class="headerlink" title="绑定 FE 和 BE"></a>绑定 FE 和 BE</h3><p>接下来还有最后一步就是将 FE 和 BE 绑定在一起。</p><p>我们在 fe 中执行以下 sql：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">ALTER</span> <span class="keyword">SYSTEM</span> <span class="keyword">ADD</span> BACKEND &quot;127.0.0.1:9050&quot;;</span><br></pre></td></tr></table></figure><p>手动添加一个节点，之后再使用：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SHOW</span> PROC <span class="string">&#x27;/backends&#x27;</span>;</span><br></pre></td></tr></table></figure><p>可以查询到 BE 的节点状态：</p><p><img src="https://s2.loli.net/2024/09/16/YMCXQDoch3NlA1L.png"></p><p>如果出现以下结果代表连接成功，这样我们就可以创建数据库和表了。</p><h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>这部分内容（本地 FE 联结 docker 里的 FE）官方文档并没有提及，也是我踩了不少坑、同时还咨询了一些大佬才全部调试成功。</p><p>还有一点需要注意的事：如果我们网络环境发生了变化，比如从家里的 Wi-Fi 切换到了公司的，需要手动删除下 <code>FE/meta</code> 下的所有文件再次启动，BE 则是需要重启一下容器。</p><p>参考链接：</p><ul><li><a href="https://docs.starrocks.io/zh/docs/developers/development-environment/IDEA/">https://docs.starrocks.io/zh/docs/developers/development-environment/IDEA/</a></li><li><a href="https://docs.starrocks.io/zh/docs/deployment/deploy_manually/#%E7%AC%AC%E5%9B%9B%E6%AD%A5%E6%90%AD%E5%BB%BA%E9%9B%86%E7%BE%A4">https://docs.starrocks.io/zh/docs/deployment/deploy_manually/#%E7%AC%AC%E5%9B%9B%E6%AD%A5%E6%90%AD%E5%BB%BA%E9%9B%86%E7%BE%A4</a></li></ul>]]></content>
    
    
    <summary type="html">&lt;h1 id=&quot;背景&quot;&gt;&lt;a href=&quot;#背景&quot; class=&quot;headerlink&quot; title=&quot;背景&quot;&gt;&lt;/a&gt;背景&lt;/h1&gt;&lt;p&gt;最近这段时间在处理一个 &lt;code&gt;StarRocks&lt;/code&gt; 的关于物化视图优化的一个问题，在此之前其实我也没有接触过 &lt;code&gt;StarRocks&lt;/code&gt; 这类主要处理数据分析的数据库，就更别提在这上面做优化了。&lt;/p&gt;
&lt;p&gt;在解决问题之前我先花了一两天时间熟悉了一下 &lt;code&gt;StarRocks&lt;/code&gt; 的一些概念和使用方法，然后又花了一些时间搭建环境然后复现了该问题。&lt;/p&gt;
&lt;p&gt;之后便开始阅读源码，大概知道了相关代码的执行流程，但即便是反复阅读了多次代码也没有找到具体出现问题的地方。&lt;/p&gt;
&lt;p&gt;所以便考虑在本地 Debug 源码，最终调试半天之后知道了问题所以，也做了相关修改，给社区提交了 PR，目前还在推进过程中。&lt;/p&gt;</summary>
    
    
    
    <category term="StarRocks" scheme="http://crossoverjie.top/categories/StarRocks/"/>
    
    
    <category term="StarRocks" scheme="http://crossoverjie.top/tags/StarRocks/"/>
    
  </entry>
  
  <entry>
    <title>🤳如何为复杂的 Java 应用编写集成测试</title>
    <link href="http://crossoverjie.top/2024/09/29/ob/%F0%9F%A4%B3cim-support-integration-test/"/>
    <id>http://crossoverjie.top/2024/09/29/ob/%F0%9F%A4%B3cim-support-integration-test/</id>
    <published>2024-09-29T11:16:06.000Z</published>
    <updated>2024-09-29T01:37:17.532Z</updated>
    
    <content type="html"><![CDATA[<p>最近有时间又把以前开源的 <a href="https://github.com/crossoverJie/cim">IM 消息系统</a>捡起来继续开发了（确实这些年经常有朋友催更）。</p><blockquote><p>没错，确实是这些年，因为上次发版还是再 2019 年的八月份。</p></blockquote><p>这段时间比较重大的更新就是把<a href="https://github.com/crossoverJie/cim/pull/140">元数据中心</a>抽离出来了，以前是和 zookeeper 的代码强耦合在一起的，重构之后可以有多种实现了。</p><span id="more"></span><p>今后甚至可以提供一个 jar 包就可以把后端服务全部启动起来用于体验，此时就可以使用一个简单的基于内存的注册中心。</p><p>除此之外做的更多的就是新增了一个集成测试的模块，没有完善的集成测试功能在合并代码的时候都要小心翼翼，基本的功能需求都没法保证。</p><p>加上这几年我也接触了不少优秀的开源项目（比如 Pulsar、OpenTelemetry、HertzBeat 等），他们都有完整的代码合并流程；首先第一点就得把测试流水线跑通过。</p><p>这一点在 OpenTelemetry 社区更为严格：</p><p><img src="https://s2.loli.net/2024/09/04/wlaPtbJNux5vc9n.png"></p><blockquote><p>他们的构建测试流程非常多，包括单元测试、集成测试、代码风格、多版本兼容等。</p></blockquote><p>所以在结合了这些优秀项目的经验后我也为 cim 项目新增相关的模块 <a href="https://github.com/crossoverJie/cim/pull/144">cim-integration-test</a>，同时也在 github 上配置了相关的 action，最终的效果如下：</p><p><img src="https://s2.loli.net/2024/09/04/p9tLcvPTlMBIVq4.png"><br><img src="https://s2.loli.net/2024/09/04/Rxw5F8kNWT1pDO7.png"></p><p>在 <code>“Build with Maven”</code> 阶段触发单元测试和集成测试，最终会把测试结果上传到 Codecov，然后会在 PR 的评论区输出测试报告。<br><img src="https://s2.loli.net/2024/09/04/zmPHB16ryCtGoEM.png"></p><p>相关的 action 配置如下：</p><p><img src="https://s2.loli.net/2024/09/05/mteK1Yj43Z7gIrR.png"></p><p>就是配置了几个 Job，重点是这里的：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mvn -B package --file pom.xml</span><br></pre></td></tr></table></figure><p>它会编译并运行项目下面的所有 test 代码。</p><h1 id="cim-integration-test-模块"><a href="#cim-integration-test-模块" class="headerlink" title="cim-integration-test 模块"></a>cim-integration-test 模块</h1><p>为了方便进行集成测试，我新增了 <code>cim-integration-test</code> 这个模块，这里面没有任何源码，只有测试相关的代码。</p><p><img src="https://s2.loli.net/2024/09/05/RfK8FVrL916D7cI.png"></p><p>类的继承关系图如下：</p><p><img src="https://s2.loli.net/2024/09/05/75U9vbkPZOgqrRx.png"></p><p>因为我们做集成测试需要把 cim 所依赖的服务都启动起来，目前主要由以下几个服务：</p><ul><li>cim-server: cim 的服务端</li><li>cim-route: 路由服务</li><li>cim-client: 客户端</li></ul><p>而 route 服务是依赖于 server 服务，所以 route 继承了 server，client 则是需要 route 和 server 都启动，所以它需要继承 route。</p><h2 id="集成-test-container"><a href="#集成-test-container" class="headerlink" title="集成 test container"></a>集成 test container</h2><p>先来看看 server 的测试实现：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">abstract</span> <span class="keyword">class</span> <span class="title class_">AbstractServerBaseTest</span> &#123;  </span><br><span class="line">  </span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="type">DockerImageName</span> <span class="variable">DEFAULT_IMAGE_NAME</span> <span class="operator">=</span> DockerImageName  </span><br><span class="line">            .parse(<span class="string">&quot;zookeeper&quot;</span>)  </span><br><span class="line">            .withTag(<span class="string">&quot;3.9.2&quot;</span>);  </span><br><span class="line">  </span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="type">Duration</span> <span class="variable">DEFAULT_STARTUP_TIMEOUT</span> <span class="operator">=</span> Duration.ofSeconds(<span class="number">60</span>);  </span><br><span class="line">  </span><br><span class="line">    <span class="meta">@Container</span>  </span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">final</span> <span class="type">ZooKeeperContainer</span>  </span><br><span class="line">            <span class="variable">zooKeeperContainer</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">ZooKeeperContainer</span>(DEFAULT_IMAGE_NAME, DEFAULT_STARTUP_TIMEOUT);  </span><br><span class="line">  </span><br><span class="line">    <span class="meta">@Getter</span>  </span><br><span class="line">    <span class="keyword">private</span> String zookeeperAddr;  </span><br><span class="line">  </span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">startServer</span><span class="params">()</span> &#123;  </span><br><span class="line">        zooKeeperContainer.start();  </span><br><span class="line">        zookeeperAddr = String.format(<span class="string">&quot;%s:%d&quot;</span>, zooKeeperContainer.getHost(), zooKeeperContainer.getMappedPort(ZooKeeperContainer.DEFAULT_CLIENT_PORT));  </span><br><span class="line">        <span class="type">SpringApplication</span> <span class="variable">server</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">SpringApplication</span>(CIMServerApplication.class);  </span><br><span class="line">        server.run(<span class="string">&quot;--app.zk.addr=&quot;</span> + zookeeperAddr);  </span><br><span class="line">    &#125;  </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>因为 <code>server</code> 是需要依赖 <code>zookeeper</code> 作为元数据中心，所以在启动之前需要先把 zookeeper 启动起来。</p><p>此时就需要使用 <a href="https://testcontainers.com/">testcontainer</a> 来做支持了，使用它可以在单测的过程中使用 docker 启动任意一个服务，这样在 CI 中做集成测试就很简单了。</p><p><img src="https://s2.loli.net/2024/09/06/X3vzp5qd7tbAIHB.png"></p><p>我们日常使用的大部分中间件都是支持的，使用起来也很简单。</p><p>先添加相关的依赖：</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependencies</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.postgresql<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>postgresql<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">version</span>&gt;</span>42.7.3<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>ch.qos.logback<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>logback-classic<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">version</span>&gt;</span>1.5.6<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.junit.jupiter<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>junit-jupiter<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">version</span>&gt;</span>5.10.2<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">scope</span>&gt;</span>test<span class="tag">&lt;/<span class="name">scope</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependencies</span>&gt;</span></span><br></pre></td></tr></table></figure><p>然后在选择我们需要依赖的服务，比如是 <code>PostgreSQL</code>：</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.testcontainers<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>postgresql<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>1.19.8<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">scope</span>&gt;</span>test<span class="tag">&lt;/<span class="name">scope</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure><p>然后在测试代码中启动相关的服务</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">CustomerServiceTest</span> &#123;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">static</span> PostgreSQLContainer&lt;?&gt; postgres = <span class="keyword">new</span> <span class="title class_">PostgreSQLContainer</span>&lt;&gt;(</span><br><span class="line">    <span class="string">&quot;postgres:16-alpine&quot;</span></span><br><span class="line">  );</span><br><span class="line"></span><br><span class="line">  CustomerService customerService;</span><br><span class="line"></span><br><span class="line">  <span class="meta">@BeforeAll</span></span><br><span class="line">  <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">beforeAll</span><span class="params">()</span> &#123;</span><br><span class="line">    postgres.start();</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="meta">@AfterAll</span></span><br><span class="line">  <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">afterAll</span><span class="params">()</span> &#123;</span><br><span class="line">    postgres.stop();</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="meta">@BeforeEach</span></span><br><span class="line">  <span class="keyword">void</span> <span class="title function_">setUp</span><span class="params">()</span> &#123;</span><br><span class="line">    <span class="type">DBConnectionProvider</span> <span class="variable">connectionProvider</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">DBConnectionProvider</span>(</span><br><span class="line">      postgres.getJdbcUrl(),</span><br><span class="line">      postgres.getUsername(),</span><br><span class="line">      postgres.getPassword()</span><br><span class="line">    );</span><br><span class="line">    customerService = <span class="keyword">new</span> <span class="title class_">CustomerService</span>(connectionProvider);</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure><p>通常情况下我们都是需要获取这些中间件的链接，比如 IP 端口啥的。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">org.testcontainers.containers.ContainerState#getHost</span><br><span class="line">org.testcontainers.containers.ContainerState#getMappedPort</span><br></pre></td></tr></table></figure><p>通常是通过这两个函数来获取对应的 IP 和端口。</p><h1 id="集成"><a href="#集成" class="headerlink" title="集成"></a>集成</h1><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Container</span>  </span><br><span class="line"><span class="type">RedisContainer</span> <span class="variable">redis</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">RedisContainer</span>(DockerImageName.parse(<span class="string">&quot;redis:7.4.0&quot;</span>));  </span><br><span class="line">  </span><br><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">startRoute</span><span class="params">()</span> &#123;  </span><br><span class="line">    redis.start();  </span><br><span class="line">    <span class="type">SpringApplication</span> <span class="variable">route</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">SpringApplication</span>(RouteApplication.class);  </span><br><span class="line">    String[] args = <span class="keyword">new</span> <span class="title class_">String</span>[]&#123;  </span><br><span class="line">            <span class="string">&quot;--spring.data.redis.host=&quot;</span> + redis.getHost(),  </span><br><span class="line">            <span class="string">&quot;--spring.data.redis.port=&quot;</span> + redis.getMappedPort(<span class="number">6379</span>),  </span><br><span class="line">            <span class="string">&quot;--app.zk.addr=&quot;</span> + <span class="built_in">super</span>.getZookeeperAddr(),  </span><br><span class="line">    &#125;;    </span><br><span class="line">    route.setAdditionalProfiles(<span class="string">&quot;route&quot;</span>);  </span><br><span class="line">    route.run(args);  </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>对于 route 来说不但需要 <code>zookeeper</code> 还需要 <code>Redis</code> 来存放用户的路由关系，此时就还需要运行一个 Redis 的容器，使用方法同理。</p><p>最后就需要以 <code>springboot</code> 的方式将这两个应用启动起来，我们直接创建一个 <code>SpringApplication</code> 对象，然后将需要修改的参数通过 <code>--varname=value</code> 的形式将数据传递进去。</p><p>还可以通过 <code>setAdditionalProfiles()</code> 函数指定当前应用运行的 profile，这样我们就可以在测试目录使用对应的配置文件了。</p><p><img src="https://s2.loli.net/2024/09/06/ySK2akYOIAPJqUH.png" alt="image.png"></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">route.setAdditionalProfiles(<span class="string">&quot;route&quot;</span>);  </span><br></pre></td></tr></table></figure><p>比如我们这里设置为 route 就可以使用 <code>application-route.yaml</code> 作为 route 的配置文件启动，就不用每个参数都通过 <code>--</code> 传递了。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title function_">login</span><span class="params">(String userName, <span class="type">int</span> port)</span> <span class="keyword">throws</span> Exception &#123;  </span><br><span class="line">    <span class="type">Long</span> <span class="variable">userId</span> <span class="operator">=</span> <span class="built_in">super</span>.registerAccount(userName);  </span><br><span class="line">    <span class="type">SpringApplication</span> <span class="variable">client</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">SpringApplication</span>(CIMClientApplication.class);  </span><br><span class="line">    client.setAdditionalProfiles(<span class="string">&quot;client&quot;</span>);  </span><br><span class="line">    String[] args = <span class="keyword">new</span> <span class="title class_">String</span>[]&#123;  </span><br><span class="line">            <span class="string">&quot;--server.port=&quot;</span> + port,  </span><br><span class="line">            <span class="string">&quot;--cim.user.id=&quot;</span> + userId,  </span><br><span class="line">            <span class="string">&quot;--cim.user.userName=&quot;</span> + userName  </span><br><span class="line">    &#125;;  </span><br><span class="line">    client.run(args);  </span><br><span class="line">&#125;  </span><br><span class="line">  </span><br><span class="line"><span class="meta">@Test</span>  </span><br><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">olu</span><span class="params">()</span> <span class="keyword">throws</span> Exception &#123;  </span><br><span class="line">    <span class="built_in">super</span>.startServer();  </span><br><span class="line">    <span class="built_in">super</span>.startRoute();  </span><br><span class="line">    <span class="built_in">this</span>.login(<span class="string">&quot;crossoverJie&quot;</span>, <span class="number">8082</span>);  </span><br><span class="line">    <span class="built_in">this</span>.login(<span class="string">&quot;cj&quot;</span>, <span class="number">8182</span>);  </span><br><span class="line">    <span class="type">MsgHandle</span> <span class="variable">msgHandle</span> <span class="operator">=</span> SpringBeanFactory.getBean(MsgHandle.class);  </span><br><span class="line">    msgHandle.innerCommand(<span class="string">&quot;:olu&quot;</span>);  </span><br><span class="line">    msgHandle.sendMsg(<span class="string">&quot;hello&quot;</span>);  </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>我们真正要测试的其实是客户端的功能，只要客户端功能正常，说明 server 和 route 也是正常的。</p><p>比如这里的 <code>olu(oline user)</code> 的测试流程是：</p><ul><li>启动 server 和 route</li><li>登录注册两个账号</li><li>查询出所有用户</li><li>发送消息</li></ul><p>最终的测试结果如下，符合预期。</p><p><img src="https://s2.loli.net/2024/09/06/uX7BrNwC8iOHqSQ.png" alt="image.png"></p><h1 id="碰到的问题"><a href="#碰到的问题" class="headerlink" title="碰到的问题"></a>碰到的问题</h1><h2 id="应用分层"><a href="#应用分层" class="headerlink" title="应用分层"></a>应用分层</h2><p>不知道大家注意到刚才测试代码存在的问题没有，主要就是没法断言。</p><p>因为客户端、route、server 都是以一个应用的维度去运行的，没法获取到一些关键指标。</p><p>比如输出在线用户，当客户端作为一个应用时，在线用户就是直接打印在了终端，而没有直接暴露一个接口返回在线数据；收发消息也是同理。</p><p>其实在应用内部这些都是有接口的，但是作为一个整体的 <code>springboot</code> 应用就没有提供这些能力了。</p><p>本质上的问题就是这里应该有一个 client-sdk 的模块，client 也是基于这个 sdk 实现的，这样就可以更好的测试相关的功能了。</p><p>之后就准备把 sdk 单独抽离一个模块，这样可以方便基于这个 sdk 实现不同的交互，甚至做一个 UI 界面都是可以的。</p><h2 id="编译失败"><a href="#编译失败" class="headerlink" title="编译失败"></a>编译失败</h2><p>还有一个问题就是我是直接将 <code>client/route/server</code> 的依赖集成到 <code>integration-test</code> 模块中：</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span>  </span><br><span class="line">  <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>com.crossoverjie.netty<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span>  </span><br><span class="line">  <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>cim-server<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span>  </span><br><span class="line">  <span class="tag">&lt;<span class="name">version</span>&gt;</span>$&#123;project.version&#125;<span class="tag">&lt;/<span class="name">version</span>&gt;</span>  </span><br><span class="line">  <span class="tag">&lt;<span class="name">scope</span>&gt;</span>compile<span class="tag">&lt;/<span class="name">scope</span>&gt;</span>  </span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span>  </span><br><span class="line">  </span><br><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span>  </span><br><span class="line">  <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>com.crossoverjie.netty<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span>  </span><br><span class="line">  <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>cim-forward-route<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span>  </span><br><span class="line">  <span class="tag">&lt;<span class="name">version</span>&gt;</span>$&#123;project.version&#125;<span class="tag">&lt;/<span class="name">version</span>&gt;</span>  </span><br><span class="line">  <span class="tag">&lt;<span class="name">scope</span>&gt;</span>compile<span class="tag">&lt;/<span class="name">scope</span>&gt;</span>  </span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span>  </span><br><span class="line">  </span><br><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span>  </span><br><span class="line">  <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>com.crossoverjie.netty<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span>  </span><br><span class="line">  <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>cim-client<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span>  </span><br><span class="line">  <span class="tag">&lt;<span class="name">version</span>&gt;</span>$&#123;project.version&#125;<span class="tag">&lt;/<span class="name">version</span>&gt;</span>  </span><br><span class="line">  <span class="tag">&lt;<span class="name">scope</span>&gt;</span>compile<span class="tag">&lt;/<span class="name">scope</span>&gt;</span>  </span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure><p>在 IDEA 里直接点击测试按钮是可以直接运行这里的测试用例的，但是想通过 <code>mvn test</code> 时就遇到了问题。</p><p><img src="https://s2.loli.net/2024/09/06/DFy6otpPvjar4JM.png" alt="image.png"></p><p>会在编译期间就是失败了，我排查了很久最终发现是因为这三个模块应用使用了springboot 的构建插件：</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">plugin</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.springframework.boot<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spring-boot-maven-plugin<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">executions</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">execution</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">goals</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">goal</span>&gt;</span>repackage<span class="tag">&lt;/<span class="name">goal</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">goals</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">execution</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">executions</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">plugin</span>&gt;</span></span><br></pre></td></tr></table></figure><p>这几个模块最终会被打包成一个 springboot 的 jar 包，从而导致 integration-test 在编译时无法加载进来从而使用里面的类。</p><p>暂时没有找到好的解决办法，我就只有把这几个插件先去掉，需要打包时再手动指定插件。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mvn clean package spring-boot:repackage -DskipTests=true</span><br></pre></td></tr></table></figure><p>其实这里的本质问题也是没有分层的结果，最好还是依赖 <code>route</code> 和 <code>server</code> 的 SDK 进行测试。</p><p>现在因为有了测试的 CI 也欢迎大家来做贡献，可以看看这里的 <code>help want</code>，有一些简单易上手可以先搞起来。</p><p><img src="https://s2.loli.net/2024/09/06/kmgfrIxdhGXib9L.png"></p><p><a href="https://github.com/crossoverJie/cim/issues/135">https://github.com/crossoverJie/cim/issues/135</a></p><p>参考链接：</p><ul><li><a href="https://github.com/crossoverJie/cim/pull/140">https://github.com/crossoverJie/cim/pull/140</a></li><li><a href="https://github.com/crossoverJie/cim/pull/144">https://github.com/crossoverJie/cim/pull/144</a></li></ul>]]></content>
    
    
    <summary type="html">&lt;p&gt;最近有时间又把以前开源的 &lt;a href=&quot;https://github.com/crossoverJie/cim&quot;&gt;IM 消息系统&lt;/a&gt;捡起来继续开发了（确实这些年经常有朋友催更）。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;没错，确实是这些年，因为上次发版还是再 2019 年的八月份。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;这段时间比较重大的更新就是把&lt;a href=&quot;https://github.com/crossoverJie/cim/pull/140&quot;&gt;元数据中心&lt;/a&gt;抽离出来了，以前是和 zookeeper 的代码强耦合在一起的，重构之后可以有多种实现了。&lt;/p&gt;</summary>
    
    
    
    <category term="cim" scheme="http://crossoverjie.top/categories/cim/"/>
    
    <category term="test" scheme="http://crossoverjie.top/categories/cim/test/"/>
    
    
    <category term="cim" scheme="http://crossoverjie.top/tags/cim/"/>
    
  </entry>
  
  <entry>
    <title>OpenTelemetry 实战：从 0 到 1 编写一个 Instrumentation</title>
    <link href="http://crossoverjie.top/2024/09/26/ob/OpenTelemetry-create-instrumentation/"/>
    <id>http://crossoverjie.top/2024/09/26/ob/OpenTelemetry-create-instrumentation/</id>
    <published>2024-09-26T05:14:01.000Z</published>
    <updated>2024-09-26T13:39:32.089Z</updated>
    
    <content type="html"><![CDATA[<h1 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h1><p>因为公司内部在使用 <a href="https://github.com/PowerJob/PowerJob">PowerJob</a> 作为我们的分布式调度系统，同时又是使用 OpenTelemetry 作为可观测的底座，但目前 OpenTelemetry 还没有对 PowerJob 提供支持，目前社区只对同类型的 XXL-JOB 有支持。<br><img src="https://s2.loli.net/2024/08/26/qfdloarJ7iNzPXy.png"></p><p>恰好公司内部也有一些开发同学有类似的需求：<br><img src="https://s2.loli.net/2024/08/26/6aIFxlEyKt7OfsC.png"></p><p>于是在这个背景下我便开始着手开发 PowerJob 的 instrumentation，最终的效果如下：<br><img src="https://s2.loli.net/2024/08/26/r7xgSHKCftqvuXw.png"><br><img src="https://s2.loli.net/2024/08/26/KNnWPzm5rU9By3c.png"></p><span id="more"></span><p>从这个链路图中可以看到 grpc-consumer 提供了调度的入口函数，然后在内部发送了 Pulsar 消息，最终又调用了 grpc-provider 的 <code>gRPC</code> 接口。</p><p>这样就可以把整个链路串起来，同时还能查看 <code>PowerJob</code> 调度的 JobId、以及调用参数等数据，这样排查问题时也更加直观。</p><h1 id="开发-Instrumentation-的前置知识"><a href="#开发-Instrumentation-的前置知识" class="headerlink" title="开发 Instrumentation 的前置知识"></a>开发 Instrumentation 的前置知识</h1><p>在正式开发 Instrumentation 之前还需要了解一些前置知识点。</p><p><img src="https://s2.loli.net/2024/08/26/K43Ix8LCkQWAao5.png"><br><img src="https://s2.loli.net/2024/08/26/29DQxfMgFViuHYa.png"></p><p>这里我们以现有的  <code>gRPC</code> 和我编写的 PowerJob instrumentation 为例，可以看到 <code>gRPC</code> 的 instrumentation 中多了一个 library 的模块。</p><p>这里就引申出了两种埋点方式：</p><ul><li><strong>Library instrumentation</strong></li><li><strong>Java agent instrumentation</strong></li></ul><p>通常我们对一个框架或者一个库进行埋点时，首先需要找到它的埋点入口。</p><p>以 <em><code>grpc</code></em> 为例，我们首先需要看他是否有提供扩展的 API 可以供我们埋点，恰好 grpc 是有提供客户端和服务端的拦截器的。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">io.grpc.ClientInterceptor</span><br><span class="line">io.grpc.ServerInterceptor</span><br></pre></td></tr></table></figure><p>我们便可以在这些拦截中加入埋点逻辑，比如客户端的埋点代码如下 <code>io.opentelemetry.instrumentation.grpc.v1_6.TracingClientInterceptor</code> ：</p><p><img src="https://s2.loli.net/2024/08/26/FJgRjf1ACVlmG3D.png"></p><p>这部分代码便是写在 <code>grpc-1.6/library</code> 模块下的。</p><p>这样做有一个好处是：当我们的业务代码不想使用 <code>javaagent</code> 时还可以手动引入 <code>grpc-1.6/library</code> 包，然后使用 <code>TracingClientInterceptor</code> 拦截器也可以实现 trace 埋点的功能。</p><figure class="highlight kotlin"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">implementation(project(<span class="string">&quot;:instrumentation:grpc-1.6:library&quot;</span>))</span><br></pre></td></tr></table></figure><p>之后 <code>javaagent</code> 这个模块也会引入 <code>library</code> ，然后直接使用它提供的 API 实现 agent 级别的埋点。</p><p>而如果一些库或者中间件并没有提供这种扩展 API 时，我们就只能使用 agent 的方式在字节码层面上进行埋点，这样就不会限制框架了，理论上任何 Java 代码都可以埋点。</p><p>所以总的来说一个库可能会没有 library instrumentation，但一定会有 agent instrumentation，我们可以根据当前框架的代码进行选择。</p><blockquote><p>而这里的 PowerJob 因为并没有提供扩展接口，所有只有 agent 的 instrumentation。</p></blockquote><h1 id="找到埋点入口"><a href="#找到埋点入口" class="headerlink" title="找到埋点入口"></a>找到埋点入口</h1><p>在开始编码之前我们需要对要埋点的库或者框架有一个清晰的理解，至少得知道它的核心逻辑在哪里。</p><p>以 PowerJob 的调度执行逻辑为例：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">TestBasicProcessor</span> <span class="keyword">implements</span> <span class="title class_">BasicProcessor</span> &#123;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> ProcessResult <span class="title function_">process</span><span class="params">(TaskContext context)</span> <span class="keyword">throws</span> Exception &#123;</span><br><span class="line">        System.out.println(<span class="string">&quot;======== BasicProcessor#process ========&quot;</span>);</span><br><span class="line">        System.out.println(<span class="string">&quot;TaskContext: &quot;</span> + JsonUtils.toJSONString(context) + <span class="string">&quot;;time = &quot;</span> + System.currentTimeMillis());</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">new</span> <span class="title class_">ProcessResult</span>(<span class="literal">true</span>, System.currentTimeMillis() + <span class="string">&quot;success&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><blockquote><p>这是一个最简单的调度执行器的实现逻辑。</p></blockquote><p>从这里看出：如果我们想要在执行器中埋点，那最核心的就是这里的 process 函数。</p><p>需要在 process 的执行前后拿到 context 数据，写入到 OpenTelemetry 中的 span 即可。</p><hr><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">SimpleCustomizedHandler</span> <span class="keyword">extends</span> <span class="title class_">IJobHandler</span> &#123;  </span><br><span class="line">  </span><br><span class="line">  <span class="meta">@Override</span>  </span><br><span class="line">  <span class="keyword">public</span> ReturnT&lt;String&gt; <span class="title function_">execute</span><span class="params">(String s)</span> <span class="keyword">throws</span> Exception &#123;  </span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">new</span> <span class="title class_">ReturnT</span>&lt;&gt;(<span class="string">&quot;Hello World&quot;</span>);  </span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>而在 xxl-job 中，它的核心逻辑就是这里的 <code>execute</code> 函数。</p><h1 id="选择合适的版本"><a href="#选择合适的版本" class="headerlink" title="选择合适的版本"></a>选择合适的版本</h1><p>找到核心的埋点逻辑后还有一个很重要的工作要做：那就是<strong>选择你需要支持的版本</strong>。</p><p>选择版本的原因是有可能框架或库在版本迭代过程中核心 API 发生了变化，比如：</p><ul><li>函数签名发生了改变</li><li>包名也发生了改变</li></ul><p>以 xxl-job 为例，它在迭代过程中就发生了几次函数签名的修改，所以我们需要针对不同的版本做兼容处理：</p><p><img src="https://s2.loli.net/2024/08/26/yLhmXBKDzVaYjJ5.png"></p><p>而我这里选择支持 <code>PowerJob:4.0+</code> 的版本，因为社区在 4.0 之后做了大量重构，导致修改了包名，同时核心逻辑的函数签名也没发生过变化。</p><p><img src="https://s2.loli.net/2024/08/26/MuRmI9e28pghzNH.png"></p><blockquote><p>4.0 之前的版本我就没做兼容了，感兴趣的朋友可以自行实现。</p></blockquote><h1 id="逻辑实现"><a href="#逻辑实现" class="headerlink" title="逻辑实现"></a>逻辑实现</h1><p>首先第一步需要创建一个 <code>InstrumentationModule</code>:</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@AutoService(InstrumentationModule.class)</span>  </span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">PowerJobInstrumentationModule</span> <span class="keyword">extends</span> <span class="title class_">InstrumentationModule</span> &#123;  </span><br><span class="line">  <span class="keyword">public</span> <span class="title function_">PowerJobInstrumentationModule</span><span class="params">()</span> &#123;  </span><br><span class="line">    <span class="built_in">super</span>(<span class="string">&quot;powerjob&quot;</span>, <span class="string">&quot;powerjob-4.0&quot;</span>);  </span><br><span class="line">  &#125;  </span><br><span class="line">  <span class="meta">@Override</span>  </span><br><span class="line">  <span class="keyword">public</span> List&lt;TypeInstrumentation&gt; <span class="title function_">typeInstrumentations</span><span class="params">()</span> &#123;  </span><br><span class="line">    <span class="keyword">return</span> asList(<span class="keyword">new</span> <span class="title class_">BasicProcessorInstrumentation</span>());  </span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><img src="https://s2.loli.net/2024/08/26/AxGWtdflEI5NmKn.png"></p><blockquote><p>这里的 @AutoService 注解，会在代码编译之后生成一份 SPI 文件。</p></blockquote><p>之后便是实现这里最核心的 <code>BasicProcessorInstrumentation</code>。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">BasicProcessorInstrumentation</span> <span class="keyword">implements</span> <span class="title class_">TypeInstrumentation</span> &#123;  </span><br><span class="line">  <span class="meta">@Override</span>  </span><br><span class="line">  <span class="keyword">public</span> ElementMatcher&lt;TypeDescription&gt; <span class="title function_">typeMatcher</span><span class="params">()</span> &#123;  </span><br><span class="line">    <span class="keyword">return</span> implementsInterface(named(<span class="string">&quot;tech.powerjob.worker.core.processor.sdk.BasicProcessor&quot;</span>));  </span><br><span class="line">  &#125;  </span><br><span class="line">  <span class="meta">@Override</span>  </span><br><span class="line">  <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">transform</span><span class="params">(TypeTransformer transformer)</span> &#123;  </span><br><span class="line">    transformer.applyAdviceToMethod(  </span><br><span class="line">        named(<span class="string">&quot;process&quot;</span>).and(isPublic()).and(takesArguments(<span class="number">1</span>)),  </span><br><span class="line">        BasicProcessorInstrumentation.class.getName() + <span class="string">&quot;$ProcessAdvice&quot;</span>);  </span><br><span class="line">  &#125;</span><br><span class="line">&#125;  </span><br></pre></td></tr></table></figure><p>从它的代码也可以看出，这里主要是指定我们需要对哪个方法的哪个函数进行埋点，然后埋点之后的处理逻辑是在哪个类(<code>ProcessAdvice</code>)中实现的。</p><p>之后便是 <code>ProcessAdvice</code> 的实现：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">class</span> <span class="title class_">ProcessAdvice</span> &#123;  </span><br><span class="line">  </span><br><span class="line">  <span class="meta">@SuppressWarnings(&quot;unused&quot;)</span>  </span><br><span class="line">  <span class="meta">@Advice</span>.OnMethodEnter(suppress = Throwable.class)  </span><br><span class="line">  <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">onSchedule</span><span class="params">(  </span></span><br><span class="line"><span class="params">      <span class="meta">@Advice</span>.This BasicProcessor handler,  </span></span><br><span class="line"><span class="params">      <span class="meta">@Advice</span>.Argument(<span class="number">0</span>)</span> TaskContext taskContext,  </span><br><span class="line">      <span class="meta">@Advice</span>.Local(<span class="string">&quot;otelRequest&quot;</span>) PowerJobProcessRequest request,  </span><br><span class="line">      <span class="meta">@Advice</span>.Local(<span class="string">&quot;otelContext&quot;</span>) Context context,  </span><br><span class="line">      <span class="meta">@Advice</span>.Local(<span class="string">&quot;otelScope&quot;</span>) Scope scope) &#123;  </span><br><span class="line">    <span class="type">Context</span> <span class="variable">parentContext</span> <span class="operator">=</span> currentContext();  </span><br><span class="line">    request = PowerJobProcessRequest.createRequest(taskContext.getJobId(), handler, <span class="string">&quot;process&quot;</span>);  </span><br><span class="line">    request.setInstanceParams(taskContext.getInstanceParams());  </span><br><span class="line">    request.setJobParams(taskContext.getJobParams());  </span><br><span class="line">    context = helper().startSpan(parentContext, request);  </span><br><span class="line">    <span class="keyword">if</span> (context == <span class="literal">null</span>) &#123;  </span><br><span class="line">      <span class="keyword">return</span>;  </span><br><span class="line">    &#125;    scope = context.makeCurrent();  </span><br><span class="line">  &#125;  </span><br><span class="line">  </span><br><span class="line">  <span class="meta">@SuppressWarnings(&quot;unused&quot;)</span>  </span><br><span class="line">  <span class="meta">@Advice</span>.OnMethodExit(onThrowable = Throwable.class, suppress = Throwable.class)  </span><br><span class="line">  <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">stopSpan</span><span class="params">(  </span></span><br><span class="line"><span class="params">      <span class="meta">@Advice</span>.Return ProcessResult result,  </span></span><br><span class="line"><span class="params">      <span class="meta">@Advice</span>.Thrown Throwable throwable,  </span></span><br><span class="line"><span class="params">      <span class="meta">@Advice</span>.Local(<span class="string">&quot;otelRequest&quot;</span>)</span> PowerJobProcessRequest request,  </span><br><span class="line">      <span class="meta">@Advice</span>.Local(<span class="string">&quot;otelContext&quot;</span>) Context context,  </span><br><span class="line">      <span class="meta">@Advice</span>.Local(<span class="string">&quot;otelScope&quot;</span>) Scope scope) &#123;  </span><br><span class="line">    helper().stopSpan(result, request, throwable, scope, context);  </span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这里最主要的就是使用 <code>OpenTelemetry</code> 提供 SDK 在入口处调用 <code>startSpan</code> 开始一个 span，然后在函数退出时调用 <code>stopSpan</code> 函数。</p><p>同时在执行前将一些请求信息存起来：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">request = PowerJobProcessRequest.createRequest(taskContext.getJobId(), handler, <span class="string">&quot;process&quot;</span>);</span><br></pre></td></tr></table></figure><p>这样可以根据这些请求信息生成 span 的 attribute，也就是 jobId, jobParam 等数据。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">PowerJobExperimentalAttributeExtractor</span>  </span><br><span class="line">    <span class="keyword">implements</span> <span class="title class_">AttributesExtractor</span>&lt;PowerJobProcessRequest, Void&gt; &#123;  </span><br><span class="line">  </span><br><span class="line">  <span class="meta">@Override</span>  </span><br><span class="line">  <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">onStart</span><span class="params">(  </span></span><br><span class="line"><span class="params">      AttributesBuilder attributes,  </span></span><br><span class="line"><span class="params">      Context parentContext,  </span></span><br><span class="line"><span class="params">      PowerJobProcessRequest powerJobProcessRequest)</span> &#123;  </span><br><span class="line">    attributes.put(POWERJOB_JOB_ID, powerJobProcessRequest.getJobId());  </span><br><span class="line">    attributes.put(POWERJOB_JOB_PARAM, powerJobProcessRequest.getJobParams());  </span><br><span class="line">    attributes.put(POWERJOB_JOB_INSTANCE_PARAM, powerJobProcessRequest.getInstanceParams());  </span><br><span class="line">    attributes.put(POWERJOB_JOB_INSTANCE_TRPE, powerJobProcessRequest.getJobType());  </span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure><p>比如这里的 jobId&#x2F; jobParams 数据都是从刚才写入的 <code>PowerJobProcessRequest</code> 中获取的。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> (CAPTURE_EXPERIMENTAL_SPAN_ATTRIBUTES) &#123;  </span><br><span class="line">  builder.addAttributesExtractor(  </span><br><span class="line">      AttributesExtractor.constant(AttributeKey.stringKey(<span class="string">&quot;job.system&quot;</span>), <span class="string">&quot;powerjob&quot;</span>));  </span><br><span class="line">  builder.addAttributesExtractor(<span class="keyword">new</span> <span class="title class_">PowerJobExperimentalAttributeExtractor</span>());  </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>同时只需要将刚才的 <code>PowerJobExperimentalAttributeExtractor</code> 在初始化 Instrumenter 时进行配置，这样 <code>OpenTelemetry</code> 的 SDK 就会自动回调这个接口，从而获取到 Span 的 attribute。</p><hr><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> <span class="keyword">static</span> net.bytebuddy.matcher.ElementMatchers.isPublic;  </span><br><span class="line"><span class="keyword">import</span> <span class="keyword">static</span> net.bytebuddy.matcher.ElementMatchers.named;  </span><br><span class="line"><span class="keyword">import</span> <span class="keyword">static</span> net.bytebuddy.matcher.ElementMatchers.takesArguments;</span><br><span class="line"><span class="keyword">import</span> net.bytebuddy.asm.Advice;</span><br></pre></td></tr></table></figure><blockquote><p>其实这里大部分的 API 都是 bytebuddy 提供的。</p></blockquote><p>不知道大家是否觉得眼熟，Instrumentation 的写法其实和 spring 的拦截器有异曲同工之妙：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> org.aspectj.lang.annotation.Aspect;</span><br><span class="line"><span class="keyword">import</span> org.aspectj.lang.annotation.Around;</span><br><span class="line"><span class="keyword">import</span> org.aspectj.lang.ProceedingJoinPoint;</span><br><span class="line"></span><br><span class="line"><span class="meta">@Aspect</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">AroundExample</span> &#123;</span><br><span class="line"></span><br><span class="line"><span class="meta">@Around(&quot;execution(* com.xyz..service.*.*(..))&quot;)</span></span><br><span class="line"><span class="keyword">public</span> Object <span class="title function_">doBasicProfiling</span><span class="params">(ProceedingJoinPoint pjp)</span> <span class="keyword">throws</span> Throwable &#123;</span><br><span class="line"><span class="comment">// start stopwatch</span></span><br><span class="line"><span class="type">Object</span> <span class="variable">retVal</span> <span class="operator">=</span> pjp.proceed();</span><br><span class="line"><span class="comment">// stop stopwatch</span></span><br><span class="line"><span class="keyword">return</span> retVal;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><blockquote><p>毕竟 Spring 的拦截器也是使用 <code>bytebuddy</code> 实现的。</p></blockquote><h1 id="一些坑"><a href="#一些坑" class="headerlink" title="一些坑"></a>一些坑</h1><p>其实整个埋点过程非常简单，我们可以参考一些现有的 instrumentation 就可以很快实现逻辑；真正麻烦的时候在提交 PR 时需要通过 CI 校验。</p><p><img src="https://s2.loli.net/2024/08/26/ynupP2g5UMWGD3Z.png"></p><blockquote><p>我这里大概提交了 8次才把  CI 全部跑通过。</p></blockquote><p>这里面有各种小坑，只有自己提交过才能感受得到，下面我就一一列举一些大家可能会碰到的问题。</p><h2 id="创建模块"><a href="#创建模块" class="headerlink" title="创建模块"></a>创建模块</h2><p>首先第一个是创建模块的时候记得使用 kotlin 作为 gradle 的 DSL。</p><p><img src="https://s2.loli.net/2024/08/26/ku9e3vhG5mSYPc4.png"></p><p>IDEA 这里默认选择的是 Groovy 作为 DSL；我当时没有注意，后面在项目构建过程中一直在报错，仔细核对后发现是 DSL 的问题，修改之后就能编译通过了。</p><h2 id="项目构建"><a href="#项目构建" class="headerlink" title="项目构建"></a>项目构建</h2><p>第二个是 module 的命名规则。</p><p><img src="https://s2.loli.net/2024/08/26/NZgl4GUR327IXW5.png"></p><p>我们需要遵守 v4_0_0 的规则，同时还得与 <code>PowerJobInstrumentationModule</code> 中定义的名称相同：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="title function_">PowerJobInstrumentationModule</span><span class="params">()</span> &#123;  </span><br><span class="line">  <span class="built_in">super</span>(<span class="string">&quot;powerjob&quot;</span>, <span class="string">&quot;powerjob-4.0&quot;</span>);  </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>比如如果我们的包名称是 <code>powerjob.v1.1.0</code> ，那这里的名称也得是 <code>&quot;powerjob-1.1.0&quot;</code></p><h1 id="Muzzle"><a href="#Muzzle" class="headerlink" title="Muzzle"></a>Muzzle</h1><p>第三个是 <code>Muzzle</code> 校验，<code>Muzzle</code> 是为了保证 <code>javaagent</code> 在业务代码中使用时和运行时的依赖不发生冲突而定义的一个校验规则。</p><figure class="highlight kotlin"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">muzzle &#123;  </span><br><span class="line">  pass &#123;  </span><br><span class="line">    group.<span class="keyword">set</span>(<span class="string">&quot;tech.powerjob&quot;</span>)  </span><br><span class="line">    module.<span class="keyword">set</span>(<span class="string">&quot;powerjob-worker&quot;</span>)  </span><br><span class="line">    versions.<span class="keyword">set</span>(<span class="string">&quot;[4.0.0,)&quot;</span>)  </span><br><span class="line">    assertInverse.<span class="keyword">set</span>(<span class="literal">true</span>)  </span><br><span class="line">    extraDependency(<span class="string">&quot;tech.powerjob:powerjob-official-processors:1.1.0&quot;</span>)  </span><br><span class="line">  &#125;  </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>以我这个为例，它的含义是兼容 <code>tech.powerjob:powerjob-worker:4.0.0+</code>以上的版本。</p><p><code>assertInverse.set(true)</code>: 的作用是与之相反的版本，也就是 4.0.0 以下的版本都不做支持，如果在这些版本中运行 javaagent 是不会生效的。</p><blockquote><p>因为这些低版本的 powerjob 不兼容我们的埋点代码。</p></blockquote><p><code>extraDependency</code>：的作用是额外需要依赖的包，我这里额外使用了这个包里的一些类，如果不加上的话在做 <code>Muzzle</code> 校验时也会失败。</p><h2 id="单元测试"><a href="#单元测试" class="headerlink" title="单元测试"></a>单元测试</h2><p>最后便是单元测试了：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Test</span></span><br><span class="line"><span class="keyword">void</span> <span class="title function_">testBasicProcessor</span><span class="params">()</span> <span class="keyword">throws</span> Exception &#123;</span><br><span class="line">  <span class="type">long</span> <span class="variable">jobId</span> <span class="operator">=</span> <span class="number">1</span>;</span><br><span class="line">  <span class="type">String</span> <span class="variable">jobParam</span> <span class="operator">=</span> <span class="string">&quot;abc&quot;</span>;</span><br><span class="line">  <span class="type">TaskContext</span> <span class="variable">taskContext</span> <span class="operator">=</span> genTaskContext(jobId, jobParam);</span><br><span class="line">  <span class="type">BasicProcessor</span> <span class="variable">testBasicProcessor</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">TestBasicProcessor</span>();</span><br><span class="line">  testBasicProcessor.process(taskContext);</span><br><span class="line">  testing.waitAndAssertTraces(</span><br><span class="line">      trace -&gt; &#123;</span><br><span class="line">        trace.hasSpansSatisfyingExactly(</span><br><span class="line">            span -&gt; &#123;</span><br><span class="line">              span.hasName(String.format(<span class="string">&quot;%s.process&quot;</span>, TestBasicProcessor.class.getSimpleName()));</span><br><span class="line">              span.hasKind(SpanKind.INTERNAL);</span><br><span class="line">              span.hasStatus(StatusData.unset());</span><br><span class="line">              span.hasAttributesSatisfying(</span><br><span class="line">                  attributeAssertions(</span><br><span class="line">                      TestBasicProcessor.class.getName(), jobId, jobParam, BASIC_PROCESSOR));</span><br><span class="line">            &#125;);</span><br><span class="line">      &#125;);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> List&lt;AttributeAssertion&gt; <span class="title function_">attributeAssertions</span><span class="params">(</span></span><br><span class="line"><span class="params">    String codeNamespace, <span class="type">long</span> jobId, String jobParam, String jobType)</span> &#123;</span><br><span class="line">  List&lt;AttributeAssertion&gt; attributeAssertions =</span><br><span class="line">      <span class="keyword">new</span> <span class="title class_">ArrayList</span>&lt;&gt;(</span><br><span class="line">          asList(</span><br><span class="line">              equalTo(AttributeKey.stringKey(<span class="string">&quot;code.namespace&quot;</span>), codeNamespace),</span><br><span class="line">              equalTo(AttributeKey.stringKey(<span class="string">&quot;code.function&quot;</span>), <span class="string">&quot;process&quot;</span>),</span><br><span class="line">              equalTo(AttributeKey.stringKey(<span class="string">&quot;job.system&quot;</span>), <span class="string">&quot;powerjob&quot;</span>),</span><br><span class="line">              equalTo(AttributeKey.longKey(<span class="string">&quot;scheduling.powerjob.job.id&quot;</span>), jobId),</span><br><span class="line">              equalTo(AttributeKey.stringKey(<span class="string">&quot;scheduling.powerjob.job.type&quot;</span>), jobType)));</span><br><span class="line">  <span class="keyword">if</span> (!StringUtils.isNullOrEmpty(jobParam)) &#123;</span><br><span class="line">    attributeAssertions.add(</span><br><span class="line">        equalTo(AttributeKey.stringKey(<span class="string">&quot;scheduling.powerjob.job.param&quot;</span>), jobParam));</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">return</span> attributeAssertions;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>测试的逻辑很简单，就是模拟一下核心逻辑的调用，然后断言是否存在我们预期的 Span，同时还得校验它的 attribute 是否符合我们的预期。</p><p>这个单测当时也调了许久，因为 <code>versions.set(&quot;[4.0.0,)&quot;)</code> 这个配置，有一个 CI workflow 会校验最新版本的 powerjob 是否也能正常运行。</p><p><img src="https://s2.loli.net/2024/08/26/vDSXq9tpGW7LAdb.png"></p><p>比如它会拉取目前最新的依赖进行测试：</p><figure class="highlight kotlin"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">implementation(<span class="string">&quot;tech.powerjob:powerjob-worker:5.1.0&quot;</span>)</span><br></pre></td></tr></table></figure><p>如果我们在单测中依赖了某些版本不存在的类，或者是函数签名发生过变化的函数用于测试，那这个 CI 就会执行失败。</p><p><img src="https://s2.loli.net/2024/08/26/HjIi5dBKlw9FxQy.png"></p><p>因为这里的构建日志非常多，同时还是并发测试的，如果我们想直接查看日志来定位问题会非常麻烦。</p><p>当然社区也考虑到了，可以在 <code>“Build scan”</code> 这个步骤中查看 <code>gradle</code> 的构建日志。</p><p><img src="https://s2.loli.net/2024/08/26/4xmRqFZi6NpkPML.png"></p><p><a href="https://scans.gradle.com/s/meywfxnvhhqtc/console-log/task/:instrumentation:powerjob-4.0:javaagent:compileTestJava?anchor=37&page=1">这里</a>会直接输出具体是哪里构建出了问题，通过它我们就能很快定位到原因。</p><p>我这里也是因为使用的某些帮助函数在最新的版本中发生了变化，为了测试通过，就不得不调整测试代码了。</p><p>如果你发现必须得依赖这些类或者函数来配合测试，那就只有考虑分为多个不同的版本进行测试，类似于 xxl-job：</p><p><img src="https://s2.loli.net/2024/08/26/yLhmXBKDzVaYjJ5.png"></p><h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>以上就是整个 instrumentation 的编写过程，其中核心的埋点过程并不复杂，只要我们对需要埋点的库或框架比较熟悉，都可以实现埋点。</p><p>真正麻烦的是需要通过社区复杂且严谨的 CI 流程，好在不管是哪一步的 CI 失败都可以查到具体的原因，有点类似于升级打怪，跟着错误信息走，最终都能验证通过。</p><p>参考链接：</p><ul><li><a href="https://github.com/open-telemetry/opentelemetry-java-instrumentation/blob/main/CONTRIBUTING.md">https://github.com/open-telemetry/opentelemetry-java-instrumentation/blob/main/CONTRIBUTING.md</a></li><li><a href="https://github.com/open-telemetry/opentelemetry-java-instrumentation/blob/main/docs/contributing/writing-instrumentation.md">https://github.com/open-telemetry/opentelemetry-java-instrumentation/blob/main/docs/contributing/writing-instrumentation.md</a></li></ul>]]></content>
    
    
    <summary type="html">&lt;h1 id=&quot;背景&quot;&gt;&lt;a href=&quot;#背景&quot; class=&quot;headerlink&quot; title=&quot;背景&quot;&gt;&lt;/a&gt;背景&lt;/h1&gt;&lt;p&gt;因为公司内部在使用 &lt;a href=&quot;https://github.com/PowerJob/PowerJob&quot;&gt;PowerJob&lt;/a&gt; 作为我们的分布式调度系统，同时又是使用 OpenTelemetry 作为可观测的底座，但目前 OpenTelemetry 还没有对 PowerJob 提供支持，目前社区只对同类型的 XXL-JOB 有支持。&lt;br&gt;&lt;img src=&quot;https://s2.loli.net/2024/08/26/qfdloarJ7iNzPXy.png&quot;&gt;&lt;/p&gt;
&lt;p&gt;恰好公司内部也有一些开发同学有类似的需求：&lt;br&gt;&lt;img src=&quot;https://s2.loli.net/2024/08/26/6aIFxlEyKt7OfsC.png&quot;&gt;&lt;/p&gt;
&lt;p&gt;于是在这个背景下我便开始着手开发 PowerJob 的 instrumentation，最终的效果如下：&lt;br&gt;&lt;img src=&quot;https://s2.loli.net/2024/08/26/r7xgSHKCftqvuXw.png&quot;&gt;&lt;br&gt;&lt;img src=&quot;https://s2.loli.net/2024/08/26/KNnWPzm5rU9By3c.png&quot;&gt;&lt;/p&gt;</summary>
    
    
    
    <category term="OB" scheme="http://crossoverjie.top/categories/OB/"/>
    
    <category term="OpenTelemetry" scheme="http://crossoverjie.top/categories/OB/OpenTelemetry/"/>
    
    
    <category term="OpenTelemetry" scheme="http://crossoverjie.top/tags/OpenTelemetry/"/>
    
  </entry>
  
  <entry>
    <title>我用我的270篇文章做了一个数字 AI 替身</title>
    <link href="http://crossoverjie.top/2024/09/23/ob/Build-ower-AI-robot/"/>
    <id>http://crossoverjie.top/2024/09/23/ob/Build-ower-AI-robot/</id>
    <published>2024-09-23T13:54:01.000Z</published>
    <updated>2024-09-23T14:55:08.624Z</updated>
    
    <content type="html"><![CDATA[<p>23 年在 ChatGPT 刚出来的时候就在 <a href="https://www.v2ex.com/t/931521">V 站</a>上看到有一个看到有大佬用自己的微信聊天记录和博客文章生成了一个 AI 替身：</p><span id="more"></span><p><img src="https://s2.loli.net/2024/09/23/7xPdy54cIEm6pnR.png" alt="image.png"></p><p>当时就想着自己做一个，不过当时实现起来还比较复杂，直到如今 AI 已经越来越普及，想做一个自己的 AI 替身成本也非常低了。</p><p>于是就有了下图里的效果：<br><img src="https://s2.loli.net/2024/09/23/vmJhURZKsg96yaY.png"><br><img src="https://s2.loli.net/2024/09/23/tOzlgqvEMdm6LFo.png"></p><p>和自己的内容这么对话还挺有意思的，现在大家就可以直接在我公众号回复消息和”他“聊天。<br><img src="https://s2.loli.net/2024/09/23/7CiykumvIdALDZe.jpg"></p><blockquote><p>也可以通过小程序来使用：<br><img src="https://s2.loli.net/2024/09/23/9bdLkeP6XGorKAJ.png"></p></blockquote><h2 id="如何搭建"><a href="#如何搭建" class="headerlink" title="如何搭建"></a>如何搭建</h2><p>这里使用的数据源全都是我发布在公众号里的 260 篇文章。<br><img src="https://s2.loli.net/2024/09/23/NWae9gRJbPHO6M8.png"></p><p>能够直接获取到微信公众号的数据一定是腾讯自己的产品，其实这个产品叫做：<a href="https://yuanqi.tencent.com/">腾讯元器</a>，是腾讯大模型团队基于混元大模型推出的智能创作工具。</p><p>我们可以自定义 prompt、数据源、插件来实现自己的 AI 机器人，或者类似的交互产品。</p><p>直接创建一个智能体，然后编写对应的提示词即可，使用起来非常简单，官方也提供了一些 <code>prompt</code> 的示例：<br><img src="https://s2.loli.net/2024/09/23/sOhwLG28i9qTcBz.png" alt="image.png"></p><p>根据自己的需求来填写就可以了。</p><p>最主要的还是创建一个知识库，也就是你的数据源，好在这里直接整合了公众号的数据；<br><img src="https://s2.loli.net/2024/09/23/sXALurKi5BRET23.png"></p><p>直接授权就可以使用，同时还可以每天定时更新，非常方便。</p><p><img src="https://s2.loli.net/2024/09/23/TEJZ56MNCBV3aLh.png"></p><p>它会根据你的问题来判断是否用知识库的内容来回答，所以即便是问一些知识库不存在的内容也能拿到结果。</p><hr><p><img src="https://s2.loli.net/2024/09/23/AJbU4s1FXq7rSxO.png"><br>除此之外还可以上传你本地的文件，所以即便是你没有写公众号也可以上传自己整理的内容。</p><p>有兴趣的朋友可以试试尝尝鲜，后续我可以持续完善这个知识库，比如输入一些代码，之后再有向我咨询问题的朋友就可以先去问问”他“，</p><p>大家可以直接在公众号里和”对话“，说不定还有意外收获🐶。</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;23 年在 ChatGPT 刚出来的时候就在 &lt;a href=&quot;https://www.v2ex.com/t/931521&quot;&gt;V 站&lt;/a&gt;上看到有一个看到有大佬用自己的微信聊天记录和博客文章生成了一个 AI 替身：&lt;/p&gt;</summary>
    
    
    
    <category term="AI" scheme="http://crossoverjie.top/categories/AI/"/>
    
    
    <category term="AI" scheme="http://crossoverjie.top/tags/AI/"/>
    
  </entry>
  
  <entry>
    <title>OpenTelemetry在企业内部应用所需要的技术栈</title>
    <link href="http://crossoverjie.top/2024/09/15/ob/OpenTelemetry-enterprise/"/>
    <id>http://crossoverjie.top/2024/09/15/ob/OpenTelemetry-enterprise/</id>
    <published>2024-09-15T07:54:11.000Z</published>
    <updated>2024-09-17T11:50:48.221Z</updated>
    
    <content type="html"><![CDATA[<h1 id="可观测性概念"><a href="#可观测性概念" class="headerlink" title="可观测性概念"></a>可观测性概念</h1><p><img src="https://s2.loli.net/2024/08/08/Sdot1TJUfWgNZyu.png"><br>当一个软件或系统出于运行状态时，如果我们不对他加以观测，那它的运行状态对我们来说就是一个黑盒。</p><blockquote><p>如上图所示。</p></blockquote><p>我们只能通过业务的表象来判断它是否正常运行，无法在故障发生前进行预判，从而只能被动解决问题。</p><span id="more"></span><p>这类问题在微服务时代体现的更加明显，即便是业务已经出现问题，在没有可观测性系统的前提下想要定位问题更是难上加难。</p><p><img src="https://s2.loli.net/2024/08/08/eUFuwnPxf3cVrCL.png"><br>好在可观测性这个概念由来已久，已经由一些业界大佬抽象出几个基本概念：</p><ul><li>Logs：离散的日志信息</li><li>Metrics：聚合的指标</li><li>Trace：请求基本的链路追踪</li></ul><p>结合这三个指标，我们排查问题的流程一般如下：<br><img src="https://s2.loli.net/2024/08/08/Ixqt2WnBaz9jAQ4.png"></p><p>首先根据 metrics 来判断是否有异常，这点可以通过在 Prometheus 的 AlertManager 配置一些核心的告警指标。</p><p>比如当 CPU、内存使用率超过 80% 或者某个应用 Down 机后就发出告警。</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">groups:</span></span><br><span class="line"><span class="bullet">-</span> <span class="attr">name:</span> <span class="string">AllInstances</span></span><br><span class="line">  <span class="attr">rules:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">alert:</span> <span class="string">InstanceDown</span></span><br><span class="line">    <span class="comment"># Condition for alerting</span></span><br><span class="line">    <span class="attr">expr:</span> <span class="string">up</span> <span class="string">==</span> <span class="number">0</span></span><br><span class="line">    <span class="attr">for:</span> <span class="string">1m</span></span><br><span class="line">    <span class="comment"># Annotation - additional informational labels to store more information</span></span><br><span class="line">    <span class="attr">annotations:</span></span><br><span class="line">      <span class="attr">title:</span> <span class="string">&#x27;Instance <span class="template-variable">&#123;&#123; $labels.instance &#125;&#125;</span> down&#x27;</span></span><br><span class="line">      <span class="attr">description:</span> <span class="string">&#x27;<span class="template-variable">&#123;&#123; $labels.instance &#125;&#125;</span> of job <span class="template-variable">&#123;&#123; $labels.job &#125;&#125;</span> has been down for more than 1 minute.&#x27;</span></span><br><span class="line">    <span class="comment"># Labels - additional labels to be attached to the alert</span></span><br><span class="line">    <span class="attr">labels:</span></span><br><span class="line">      <span class="attr">severity:</span> <span class="string">&#x27;critical&#x27;</span></span><br></pre></td></tr></table></figure><p><img src="https://s2.loli.net/2024/08/15/vh4t8nLk2NaXKu9.png"></p><p>这可以让我们尽早发现故障。</p><p>之后我们可以通过链路信息找到发生故障的节点。<br><img src="https://s2.loli.net/2024/08/15/A4C8xQour2WqpLO.png"></p><p>然后通过这里的 trace_id 在应用中找到具体的日志：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mdc.trace_id:4a686dedcdf4e95b1a83b36e62563a96</span><br></pre></td></tr></table></figure><p>再根据日志中的上下文确定具体的异常原因。</p><p>这就是一个完整的排查问题的流程。</p><h1 id="OpenTelemetry-发展历史"><a href="#OpenTelemetry-发展历史" class="headerlink" title="OpenTelemetry 发展历史"></a>OpenTelemetry 发展历史</h1><p><img src="https://s2.loli.net/2024/08/08/p5WkVbSarUdIQwT.png" alt="image.png"><br><img src="https://s2.loli.net/2024/08/08/pvMEBObGgHcdRom.png"><br>在 OpenTelemetry 开始之前还是先回顾下可观测性的发展历史，其中有几个重要时间点：</p><ul><li>2010 年 Google 发布了 Dapper 论文，给业界带来了实现分布式追踪的理论支持，之后的许多分布式链路追踪实现都有它的影子</li><li>kubernetes 的发布奠定了后续云原生社区的基础</li><li>Jaeger 发布后成为了主流的链路存储系统</li><li>2019 年 OpenTracing 和 OpenCensus 合并为 OpenTelemetry</li><li>2021 年底 OpenTelemetry 发布第一个 GA release 版本</li></ul><h2 id="OpenTelemetry-是什么？"><a href="#OpenTelemetry-是什么？" class="headerlink" title="OpenTelemetry 是什么？"></a>OpenTelemetry 是什么？</h2><p><img src="https://s2.loli.net/2024/08/08/FDzVTSqruLxY8EX.png"></p><p>以前我们所接触到的类似于阿里的ARMS、美团的 CAT、Pinpoint 这类系统大多都有一个公司在背后进行驱动，与厂商绑定的非常紧密。</p><p>而 OpenTelemetry 则相反，它主要由社区驱动，参与的公司众多；同时它定义和提供了一套可观测性的标准（包括 API、SDK、规范等数据）。</p><p>使用它你可以灵活的选择和搭配任意的开源或商业产品来组成你的可观测性技术栈。</p><p><img src="https://s2.loli.net/2024/08/08/8RJ6H75hsICWgcD.png"></p><p>因为社区非常活跃，所以当前也几乎支持主流的开发语言。</p><h2 id="OpenTelemetry-的架构"><a href="#OpenTelemetry-的架构" class="headerlink" title="OpenTelemetry 的架构"></a>OpenTelemetry 的架构</h2><p><img src="https://s2.loli.net/2024/08/08/DMd1JfcCrO7Pm52.png"><br>OpenTelemetry 的架构主要分为三个部分：</p><ul><li>左侧的客户端 Agent，用于采集客户端的数据，通常就是我们的应用。</li><li>中间的是 Collector-Service，用于接受客户端的数据、内部处理、导出数据到各种存储</li><li>右侧的则是各种存储层，用于存储 Metrics、Logs、Traces 这些数据。</li></ul><p>我们基于官方推荐的技术架构选型了我们的技术栈：<br><img src="https://s2.loli.net/2024/08/09/XTzCOPBI6HYNta1.png" alt="image.png"><br>主要的区别就是使用 VictoriaMetrics 存储指标、StackRocks 存储 Trace，ElasticSearch 存储日志。</p><blockquote><p>只是目前我们的日志链路还没有完全切换到 OpenTelemetry 的链路，依然是在 Pod 中挂载了一个 sidecar，在这个 sidecar 中通过 filebeat 采集日志输出到 elasticsearch，后续也会逐步迁移。</p></blockquote><h2 id="核心项目"><a href="#核心项目" class="headerlink" title="核心项目"></a>核心项目</h2><h3 id="Collecotor"><a href="#Collecotor" class="headerlink" title="Collecotor"></a>Collecotor</h3><p>OpenTelemetry 社区的项目众多，其中大部分都是各种语言的 SDK 和 API，其中最为关键的应该就是 <a href="https://github.com/open-telemetry?q=opentelemetry-collector&type=all&language=&sort=">opentelemetry-collector</a></p><p>也就是刚才架构图中的中间部分，我们可以把它理解为类似 APIGateway 的角色，所有上报的 OTel 数据都得经过它的处理。</p><p><img src="https://s2.loli.net/2024/08/16/UfuI2wHtojqNS96.png"></p><p>主要由以下三部分组成：</p><ul><li>Receiver：用于接受客户端上报的数据</li><li>Process：内部的数据处理器</li><li>Exporter：将数据导出到不同的存储</li></ul><p>由于 OpenTelemetry 社区非常的活跃，所以这里支持的 <a href="https://github.com/open-telemetry/opentelemetry-collector-contrib/tree/main/receiver">Receiver</a>、<a href="https://github.com/open-telemetry/opentelemetry-collector-contrib/tree/main/processor">Processor</a> 和 <a href="https://github.com/open-telemetry/opentelemetry-collector-contrib/tree/main/exporter">Exporter</a> 类型非常多。</p><p><img src="https://s2.loli.net/2024/08/16/hTeuXskGMitYFCr.png"><br><img src="https://s2.loli.net/2024/08/16/EqPcjxK3Myr2LUC.png"><br><img src="https://s2.loli.net/2024/08/16/btqTu9gAl7heJra.png"></p><h3 id="其他核心项目"><a href="#其他核心项目" class="headerlink" title="其他核心项目"></a>其他核心项目</h3><p>我们以 Java 为例，对业务开发最重要的库就是 <a href="https://github.com/open-telemetry/opentelemetry-java-instrumentation/">opentelemetry-java-instrumentation</a></p><p>它可以打包一个 javaagent 给我们使用：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Java example</span></span><br><span class="line">java -javaagent:path/to/opentelemetry-javaagent.jar \  </span><br><span class="line">     -jar myapp.jar</span><br></pre></td></tr></table></figure><p><img src="https://s2.loli.net/2024/08/16/YjzfWKFxPOqH5N6.png"></p><p>同时也支持了我们日常开发的绝大多数框架和中间件。</p><blockquote><p>支持的<a href="https://github.com/open-telemetry/opentelemetry-java-instrumentation/blob/main/docs/supported-libraries.md">库与框架</a>列表</p></blockquote><p>如果我们需要在应用中自定义打桩一些 Span、Metrics ，就还需要 <a href="https://github.com/open-telemetry/opentelemetry-java">opentelemetry-java</a> 这个项目。</p><p>它提供了具体的 SDK 可以方便的创建 Span 和 Metrics。</p><h1 id="Trace"><a href="#Trace" class="headerlink" title="Trace"></a>Trace</h1><p>之后来看看 <code>OpenTelemetry</code> 中具体的三个维度的概念和应用，首先是 Trace。</p><p><img src="https://s2.loli.net/2024/08/16/DAB7J5Rpx8OFs6L.png"></p><p>Trace 这个概念首先是 <a href="https://static.googleusercontent.com/media/research.google.com/zh-CN//archive/papers/dapper-2010-1.pdf">Google Dapper</a> 论文中提到。</p><p>如上图所示：一次用户请求经历了 4 次 PRC 调用，分别也属于不同的系统。</p><p>每一次 RPC 调用就会产生一个 Span，将这些 span 串联起来就能形成一个调用链路。</p><p>这个 Span 主要包含以下信息：</p><ul><li>SpanName</li><li>ParentID</li><li>SpanID</li></ul><p>当我们将一个 Span 放大后会看到更加具体的信息：</p><ul><li>TraceId</li><li>SpanName</li><li>ParentID</li><li>SpanID</li><li>开始时间</li><li>结束时间<br>在 Dapper 论文中使用 Annotations 来存放 span 的属性，当然也可以自定义存放一些数据，比如图中的 <code>&quot;foo&quot;</code>。</li></ul><blockquote><p>在 OpenTelemetry 的 SDK 中称为  attribute，而在 Jaeger 的 UI 中又称为 tag，虽然叫法不同，但本质上是一个东西。</p></blockquote><p>最终就会形成上图中的树状结构的调用关系。</p><h2 id="Span-Kind"><a href="#Span-Kind" class="headerlink" title="Span Kind"></a>Span Kind</h2><p><img src="https://s2.loli.net/2024/08/16/XSAGlCY7F4f1pu5.png"><br>Span 中还有一个非常重要的概念，就是 Span Kind，也就是 Span 的类型，这个类型可以在排查问题时很容易得知该服务的类型。</p><p><img src="https://s2.loli.net/2024/08/16/cqezfgKSylJipRB.png"><br>按照官方的定义，Span 的类型分为：</p><ul><li>Client</li><li>Server</li><li>Internal</li><li>Producer</li><li>Consumer</li></ul><p>对于 RPC 的客户端和服务端自然就对应 Client 和 Server，而使用了消息队列的生产者消费者对应的就是 Produce 和 Consumer。</p><p>除此之外发生在应用内部的一些关键 Span 的类型就是 Internal，比如我们需要对业务的某些关键函数生成 Span 时，此时的 Span 类型通常也都是 Internal。</p><h2 id="上下文传递"><a href="#上下文传递" class="headerlink" title="上下文传递"></a>上下文传递</h2><p><img src="https://s2.loli.net/2024/08/09/v1mwnLEGNlKMbsq.png" alt="image.png"></p><p>在 Trace 中有一个关键技术问题需要被解决，也就是 Context 的上下文传递。</p><p>这个特别是在分布式系统中必须要解决，我们可以简单把它理解为如何把上游生成的 trace_id 传递到下游，这样才能在追踪的链路追踪系统中串联起来。</p><p>这个关键的技术名词在 OpenTelemetry 中称为：<a href="https://opentelemetry.io/docs/concepts/context-propagation/">Context Propagation</a>.</p><p>在分布式系统中，数据都是通过网络传递的，所以这里的本质问题依然是如何将上下文数据序列化之后，在下游可以反序列化到 <code>Context</code> 中。</p><p>聪明的小伙伴应该已经想到，我们可以将 trace_id 写入到跨进程调用的元数据中：</p><ul><li>http 可以存放在 http header 中</li><li>gRPC 可以存放在 meta 中</li><li>Pulsar 可以存放在消息的 properties 中</li><li>其余的中间件和框架也是同理</li></ul><p>然后在远程调用之前使用 <code>Inject</code> 将数据注入到这些元数据里，下游在接收到请求后再通过一个<code>Extract</code> 函数将元数据解析到 <code>Context</code> 中，这样 <code>trace_id</code> 就可以串联起来了。</p><p><img src="https://s2.loli.net/2024/08/08/wfKZNacuBJeMDO1.png" alt="image.png"></p><p><img src="https://s2.loli.net/2024/08/08/NHOYS9R1EIZrBhd.png" alt="image.png"></p><p>上图就是 Pulsar 和 gRPC 传递 trace_id 的过程，数据都是存放在元数据中的，这里的 <code>traceparent</code> 的值本质上就是 trace_id.</p><blockquote><p>具体的代码细节我会在下一篇继续分析。</p></blockquote><h1 id="Metrics"><a href="#Metrics" class="headerlink" title="Metrics"></a>Metrics</h1><p><img src="https://s2.loli.net/2024/08/09/HfFnubtAKvJ8hVy.png"></p><p>Metrics 相对于 Trace 来说则是要简单许多，OpenTelemetry 定义了许多命名规范和标准，这样大家在复用社区的一些监控模板时就要更加容易一些。</p><h2 id="Metrics-Exemplars"><a href="#Metrics-Exemplars" class="headerlink" title="Metrics Exemplars"></a>Metrics Exemplars</h2><p><img src="https://s2.loli.net/2024/08/09/tOlkQFZBH421wri.png"></p><p>Metrics 还提供了一个 Exemplar 的功能，它的主要作用是可以将 Metrics 和 Trace 关联在一起，这样在通过 Metrics 发现问题时，就可以直接跳转到链路系统。</p><p>因为 trace_id 可以通过 MDC 和日志关联，所以我们可以直接通过 Metrics 定位具体应用的日志，这样排查问题的效率将会非常高。</p><h1 id="扩展信息"><a href="#扩展信息" class="headerlink" title="扩展信息"></a>扩展信息</h1><p>以上就是关于 OpenTelemetry 的整体架构，下面来扩展一些内容。</p><h2 id="eBPF"><a href="#eBPF" class="headerlink" title="eBPF"></a>eBPF</h2><p><img src="https://s2.loli.net/2024/08/16/KPxF6kvcBCX4JER.png"><br>eBPF 是一个运行在 Linux 内核中的虚拟机，它提供一套特殊的指令集并允许我们在不重新编译内核、也不需要重启应用的情况下加载自定义的逻辑。</p><p>eBPF 技术具有三大特点：</p><ul><li>第一是<strong>无侵入</strong>，动态挂载，目标进程无需重启，而且因为是 Linux 内核提供功能，所以与语言无关，任何语言都可以支持。</li><li>第二是<strong>高性能</strong>，eBPF 字节码会被 JIT 成机器码后执行，效率非常高；</li><li>第三是更加<strong>安全</strong>，它会运行在自己的沙箱环境中，不会导致目标进程崩溃。</li></ul><p>eBPF 虽然有很多优点，同时也有一些局限性，比如我想监控业务代码中的某个具体指标（订单创建数量），此时它就难以实现了，所以还得看我们的应用场景。<br>更适合一些云平台，或者更偏向底层的应用。</p><p>目前 eBPF 的应用场景还不够广泛，但假以时日一定会成为可观测领域的未来之星。</p><h2 id="SigNoz"><a href="#SigNoz" class="headerlink" title="SigNoz"></a><a href="https://signoz.io/">SigNoz</a></h2><p>不知道大家发现没有，如果我们直接 OpenTelemetry 技术栈会需要为 Trace、Metrics、Logs 选择不同的存储，而且他们的查询界面也分散在不同的地方。</p><p>那有没有一个统一的平台可以给我们提供完整的可观测体验呢？</p><p>有这样的需求那就有对应的厂商实现了：<br><img src="https://s2.loli.net/2024/08/09/YZbT3CrlGwoceDE.png"></p><p><a href="https://signoz.io/">SigNoz</a> 就是这样的平台，它将 OpenTelemetry-collector 和数据存储全部整合在了一起，同时全面兼容  OpenTelemetry；可以说它就是基于 OpenTelemetry 构建的一个可观测产品。</p><p>对于一些中小厂商，不想单独维护这些组件时是非常有用的。</p><h2 id="OpenObserve"><a href="#OpenObserve" class="headerlink" title="OpenObserve"></a><a href="https://openobserve.ai/">OpenObserve</a></h2><p><img src="https://s2.loli.net/2024/08/16/CuzXT7ts6vWQAEO.png" alt="image.png"></p><p><a href="https://openobserve.ai/">OpenObserve</a>在 SigNoz 的基础上做的更加极致一些，它提供了一个统一的存储可以存放日志、Trace、Metrics 等数据。</p><p>这样我们就可以只使用一个数据库存放所有的数据，同时它也提供了完整的 UI，并且也全面兼容 OpenTelemetry。</p><p>这样对于运维来说会更加简单，只是可能带来的副作用就是需要与它完全绑定。</p><h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>以上就是 OpenTelemetry 在企业的应用，大家可以根据自己的情况选择自建 OTel 的技术栈，还是选择 SigNoz 和 OpenObserve 这类的标准化产品。</p>]]></content>
    
    
    <summary type="html">&lt;h1 id=&quot;可观测性概念&quot;&gt;&lt;a href=&quot;#可观测性概念&quot; class=&quot;headerlink&quot; title=&quot;可观测性概念&quot;&gt;&lt;/a&gt;可观测性概念&lt;/h1&gt;&lt;p&gt;&lt;img src=&quot;https://s2.loli.net/2024/08/08/Sdot1TJUfWgNZyu.png&quot;&gt;&lt;br&gt;当一个软件或系统出于运行状态时，如果我们不对他加以观测，那它的运行状态对我们来说就是一个黑盒。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;如上图所示。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;我们只能通过业务的表象来判断它是否正常运行，无法在故障发生前进行预判，从而只能被动解决问题。&lt;/p&gt;</summary>
    
    
    
    <category term="OB" scheme="http://crossoverjie.top/categories/OB/"/>
    
    <category term="OpenTelemetry" scheme="http://crossoverjie.top/categories/OB/OpenTelemetry/"/>
    
    
    <category term="OpenTelemetry" scheme="http://crossoverjie.top/tags/OpenTelemetry/"/>
    
  </entry>
  
  <entry>
    <title>日志与追踪的完美融合：OpenTelemetry MDC 实践指南</title>
    <link href="http://crossoverjie.top/2024/09/05/ob/OpenTelemetry-client-log-mdc/"/>
    <id>http://crossoverjie.top/2024/09/05/ob/OpenTelemetry-client-log-mdc/</id>
    <published>2024-09-05T06:50:33.000Z</published>
    <updated>2024-09-10T13:41:32.260Z</updated>
    
    <content type="html"><![CDATA[<h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>在前面两篇实战文章中：</p><ul><li><a href="https://juejin.cn/post/7391744486979076146">OpenTelemetry 实战：从零实现分布式链路追踪</a></li><li><a href="https://juejin.cn/post/7394395254566846475">OpenTelemetry 实战：从零实现应用指标监控</a></li></ul><p>覆盖了可观测中的指标追踪和 <code>metrics</code> 监控，下面理应开始第三部分：<strong>日志</strong>。</p><p>但在开始日志之前还是要先将链路追踪和日志结合起来看看应用实际使用的实践。</p><p>通常我们排查问题的方式是先查询异常日志，判断是否是当前系统的问题。</p><p>如果不是，则在日志中捞出 <code>trace_id</code> 再到链路查询系统中查询链路，看看具体是哪个系统的问题，然后再做具体的排查。</p><p>类似于这样：<br><img src="https://s2.loli.net/2024/08/05/mP97tShHKrGXge2.png"><br>日志中会打印 <code>trace_id</code> 和 <code>span_id</code>。</p><blockquote><p>如果日志系统做的比较完善的话，还可以直接点击 <code>trace_id</code> 跳转到链路系统里直接查询链路信息。</p></blockquote><span id="more"></span><h1 id="MDC"><a href="#MDC" class="headerlink" title="MDC"></a>MDC</h1><p>这里的日志里关联 trace 信息的做法有个专有名词：MDC:(Mapped Diagnostic Context)。</p><p>简单来说就是用于排查问题的上下文信息，通常是由键值对组成，类似于这样的数据：</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="punctuation">&#123;</span>  </span><br><span class="line">  <span class="attr">&quot;timestamp&quot;</span> <span class="punctuation">:</span> <span class="string">&quot;2024-08-05 17:27:31.097&quot;</span><span class="punctuation">,</span>  </span><br><span class="line">  <span class="attr">&quot;level&quot;</span> <span class="punctuation">:</span> <span class="string">&quot;INFO&quot;</span><span class="punctuation">,</span>  </span><br><span class="line">  <span class="attr">&quot;thread&quot;</span> <span class="punctuation">:</span> <span class="string">&quot;http-nio-9191-exec-1&quot;</span><span class="punctuation">,</span>  </span><br><span class="line">  <span class="attr">&quot;mdc&quot;</span> <span class="punctuation">:</span> <span class="punctuation">&#123;</span>  </span><br><span class="line">    <span class="attr">&quot;trace_id&quot;</span> <span class="punctuation">:</span> <span class="string">&quot;26242f945af80b044a60226af00211fb&quot;</span><span class="punctuation">,</span>  </span><br><span class="line">    <span class="attr">&quot;trace_flags&quot;</span> <span class="punctuation">:</span> <span class="string">&quot;01&quot;</span><span class="punctuation">,</span>  </span><br><span class="line">    <span class="attr">&quot;span_id&quot;</span> <span class="punctuation">:</span> <span class="string">&quot;3a7842b3e28ed5c8&quot;</span>  </span><br><span class="line">  <span class="punctuation">&#125;</span><span class="punctuation">,</span>  </span><br><span class="line">  <span class="attr">&quot;logger&quot;</span> <span class="punctuation">:</span> <span class="string">&quot;com.example.demo.DemoApplication&quot;</span><span class="punctuation">,</span>  </span><br><span class="line">  <span class="attr">&quot;message&quot;</span> <span class="punctuation">:</span> <span class="string">&quot;request: name: \&quot;1232\&quot;\n&quot;</span><span class="punctuation">,</span>  </span><br><span class="line">  <span class="attr">&quot;context&quot;</span> <span class="punctuation">:</span> <span class="string">&quot;default&quot;</span>  </span><br><span class="line"><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure><p>在 Java 中的 Log4j 和 Logback 都有提供对应的实现。</p><p>如果我们使用了 OpenTelemetry 提供的 <code>javaagent</code> 再配合 <code>logback</code> 或者 <code>Log4j</code> 时就会自动具备打印 <code>MDC</code> 的能力：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">java -javaagent:/Users/chenjie/Downloads/blog-img/demo/opentelemetry-javaagent-2.4.0-SNAPSHOT.jar xx.jar</span><br></pre></td></tr></table></figure><p>比如我们只需要这样配置这样一个JSON 输出的 logback 即可：</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">appender</span> <span class="attr">name</span>=<span class="string">&quot;PROJECT_LOG&quot;</span> <span class="attr">class</span>=<span class="string">&quot;ch.qos.logback.core.rolling.RollingFileAppender&quot;</span>&gt;</span>  </span><br><span class="line">    <span class="tag">&lt;<span class="name">file</span>&gt;</span>$&#123;PATH&#125;/demo.log<span class="tag">&lt;/<span class="name">file</span>&gt;</span>  </span><br><span class="line">  </span><br><span class="line">    <span class="tag">&lt;<span class="name">rollingPolicy</span> <span class="attr">class</span>=<span class="string">&quot;ch.qos.logback.core.rolling.FixedWindowRollingPolicy&quot;</span>&gt;</span>  </span><br><span class="line">        <span class="tag">&lt;<span class="name">fileNamePattern</span>&gt;</span>$&#123;PATH&#125;/demo_%i.log<span class="tag">&lt;/<span class="name">fileNamePattern</span>&gt;</span>  </span><br><span class="line">        <span class="tag">&lt;<span class="name">maxIndex</span>&gt;</span>1<span class="tag">&lt;/<span class="name">maxIndex</span>&gt;</span>  </span><br><span class="line">    <span class="tag">&lt;/<span class="name">rollingPolicy</span>&gt;</span>  </span><br><span class="line">  </span><br><span class="line">    <span class="tag">&lt;<span class="name">triggeringPolicy</span> <span class="attr">class</span>=<span class="string">&quot;ch.qos.logback.core.rolling.SizeBasedTriggeringPolicy&quot;</span>&gt;</span>  </span><br><span class="line">        <span class="tag">&lt;<span class="name">maxFileSize</span>&gt;</span>100MB<span class="tag">&lt;/<span class="name">maxFileSize</span>&gt;</span>  </span><br><span class="line">    <span class="tag">&lt;/<span class="name">triggeringPolicy</span>&gt;</span>  </span><br><span class="line">  </span><br><span class="line">    <span class="tag">&lt;<span class="name">layout</span> <span class="attr">class</span>=<span class="string">&quot;ch.qos.logback.contrib.json.classic.JsonLayout&quot;</span>&gt;</span>  </span><br><span class="line">        <span class="tag">&lt;<span class="name">jsonFormatter</span>  </span></span><br><span class="line"><span class="tag">                <span class="attr">class</span>=<span class="string">&quot;ch.qos.logback.contrib.jackson.JacksonJsonFormatter&quot;</span>&gt;</span>  </span><br><span class="line">            <span class="tag">&lt;<span class="name">prettyPrint</span>&gt;</span>true<span class="tag">&lt;/<span class="name">prettyPrint</span>&gt;</span>  </span><br><span class="line">        <span class="tag">&lt;/<span class="name">jsonFormatter</span>&gt;</span>  </span><br><span class="line">        <span class="tag">&lt;<span class="name">timestampFormat</span>&gt;</span>yyyy-MM-dd&#x27; &#x27;HH:mm:ss.SSS<span class="tag">&lt;/<span class="name">timestampFormat</span>&gt;</span>  </span><br><span class="line">    <span class="tag">&lt;/<span class="name">layout</span>&gt;</span>  </span><br><span class="line">  </span><br><span class="line"><span class="tag">&lt;/<span class="name">appender</span>&gt;</span>  </span><br><span class="line">  </span><br><span class="line"><span class="tag">&lt;<span class="name">root</span> <span class="attr">level</span>=<span class="string">&quot;INFO&quot;</span>&gt;</span>  </span><br><span class="line">    <span class="tag">&lt;<span class="name">appender-ref</span> <span class="attr">ref</span>=<span class="string">&quot;STDOUT&quot;</span>/&gt;</span>  </span><br><span class="line">    <span class="tag">&lt;<span class="name">appender-ref</span> <span class="attr">ref</span>=<span class="string">&quot;PROJECT_LOG&quot;</span>/&gt;</span>  </span><br><span class="line"><span class="tag">&lt;/<span class="name">root</span>&gt;</span></span><br></pre></td></tr></table></figure><p><img src="https://s2.loli.net/2024/08/05/ba195iyS2hgnOVx.png"></p><p>就会在日志文件中输出 <code>JSON</code> 格式的日志，并且带上 <code>MDC</code> 的信息。</p><h1 id="自动-MDC-的原理"><a href="#自动-MDC-的原理" class="headerlink" title="自动 MDC 的原理"></a>自动 MDC 的原理</h1><p>我也比较好奇 OpenTelemetry 是如何自动写入 MDC 信息的，这里以 <code>logback</code> 为例。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Override</span>  </span><br><span class="line"><span class="keyword">public</span> ElementMatcher&lt;TypeDescription&gt; <span class="title function_">typeMatcher</span><span class="params">()</span> &#123;  </span><br><span class="line">  <span class="keyword">return</span> implementsInterface(named(<span class="string">&quot;ch.qos.logback.classic.spi.ILoggingEvent&quot;</span>));  </span><br><span class="line">&#125;  </span><br><span class="line">  </span><br><span class="line"><span class="meta">@Override</span>  </span><br><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">transform</span><span class="params">(TypeTransformer transformer)</span> &#123;  </span><br><span class="line">  transformer.applyAdviceToMethod(  </span><br><span class="line">      isMethod()  </span><br><span class="line">          .and(isPublic())  </span><br><span class="line">          .and(namedOneOf(<span class="string">&quot;getMDCPropertyMap&quot;</span>, <span class="string">&quot;getMdc&quot;</span>))  </span><br><span class="line">          .and(takesArguments(<span class="number">0</span>)),  </span><br><span class="line">      LoggingEventInstrumentation.class.getName() + <span class="string">&quot;$GetMdcAdvice&quot;</span>);  </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>会在调用 <code>ch.qos.logback.classic.spi.ILoggingEvent.getMDCPropertyMap()/getMdc()</code> 这两个函数中进行埋点。</p><blockquote><p>这些逻辑都是写在 javaagent 中的。</p></blockquote><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> Map&lt;String, String&gt; <span class="title function_">getMDCPropertyMap</span><span class="params">()</span> &#123;  </span><br><span class="line">    <span class="comment">// populate mdcPropertyMap if null  </span></span><br><span class="line">    <span class="keyword">if</span> (mdcPropertyMap == <span class="literal">null</span>) &#123;  </span><br><span class="line">        <span class="type">MDCAdapter</span> <span class="variable">mdc</span> <span class="operator">=</span> MDC.getMDCAdapter();  </span><br><span class="line">        <span class="keyword">if</span> (mdc <span class="keyword">instanceof</span> LogbackMDCAdapter)  </span><br><span class="line">            mdcPropertyMap = ((LogbackMDCAdapter) mdc).getPropertyMap();  </span><br><span class="line">        <span class="keyword">else</span>  </span><br><span class="line">            mdcPropertyMap = mdc.getCopyOfContextMap();  </span><br><span class="line">    &#125;    </span><br><span class="line">    <span class="comment">// mdcPropertyMap still null, use emptyMap()  </span></span><br><span class="line">    <span class="keyword">if</span> (mdcPropertyMap == <span class="literal">null</span>)  </span><br><span class="line">        mdcPropertyMap = Collections.emptyMap();  </span><br><span class="line">  </span><br><span class="line">    <span class="keyword">return</span> mdcPropertyMap;  </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这个函数其实默认情况下会返回一个 logback 内置 MDC 的 map 数据（这里的数据我们可以自定义配置）。</p><p>而这里要做的就是将 trace 的上下文信息写入这个 mdcPropertyMap 中。</p><p>以下是 OpenTelemetry agent 中的源码：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">Map&lt;String, String&gt; spanContextData = <span class="keyword">new</span> <span class="title class_">HashMap</span>&lt;&gt;();  </span><br><span class="line">  </span><br><span class="line"><span class="type">SpanContext</span> <span class="variable">spanContext</span> <span class="operator">=</span> Java8BytecodeBridge.spanFromContext(context).getSpanContext();  </span><br><span class="line">  </span><br><span class="line"><span class="keyword">if</span> (spanContext.isValid()) &#123;  </span><br><span class="line">  spanContextData.put(traceIdKey(), spanContext.getTraceId());  </span><br><span class="line">  spanContextData.put(spanIdKey(), spanContext.getSpanId());  </span><br><span class="line">  spanContextData.put(traceFlagsKey(), spanContext.getTraceFlags().asHex());  </span><br><span class="line">&#125;  </span><br><span class="line">spanContextData.putAll(ConfiguredResourceAttributesHolder.getResourceAttributes());  </span><br><span class="line">  </span><br><span class="line"><span class="keyword">if</span> (LogbackSingletons.addBaggage()) &#123;  </span><br><span class="line">  <span class="type">Baggage</span> <span class="variable">baggage</span> <span class="operator">=</span> Java8BytecodeBridge.baggageFromContext(context);  </span><br><span class="line">  </span><br><span class="line">  <span class="comment">// using a lambda here does not play nicely with instrumentation bytecode process  </span></span><br><span class="line">  <span class="comment">// (Java 6 related errors are observed) so relying on for loop instead  for (Map.Entry&lt;String, BaggageEntry&gt; entry : baggage.asMap().entrySet()) &#123;  </span></span><br><span class="line">    spanContextData.put(  </span><br><span class="line">        <span class="comment">// prefix all baggage values to avoid clashes with existing context  </span></span><br><span class="line">        <span class="string">&quot;baggage.&quot;</span> + entry.getKey(), entry.getValue().getValue());  </span><br><span class="line">  &#125;&#125;  </span><br><span class="line">  </span><br><span class="line"><span class="keyword">if</span> (contextData == <span class="literal">null</span>) &#123;  </span><br><span class="line">  contextData = spanContextData;  </span><br><span class="line">&#125; <span class="keyword">else</span> &#123;  </span><br><span class="line">  contextData = <span class="keyword">new</span> <span class="title class_">UnionMap</span>&lt;&gt;(contextData, spanContextData);  </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这就是核心的写入逻辑，从这个代码中也可以看出直接从上线文中获取的 span 的 context，而我们所需要的 <code>trace_id/span_id</code>  都是存放在 context 中的，只需要 get 出来然后写入进 map 中即可。</p><p>从源码里还得知，只要我们开启 <code>-Dotel.instrumentation.logback-mdc.add-baggage=true</code> 配置还可以将 baggage 中的数据也写入到 MDC 中。</p><p>而得易于 OpenTelemetry 中的 trace 是可以跨线程传输的，所以即便是我们在多线程里打印日志时 MDC 数据依然可以准确无误的传递。</p><h2 id="MDC-的原理"><a href="#MDC-的原理" class="headerlink" title="MDC 的原理"></a>MDC 的原理</h2><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="type">String</span> <span class="variable">MDC_ATTR_NAME</span> <span class="operator">=</span> <span class="string">&quot;mdc&quot;</span>;</span><br></pre></td></tr></table></figure><p><img src="https://s2.loli.net/2024/08/05/e7PIASyowDGO1sQ.png"></p><p>在 <code>logback</code> 的实现中是会调用刚才的 <code>getMDCPropertyMap()</code> 然后写入到一个 key 为 <code>mdc</code> 的 <code>map</code> 里，最终可以写入到文件或者控制台。</p><p>这样整个原理就可以串起来了。</p><h2 id="自定义日志-数据"><a href="#自定义日志-数据" class="headerlink" title="自定义日志 数据"></a>自定义日志 数据</h2><p>提到可以自定义 MDC 数据其实也是有使用场景的，比如我们的业务系统经常有类似的需求，需要在日志中打印一些常用业务数据：</p><ul><li>userId、userName</li><li>客户端 IP等信息时</li></ul><p>此时我们就可以创建一个 <code>Layout</code> 类来继承 <code>ch.qos.logback.contrib.json.classic.JsonLayout</code>:</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">CustomJsonLayout</span> <span class="keyword">extends</span> <span class="title class_">JsonLayout</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="title function_">CustomJsonLayout</span><span class="params">()</span> &#123;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">protected</span> <span class="keyword">void</span> <span class="title function_">addCustomDataToJsonMap</span><span class="params">(Map&lt;String, Object&gt; map, ILoggingEvent event)</span> &#123;</span><br><span class="line">        map.put(<span class="string">&quot;user_name&quot;</span>, context.getProperty(<span class="string">&quot;userName&quot;</span>));</span><br><span class="line">        map.put(<span class="string">&quot;user_id&quot;</span>, context.getProperty(<span class="string">&quot;userId&quot;</span>));</span><br><span class="line">        map.put(<span class="string">&quot;trace_id&quot;</span>, TraceContext.traceId());</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">CustomJsonLayoutEncoder</span> <span class="keyword">extends</span> <span class="title class_">LayoutWrappingEncoder</span>&lt;ILoggingEvent&gt; &#123;  </span><br><span class="line">    <span class="keyword">public</span> <span class="title function_">CustomJsonLayoutEncoder</span><span class="params">()</span> &#123;  </span><br><span class="line">    &#125;  </span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">start</span><span class="params">()</span> &#123;  </span><br><span class="line">        <span class="type">CustomJsonLayout</span> <span class="variable">jsonLayout</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">CustomJsonLayout</span>();  </span><br><span class="line">        jsonLayout.setContext(<span class="built_in">this</span>.context);  </span><br><span class="line">        jsonLayout.setIncludeContextName(<span class="literal">false</span>);  </span><br><span class="line">        jsonLayout.setAppendLineSeparator(<span class="literal">true</span>);  </span><br><span class="line">        jsonLayout.setJsonFormatter(<span class="keyword">new</span> <span class="title class_">JacksonJsonFormatter</span>());  </span><br><span class="line">        jsonLayout.start();  </span><br><span class="line">        <span class="built_in">super</span>.setCharset(StandardCharsets.UTF_8);  </span><br><span class="line">        <span class="built_in">super</span>.setLayout(jsonLayout);  </span><br><span class="line">        <span class="built_in">super</span>.start();  </span><br><span class="line">    &#125;&#125;</span><br></pre></td></tr></table></figure><blockquote><p>这里的 trace_id 是之前使用 skywalking 的时候由 skywalking 提供的函数：org.apache.skywalking.apm.toolkit.trace.TraceContext#traceId</p></blockquote><p>接着只需要在 <code>logback.xml</code> 中配置这个 <code>CustomJsonLayoutEncoder</code> 就可以按照我们自定义的数据输出日志了：</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">appender</span> <span class="attr">name</span>=<span class="string">&quot;PROJECT_LOG&quot;</span> <span class="attr">class</span>=<span class="string">&quot;ch.qos.logback.core.rolling.RollingFileAppender&quot;</span>&gt;</span>  </span><br><span class="line">    <span class="tag">&lt;<span class="name">file</span>&gt;</span>$&#123;PATH&#125;/app.log<span class="tag">&lt;/<span class="name">file</span>&gt;</span>  </span><br><span class="line">  </span><br><span class="line">    <span class="tag">&lt;<span class="name">rollingPolicy</span> <span class="attr">class</span>=<span class="string">&quot;ch.qos.logback.core.rolling.FixedWindowRollingPolicy&quot;</span>&gt;</span>  </span><br><span class="line">        <span class="tag">&lt;<span class="name">fileNamePattern</span>&gt;</span>$&#123;PATH&#125;/app_%i.log<span class="tag">&lt;/<span class="name">fileNamePattern</span>&gt;</span>  </span><br><span class="line">        <span class="tag">&lt;<span class="name">maxIndex</span>&gt;</span>1<span class="tag">&lt;/<span class="name">maxIndex</span>&gt;</span>  </span><br><span class="line">    <span class="tag">&lt;/<span class="name">rollingPolicy</span>&gt;</span>  </span><br><span class="line">  </span><br><span class="line">    <span class="tag">&lt;<span class="name">triggeringPolicy</span> <span class="attr">class</span>=<span class="string">&quot;ch.qos.logback.core.rolling.SizeBasedTriggeringPolicy&quot;</span>&gt;</span>  </span><br><span class="line">        <span class="tag">&lt;<span class="name">maxFileSize</span>&gt;</span>100MB<span class="tag">&lt;/<span class="name">maxFileSize</span>&gt;</span>  </span><br><span class="line">    <span class="tag">&lt;/<span class="name">triggeringPolicy</span>&gt;</span>  </span><br><span class="line">  </span><br><span class="line">    <span class="tag">&lt;<span class="name">encoder</span> <span class="attr">class</span>=<span class="string">&quot;xx.CustomJsonLayoutEncoder&quot;</span>/&gt;</span>  </span><br><span class="line"><span class="tag">&lt;/<span class="name">appender</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">root</span> <span class="attr">level</span>=<span class="string">&quot;INFO&quot;</span>&gt;</span>  </span><br><span class="line">    <span class="tag">&lt;<span class="name">appender-ref</span> <span class="attr">ref</span>=<span class="string">&quot;STDOUT&quot;</span>/&gt;</span>  </span><br><span class="line">    <span class="tag">&lt;<span class="name">appender-ref</span> <span class="attr">ref</span>=<span class="string">&quot;PROJECT_LOG&quot;</span>/&gt;</span>  </span><br><span class="line"><span class="tag">&lt;/<span class="name">root</span>&gt;</span></span><br></pre></td></tr></table></figure><p>虽然这个功能也可以使用日志切面来打印，但还是没有直接在日志中输出更加方便，它可以直接和我们的日志关联在一起，只是多加了这几个字段而已。</p><h2 id="Spring-Boot-使用"><a href="#Spring-Boot-使用" class="headerlink" title="Spring Boot 使用"></a>Spring Boot 使用</h2><p><code>OpenTelemetry</code> 有给 springboot 应用提供一个 <code>spring-boot-starter</code> 包，用于在不使用  <code>javaagent</code> 的情况下也可以自动埋点。</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependencies</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>io.opentelemetry.instrumentation<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>opentelemetry-spring-boot-starter<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>OPENTELEMETRY_VERSION<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependencies</span>&gt;</span></span><br></pre></td></tr></table></figure><p>但在早<a href="https://github.com/open-telemetry/opentelemetry-java-instrumentation/discussions/7653">期的版本</a>中还不支持直接打印 MDC 日志：<br><img src="https://s2.loli.net/2024/08/05/aunR8ApiMEoeJ1O.png" alt="image.png"></p><blockquote><p>最新的版本已经支持</p></blockquote><p>即便已经支持默认输出 MDC 后，我们依然可以自定义的内容，比如我们想修改一下 key 的名称，由 <code>trace_id</code> 修改为 <code>otel_trace_id</code> 等。</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">appender</span> <span class="attr">name</span>=<span class="string">&quot;OTEL&quot;</span> <span class="attr">class</span>=<span class="string">&quot;io.opentelemetry.instrumentation.logback.mdc.v1_0.OpenTelemetryAppender&quot;</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">traceIdKey</span>&gt;</span>otel_trace_id<span class="tag">&lt;/<span class="name">traceIdKey</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">spanIdKey</span>&gt;</span>otel_span_id<span class="tag">&lt;/<span class="name">spanIdKey</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">traceFlagsKey</span>&gt;</span>otel_trace_flags<span class="tag">&lt;/<span class="name">traceFlagsKey</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">appender</span>&gt;</span></span><br></pre></td></tr></table></figure><p>还是和之前类似，修改下 logback.xml 即可。</p><p><img src="https://s2.loli.net/2024/08/05/Y3zvfm6rUbxwtOK.png" alt="image.png"><br>他的实现逻辑其实和之前的 auto instrument 中的类似，只不过使用的 API 不同而已。</p><p>auto instrument 是直接拦截代码逻辑修改 map 的返回值，而 <code>OpenTelemetryAppender</code> 是继承了 <code>ch.qos.logback.core.UnsynchronizedAppenderBase</code> 接口，从而获得了重写 <code>MDC</code> 的能力，但本质上都是一样的，没有太大区别。</p><p>不过使用它的前提是我们需要引入以下一个依赖：</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependencies</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>io.opentelemetry.instrumentation<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>opentelemetry-logback-mdc-1.0<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>OPENTELEMETRY_VERSION<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependencies</span>&gt;</span></span><br></pre></td></tr></table></figure><p>如果不想修改 logback.yaml ，对于 <code>springboot</code> 来说还有更简单的方案，我们只需要使用以下配置即可自定义 MDC 数据：</p><figure class="highlight properties"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">logging.pattern.level</span> = <span class="string">trace_id=%mdc&#123;trace_id&#125; span_id=%mdc&#123;span_id&#125; trace_flags=%mdc&#123;trace_flags&#125; %5p</span></span><br></pre></td></tr></table></figure><p>这里的 key 也可以自定义，只要占位符没有取错即可。</p><blockquote><p>使用这个的前提是需要加载  javaagent，因为这里的数据是 javaagent 里写进去的。</p></blockquote><h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>以上就是关于 <code>MDC</code> 在 <code>OpenTelemetry</code> 中的使用，从使用和源码逻辑上都分析了一遍，希望对 <code>MDC</code> 和 <code>OpenTelemetry</code> 的理解更加深刻一些。</p><p>关于 MDC 相关的概念与使用还是很有用的，是日常排查问题必不可少的一个工具。</p>]]></content>
    
    
    <summary type="html">&lt;h1 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h1&gt;&lt;p&gt;在前面两篇实战文章中：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;https://juejin.cn/post/7391744486979076146&quot;&gt;OpenTelemetry 实战：从零实现分布式链路追踪&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://juejin.cn/post/7394395254566846475&quot;&gt;OpenTelemetry 实战：从零实现应用指标监控&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;覆盖了可观测中的指标追踪和 &lt;code&gt;metrics&lt;/code&gt; 监控，下面理应开始第三部分：&lt;strong&gt;日志&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;但在开始日志之前还是要先将链路追踪和日志结合起来看看应用实际使用的实践。&lt;/p&gt;
&lt;p&gt;通常我们排查问题的方式是先查询异常日志，判断是否是当前系统的问题。&lt;/p&gt;
&lt;p&gt;如果不是，则在日志中捞出 &lt;code&gt;trace_id&lt;/code&gt; 再到链路查询系统中查询链路，看看具体是哪个系统的问题，然后再做具体的排查。&lt;/p&gt;
&lt;p&gt;类似于这样：&lt;br&gt;&lt;img src=&quot;https://s2.loli.net/2024/08/05/mP97tShHKrGXge2.png&quot;&gt;&lt;br&gt;日志中会打印 &lt;code&gt;trace_id&lt;/code&gt; 和 &lt;code&gt;span_id&lt;/code&gt;。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;如果日志系统做的比较完善的话，还可以直接点击 &lt;code&gt;trace_id&lt;/code&gt; 跳转到链路系统里直接查询链路信息。&lt;/p&gt;
&lt;/blockquote&gt;</summary>
    
    
    
    <category term="OB" scheme="http://crossoverjie.top/categories/OB/"/>
    
    <category term="OpenTelemetry" scheme="http://crossoverjie.top/categories/OB/OpenTelemetry/"/>
    
    
    <category term="OpenTelemetry" scheme="http://crossoverjie.top/tags/OpenTelemetry/"/>
    
  </entry>
  
  <entry>
    <title>OpenTelemetry 实战：gRPC 监控的实现原理</title>
    <link href="http://crossoverjie.top/2024/08/29/ob/OpenTelemetry-grpc-principle/"/>
    <id>http://crossoverjie.top/2024/08/29/ob/OpenTelemetry-grpc-principle/</id>
    <published>2024-08-29T06:50:33.000Z</published>
    <updated>2024-09-03T15:08:51.463Z</updated>
    
    <content type="html"><![CDATA[<h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p><img src="https://s2.loli.net/2024/07/29/uUTYr8lziEABk4d.png"></p><p>最近在给 <code>opentelemetry-java-instrumentation</code> 提交了一个 <a href="https://github.com/open-telemetry/opentelemetry-java-instrumentation/pull/11833">PR</a>，是关于给 gRPC 新增四个 metrics：</p><ul><li><code>rpc.client.request.size</code>: 客户端请求包大小</li><li><code>rpc.client.response.size</code>：客户端收到的响应包大小</li><li><code>rpc.server.request.size</code>：服务端收到的请求包大小</li><li><code>rpc.server.response.size</code>：服务端响应的请求包大小</li></ul><p>这个 PR 的主要目的就是能够在指标监控中拿到 <code>RPC</code> 请求的包大小，而这里的关键就是如何才能拿到这些包的大小。</p><span id="more"></span><p>首先支持的是 <code>gRPC</code>（目前在云原生领域使用的最多），其余的 RPC 理论上也是可以支持的：<br><img src="https://s2.loli.net/2024/07/29/efGYRktoK8IESzP.png"></p><p>在实现的过程中我也比较好奇 <code>OpenTelemetry</code> 框架是如何给 <code>gRPC</code> 请求创建 <code>span</code> 调用链的，如下图所示：<br><img src="https://s2.loli.net/2024/07/15/skNmSDJaPfHh3GB.png" alt="image.png"><br><img src="https://s2.loli.net/2024/07/15/xoG2finOmFlDReE.png" alt="image.png"></p><blockquote><p>这是一个 gRPC 远程调用，java-demo 是 gRPC 的客户端，k8s-combat 是 gRPC 的服务端</p></blockquote><p>在开始之前我们可以根据 <code>OpenTelemetry</code> 的运行原理大概猜测下它的实现过程。</p><p>首先我们应用可以创建这些链路信息的前提是：使用了 <code>OpenTelemetry</code> 提供的 <code>javaagent</code>，这个 agent 的原理是在运行时使用了 <a href="https://github.com/raphw/byte-buddy">byte-buddy</a> 增强了我们应用的字节码，在这些字节码中代理业务逻辑，从而可以在不影响业务的前提下增强我们的代码（只要就是创建 span、metrics 等数据）</p><blockquote><p>Spring 的一些代理逻辑也是这样实现的</p></blockquote><h1 id="gRPC-增强原理"><a href="#gRPC-增强原理" class="headerlink" title="gRPC 增强原理"></a>gRPC 增强原理</h1><p>而在工程实现上，我们最好是不能对业务代码进行增强，而是要找到这些框架提供的扩展接口。</p><p>拿 <code>gRPC</code> 来说，我们可以使用它所提供的 <code>io.grpc.ClientInterceptor</code> 和 <code>io.grpc.ServerInterceptor</code> 接口来增强代码。</p><p>打开 <code>io.opentelemetry.instrumentation.grpc.v1_6.TracingClientInterceptor</code> 类我们可以看到它就是实现了 <code>io.grpc.ClientInterceptor</code>：<br><img src="https://s2.loli.net/2024/07/29/dVaESmoXIwJC6Li.png"></p><p>而其中最关键的就是要实现 <code>io.grpc.ClientInterceptor#interceptCall</code> 函数：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Override</span>  </span><br><span class="line"><span class="keyword">public</span> &lt;REQUEST, RESPONSE&gt; ClientCall&lt;REQUEST, RESPONSE&gt; <span class="title function_">interceptCall</span><span class="params">(  </span></span><br><span class="line"><span class="params">    MethodDescriptor&lt;REQUEST, RESPONSE&gt; method, CallOptions callOptions, Channel next)</span> &#123;  </span><br><span class="line">  <span class="type">GrpcRequest</span> <span class="variable">request</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">GrpcRequest</span>(method, <span class="literal">null</span>, <span class="literal">null</span>, next.authority());  </span><br><span class="line">  <span class="type">Context</span> <span class="variable">parentContext</span> <span class="operator">=</span> Context.current();  </span><br><span class="line">  <span class="keyword">if</span> (!instrumenter.shouldStart(parentContext, request)) &#123;  </span><br><span class="line">    <span class="keyword">return</span> next.newCall(method, callOptions);  </span><br><span class="line">  &#125;  </span><br><span class="line">  <span class="type">Context</span> <span class="variable">context</span> <span class="operator">=</span> instrumenter.start(parentContext, request);  </span><br><span class="line">  ClientCall&lt;REQUEST, RESPONSE&gt; result;  </span><br><span class="line">  <span class="keyword">try</span> (<span class="type">Scope</span> <span class="variable">ignored</span> <span class="operator">=</span> context.makeCurrent()) &#123;  </span><br><span class="line">    <span class="keyword">try</span> &#123;  </span><br><span class="line">      <span class="comment">// call other interceptors  </span></span><br><span class="line">      result = next.newCall(method, callOptions);  </span><br><span class="line">    &#125; <span class="keyword">catch</span> (Throwable e) &#123;  </span><br><span class="line">      instrumenter.end(context, request, Status.UNKNOWN, e);  </span><br><span class="line">      <span class="keyword">throw</span> e;  </span><br><span class="line">    &#125;  &#125;  </span><br><span class="line">  <span class="keyword">return</span> <span class="keyword">new</span> <span class="title class_">TracingClientCall</span>&lt;&gt;(result, parentContext, context, request);  </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这个接口是 <code>gRPC</code> 提供的拦截器接口，对于 <code>gRPC</code> 客户端来说就是在发起真正的网络调用前后会执行的方法。</p><p>所以在这个接口中我们就可以实现创建 span 获取包大小等逻辑。</p><h2 id="使用-byte-buddy-增强代码"><a href="#使用-byte-buddy-增强代码" class="headerlink" title="使用 byte-buddy 增强代码"></a>使用 byte-buddy 增强代码</h2><p>不过有一个问题是我们实现的 <code>io.grpc.ClientInterceptor</code> 类需要加入到拦截器中才可以使用：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">var</span> <span class="variable">managedChannel</span> <span class="operator">=</span> ManagedChannelBuilder.forAddress(host, port) .intercept(<span class="keyword">new</span> <span class="title class_">TracingClientInterceptor</span>()) <span class="comment">// 加入拦截器</span></span><br><span class="line">.usePlaintext()</span><br><span class="line">.build();</span><br></pre></td></tr></table></figure><p>但在 <code>javaagent</code> 中是没法给业务代码中加上这样的代码的。</p><p>此时就需要 <a href="https://bytebuddy.net/#/">byte-buddy</a> 登场了，它可以动态修改字节码从而实现类似于修改源码的效果。</p><p>在 <code>io.opentelemetry.javaagent.instrumentation.grpc.v1_6.GrpcClientBuilderBuildInstr umentation</code>  类里可以看到 <code>OpenTelemetry</code> 是如何使用 <code>byte-buddy</code> 的。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="keyword">public</span> ElementMatcher&lt;TypeDescription&gt; <span class="title function_">typeMatcher</span><span class="params">()</span> &#123;</span><br><span class="line">  <span class="keyword">return</span> extendsClass(named(<span class="string">&quot;io.grpc.ManagedChannelBuilder&quot;</span>))</span><br><span class="line">      .and(declaresField(named(<span class="string">&quot;interceptors&quot;</span>)));</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">transform</span><span class="params">(TypeTransformer transformer)</span> &#123;</span><br><span class="line">  transformer.applyAdviceToMethod(</span><br><span class="line">      isMethod().and(named(<span class="string">&quot;build&quot;</span>)),</span><br><span class="line">      GrpcClientBuilderBuildInstrumentation.class.getName() + <span class="string">&quot;$AddInterceptorAdvice&quot;</span>);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="meta">@SuppressWarnings(&quot;unused&quot;)</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">class</span> <span class="title class_">AddInterceptorAdvice</span> &#123;</span><br><span class="line"></span><br><span class="line">  <span class="meta">@Advice</span>.OnMethodEnter(suppress = Throwable.class)</span><br><span class="line">  <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">addInterceptor</span><span class="params">(</span></span><br><span class="line"><span class="params">      <span class="meta">@Advice</span>.This ManagedChannelBuilder&lt;?&gt; builder,</span></span><br><span class="line"><span class="params">      <span class="meta">@Advice</span>.FieldValue(<span class="string">&quot;interceptors&quot;</span>)</span> List&lt;ClientInterceptor&gt; interceptors) &#123;</span><br><span class="line">    VirtualField&lt;ManagedChannelBuilder&lt;?&gt;, Boolean&gt; instrumented =</span><br><span class="line">        VirtualField.find(ManagedChannelBuilder.class, Boolean.class);</span><br><span class="line">    <span class="keyword">if</span> (!Boolean.TRUE.equals(instrumented.get(builder))) &#123;</span><br><span class="line">      interceptors.add(<span class="number">0</span>, GrpcSingletons.CLIENT_INTERCEPTOR);</span><br><span class="line">      instrumented.set(builder, <span class="literal">true</span>);</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>从这里的源码可以看出，使用了 <code>byte-buddy</code> 拦截了 <code>io.grpc.ManagedChannelBuilder#intercept(java.util.List&lt;io.grpc.ClientInterceptor&gt;)</code> 函数。</p><blockquote><p>io.opentelemetry.javaagent.extension.matcher.AgentElementMatchers#extendsClass&#x2F; isMethod 等函数都是 byte-buddy 库提供的函数。</p></blockquote><p>而这个函数正好就是我们需要在业务代码里加入拦截器的地方。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">interceptors.add(<span class="number">0</span>, GrpcSingletons.CLIENT_INTERCEPTOR);</span><br><span class="line">GrpcSingletons.CLIENT_INTERCEPTOR = <span class="keyword">new</span> <span class="title class_">TracingClientInterceptor</span>(clientInstrumenter, propagators);</span><br></pre></td></tr></table></figure><p>通过这行代码可以手动将 <code>OpenTelemetry</code> 里的 <code>TracingClientInterceptor</code> 加入到拦截器列表中，并且作为第一个拦截器。</p><p>而这里的：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">extendsClass(named(<span class="string">&quot;io.grpc.ManagedChannelBuilder&quot;</span>))</span><br><span class="line">        .and(declaresField(named(<span class="string">&quot;interceptors&quot;</span>)))</span><br></pre></td></tr></table></figure><p>通过函数的名称也可以看出是为了找到 继承了<code>io.grpc.ManagedChannelBuilder</code> 类中存在成员变量 <code>interceptors</code> 的类。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">transformer.applyAdviceToMethod(  </span><br><span class="line">    isMethod().and(named(<span class="string">&quot;build&quot;</span>)),  </span><br><span class="line">    GrpcClientBuilderBuildInstrumentation.class.getName() + <span class="string">&quot;$AddInterceptorAdvice&quot;</span>);</span><br></pre></td></tr></table></figure><p>然后在调用 <code>build</code> 函数后就会进入自定义的 <code>AddInterceptorAdvice</code> 类，从而就可以拦截到添加拦截器的逻辑，然后把自定义的拦截器加入其中。</p><h1 id="获取-span-的-attribute"><a href="#获取-span-的-attribute" class="headerlink" title="获取 span 的 attribute"></a>获取 span 的 attribute</h1><p><img src="https://s2.loli.net/2024/07/29/dawSY4uQGmJo6qi.png"></p><p>我们在 gRPC 的链路中还可以看到这个请求的具体属性，比如：</p><ul><li>gRPC 服务提供的 IP 端口。</li><li>请求的响应码</li><li>请求的 service 和 method</li><li>线程等信息。<blockquote><p>这些信息在问题排查过程中都是至关重要的。</p></blockquote></li></ul><p>可以看到这里新的 <code>attribute</code> 主要是分为了三类：</p><ul><li><code>net.*</code> 是网络相关的属性</li><li><code>rpc.*</code> 是和 grpc 相关的属性</li><li><code>thread.*</code> 是线程相关的属性</li></ul><p>所以理论上我们在设计 API 时最好可以将这些不同分组的属性解耦开，如果是 MQ 相关的可能还有一些 topic 等数据，所以各个属性之间是互不影响的。</p><p>带着这个思路我们来看看 gRPC 这里是如何实现的。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">clientInstrumenterBuilder</span><br><span class="line">.setSpanStatusExtractor(GrpcSpanStatusExtractor.CLIENT)</span><br><span class="line">.addAttributesExtractors(additionalExtractors)</span><br><span class="line">        .addAttributesExtractor(RpcClientAttributesExtractor.create(rpcAttributesGetter))</span><br><span class="line">        .addAttributesExtractor(ServerAttributesExtractor.create(netClientAttributesGetter))</span><br><span class="line">        .addAttributesExtractor(NetworkAttributesExtractor.create(netClientAttributesGetter))</span><br></pre></td></tr></table></figure><p><code>OpenTelemetry</code> 会提供一个 <code>io.opentelemetry.instrumentation.api.instrumenter.InstrumenterBuilder#addAttributesExtractor</code>构建器函数，用于存放自定义的属性解析器。</p><p>从这里的源码可以看出分别传入了网络相关、RPC 相关的解析器；正好也就对应了图中的那些属性，也满足了我们刚才提到的解耦特性。</p><p>而每一个自定义属性解析器都需要实现接口 <code>io.opentelemetry.instrumentation.api.instrumenter.AttributesExtractor</code></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">interface</span> <span class="title class_">AttributesExtractor</span>&lt;REQUEST, RESPONSE&gt; &#123;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这里我们以 <code>GrpcRpcAttributesGetter</code> 为例。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">enum</span> <span class="title class_">GrpcRpcAttributesGetter</span> <span class="keyword">implements</span> <span class="title class_">RpcAttributesGetter</span>&lt;GrpcRequest&gt; &#123;</span><br><span class="line">  INSTANCE;</span><br><span class="line"></span><br><span class="line">  <span class="meta">@Override</span></span><br><span class="line">  <span class="keyword">public</span> String <span class="title function_">getSystem</span><span class="params">(GrpcRequest request)</span> &#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="string">&quot;grpc&quot;</span>;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="meta">@Override</span></span><br><span class="line">  <span class="meta">@Nullable</span></span><br><span class="line">  <span class="keyword">public</span> String <span class="title function_">getService</span><span class="params">(GrpcRequest request)</span> &#123;</span><br><span class="line">    <span class="type">String</span> <span class="variable">fullMethodName</span> <span class="operator">=</span> request.getMethod().getFullMethodName();</span><br><span class="line">    <span class="type">int</span> <span class="variable">slashIndex</span> <span class="operator">=</span> fullMethodName.lastIndexOf(<span class="string">&#x27;/&#x27;</span>);</span><br><span class="line">    <span class="keyword">if</span> (slashIndex == -<span class="number">1</span>) &#123;</span><br><span class="line">      <span class="keyword">return</span> <span class="literal">null</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> fullMethodName.substring(<span class="number">0</span>, slashIndex);</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure><p>可以看到 system 是写死的 <code>grpc</code>，也就是对于到页面上的 <code>rpc.system</code> 属性。</p><p>而这里的 <code>getService</code> 函数则是拿来获取 <code>rpc.service</code> 属性的，可以看到它是通过 <code>gRPC</code> <code>的method</code> 信息来获取 <code>service</code> 的。</p><hr><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">interface</span> <span class="title class_">RpcAttributesGetter</span>&lt;REQUEST&gt; &#123;  </span><br><span class="line">  </span><br><span class="line">  <span class="meta">@Nullable</span>  </span><br><span class="line">  String <span class="title function_">getService</span><span class="params">(REQUEST request)</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>而这里 <code>REQUEST</code> 其实是一个泛型，在 gRPC 里是 <code>GrpcRequest</code>，在其他 RPC 里这是对应的 RPC 的数据。</p><p>这个 <code>GrpcRequest</code> 是在我们自定义的拦截器中创建并传递的。<br><img src="https://s2.loli.net/2024/07/29/46mOv7XMoT81Bxl.png"></p><p>而我这里需要的请求包大小也是在拦截中获取到数据然后写入进 GrpcRequest。</p><p><img src="https://s2.loli.net/2024/07/29/A1zk79tVOr3DxnQ.png"></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">static</span> &lt;T&gt; Long <span class="title function_">getBodySize</span><span class="params">(T message)</span> &#123;  </span><br><span class="line">  <span class="keyword">if</span> (message <span class="keyword">instanceof</span> MessageLite) &#123;  </span><br><span class="line">    <span class="keyword">return</span> (<span class="type">long</span>) ((MessageLite) message).getSerializedSize();  </span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;  </span><br><span class="line">    <span class="comment">// Message is not a protobuf message  </span></span><br><span class="line">    <span class="keyword">return</span> <span class="literal">null</span>;  </span><br><span class="line">  &#125;&#125;</span><br></pre></td></tr></table></figure><p>这样就可以实现不同的 RPC 中获取自己的 <code>attribute</code>，同时每一组 <code>attribute</code> 也都是隔离的，互相解耦。</p><h1 id="自定义-metrics"><a href="#自定义-metrics" class="headerlink" title="自定义 metrics"></a>自定义 metrics</h1><p>每个插件自定义 Metrics 的逻辑也是类似的，需要由框架层面提供 API 接口：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> InstrumenterBuilder&lt;REQUEST, RESPONSE&gt; <span class="title function_">addOperationMetrics</span><span class="params">(OperationMetrics factory)</span> &#123;  </span><br><span class="line">  operationMetrics.add(requireNonNull(factory, <span class="string">&quot;operationMetrics&quot;</span>));  </span><br><span class="line">  <span class="keyword">return</span> <span class="built_in">this</span>;  </span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 客户端的 metrics</span></span><br><span class="line">.addOperationMetrics(RpcClientMetrics.get());</span><br><span class="line"></span><br><span class="line"><span class="comment">// 服务端的 metrics</span></span><br><span class="line">.addOperationMetrics(RpcServerMetrics.get());</span><br></pre></td></tr></table></figure><p>之后也会在框架层面回调这些自定义的 <code>OperationMetrics</code>:</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">   <span class="keyword">if</span> (operationListeners.length != <span class="number">0</span>) &#123;</span><br><span class="line">     <span class="comment">// operation listeners run after span start, so that they have access to the current span</span></span><br><span class="line">     <span class="comment">// for capturing exemplars</span></span><br><span class="line">     <span class="type">long</span> <span class="variable">startNanos</span> <span class="operator">=</span> getNanos(startTime);</span><br><span class="line">     <span class="keyword">for</span> (<span class="type">int</span> <span class="variable">i</span> <span class="operator">=</span> <span class="number">0</span>; i &lt; operationListeners.length; i++) &#123;</span><br><span class="line">       context = operationListeners[i].onStart(context, attributes, startNanos);</span><br><span class="line">     &#125;</span><br><span class="line">   &#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> (operationListeners.length != <span class="number">0</span>) &#123;  </span><br><span class="line">  <span class="type">long</span> <span class="variable">endNanos</span> <span class="operator">=</span> getNanos(endTime);  </span><br><span class="line">  <span class="keyword">for</span> (<span class="type">int</span> <span class="variable">i</span> <span class="operator">=</span> operationListeners.length - <span class="number">1</span>; i &gt;= <span class="number">0</span>; i--) &#123;  </span><br><span class="line">    operationListeners[i].onEnd(context, attributes, endNanos);  </span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这其中最关键的就是两个函数 onStart 和 onEnd，分别会在当前这个 span 的开始和结束时进行回调。</p><p>所以通常的做法是在 <code>onStart</code> 函数中初始化数据，然后在 <code>onEnd</code> 结束时统计结果，最终可以拿到 metrics 所需要的数据。</p><p>以这个 <code>rpc.client.duration</code> 客户端的请求耗时指标为例：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Override</span>  </span><br><span class="line"><span class="keyword">public</span> Context <span class="title function_">onStart</span><span class="params">(Context context, Attributes startAttributes, <span class="type">long</span> startNanos)</span> &#123;  </span><br><span class="line">  <span class="keyword">return</span> context.with(  </span><br><span class="line">      RPC_CLIENT_REQUEST_METRICS_STATE,  </span><br><span class="line">      <span class="keyword">new</span> <span class="title class_">AutoValue_RpcClientMetrics_State</span>(startAttributes, startNanos));  </span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="meta">@Override</span>  </span><br><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">onEnd</span><span class="params">(Context context, Attributes endAttributes, <span class="type">long</span> endNanos)</span> &#123;  </span><br><span class="line">  <span class="type">State</span> <span class="variable">state</span> <span class="operator">=</span> context.get(RPC_CLIENT_REQUEST_METRICS_STATE);</span><br><span class="line"><span class="type">Attributes</span> <span class="variable">attributes</span> <span class="operator">=</span> state.startAttributes().toBuilder().putAll(endAttributes).build();  </span><br><span class="line">clientDurationHistogram.record(  </span><br><span class="line">    (endNanos - state.startTimeNanos()) / NANOS_PER_MS, attributes, context);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>在开始时记录下当前的时间，结束时获取当前时间和结束时间的差值正好就是这个 span 的执行时间，也就是 rpc client 的处理时间。</p><p>在 <code>OpenTelemetry</code> 中绝大多数的请求时间都是这么记录的。</p><h1 id="Golang-增强"><a href="#Golang-增强" class="headerlink" title="Golang 增强"></a>Golang 增强</h1><p>而在 <code>Golang</code> 中因为没有 <a href="https://bytebuddy.net/#/">byte-buddy</a> 这种魔法库的存在，不可以直接修改源码，所以通常的做法还是得硬编码才行。</p><p>还是以 <code>gRPC</code> 为例，我们在创建 gRPC server 时就得指定一个 <code>OpenTelemetry</code> 提供的函数。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">s := grpc.NewServer(  </span><br><span class="line">    grpc.StatsHandler(otelgrpc.NewServerHandler()),  </span><br><span class="line">)</span><br></pre></td></tr></table></figure><p><img src="https://s2.loli.net/2024/07/29/RP9LWQVKSOF1d4Z.png"></p><p> 在这个 SDK 中也会实现刚才在 Java 里类似的逻辑，限于篇幅具体逻辑就不细讲了。</p><h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>以上就是 <code>gRPC</code> 在 <code>OpenTelemetry</code> 中的具体实现，主要就是在找到需要增强框架是否有提供扩展的接口，如果有就直接使用该接口进行埋点。</p><p>如果没有那就需要查看源码，找到核心逻辑，再使用 <code>byte-buddy</code> 进行埋点。</p><p><img src="https://s2.loli.net/2024/07/30/h1uvr3EjA9fGmzR.png"></p><p>比如 Pulsar 并没有在客户端提供一些扩展接口，只能找到它的核心函数进行埋点。</p><p>而在具体埋点过程中 <code>OpenTelemetry</code> 提供了许多解耦的 API，方便我们实现埋点所需要的业务逻辑，也会在后续的文章继续分析 <code>OpenTelemetry</code> 的一些设计原理和核心 API 的使用。</p><p>这部分 API 的设计我觉得是 <code>OpenTelemetry</code> 中最值得学习的地方。</p><p>参考链接：</p><ul><li><a href="https://bytebuddy.net/#/">https://bytebuddy.net/#/</a></li><li><a href="https://opentelemetry.io/docs/specs/semconv/rpc/rpc-metrics/#metric-rpcserverrequestsize">https://opentelemetry.io/docs/specs/semconv/rpc/rpc-metrics/#metric-rpcserverrequestsize</a></li></ul>]]></content>
    
    
    <summary type="html">&lt;h1 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h1&gt;&lt;p&gt;&lt;img src=&quot;https://s2.loli.net/2024/07/29/uUTYr8lziEABk4d.png&quot;&gt;&lt;/p&gt;
&lt;p&gt;最近在给 &lt;code&gt;opentelemetry-java-instrumentation&lt;/code&gt; 提交了一个 &lt;a href=&quot;https://github.com/open-telemetry/opentelemetry-java-instrumentation/pull/11833&quot;&gt;PR&lt;/a&gt;，是关于给 gRPC 新增四个 metrics：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;rpc.client.request.size&lt;/code&gt;: 客户端请求包大小&lt;/li&gt;
&lt;li&gt;&lt;code&gt;rpc.client.response.size&lt;/code&gt;：客户端收到的响应包大小&lt;/li&gt;
&lt;li&gt;&lt;code&gt;rpc.server.request.size&lt;/code&gt;：服务端收到的请求包大小&lt;/li&gt;
&lt;li&gt;&lt;code&gt;rpc.server.response.size&lt;/code&gt;：服务端响应的请求包大小&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;这个 PR 的主要目的就是能够在指标监控中拿到 &lt;code&gt;RPC&lt;/code&gt; 请求的包大小，而这里的关键就是如何才能拿到这些包的大小。&lt;/p&gt;</summary>
    
    
    
    <category term="OB" scheme="http://crossoverjie.top/categories/OB/"/>
    
    <category term="OpenTelemetry" scheme="http://crossoverjie.top/categories/OB/OpenTelemetry/"/>
    
    
    <category term="OpenTelemetry" scheme="http://crossoverjie.top/tags/OpenTelemetry/"/>
    
  </entry>
  
</feed>
