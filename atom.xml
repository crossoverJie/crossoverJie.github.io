<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>crossoverJie&#39;s Blog</title>
  
  <subtitle>baller</subtitle>
  <link href="http://crossoverjie.top/atom.xml" rel="self"/>
  
  <link href="http://crossoverjie.top/"/>
  <updated>2025-08-04T02:30:26.808Z</updated>
  <id>http://crossoverjie.top/</id>
  
  <author>
    <name>crossoverJie</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>StarRocks 如何在本地搭建存算分离集群</title>
    <link href="http://crossoverjie.top/2025/08/04/ob/StarRocks-shard-data-cluster/"/>
    <id>http://crossoverjie.top/2025/08/04/ob/StarRocks-shard-data-cluster/</id>
    <published>2025-08-04T02:30:26.807Z</published>
    <updated>2025-08-04T02:30:26.808Z</updated>
    
    <content type="html"><![CDATA[<p>之前写过一篇 <a href="https://crossoverjie.top/2025/02/26/ob/StarRocks-dev-shard-data-build/">StarRocks 开发环境搭建踩坑指北之存算分离篇</a>讲解如何在本地搭建一个可以 debug 的存算分离版本。</p><p>但最近在本地调试一个场景，需要 CN 节点是以集群的方式启动，我还是按照<a href="https://crossoverjie.top/2025/02/26/ob/StarRocks-dev-shard-data-build/">老方法</a>通过 docker 启动 CN，然后 export 端口的方式让 FE 进行绑定。</p><p>比如用以下两个命令可以启动两个 CN 节点。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker run -p 9060:9060 -p 8040:8040 -p 9050:9050 -p 8060:8060 -p 9070:9070 -itd --rm --name cn -e &quot;TZ=Asia/Shanghai&quot; starrocks/cn-ubuntu:3.5.2</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker run -p 9061:9060 -p 8041:8040 -p 9051:9050 -p 8061:8060 -p 9071:9070 -itd --rm --name cn2 -e &quot;TZ=Asia/Shanghai&quot; starrocks/cn-ubuntu:3.5.2</span><br></pre></td></tr></table></figure><span id="more"></span><p>然后按照之前的方式在 FE 中手动绑定这两个节点：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">ALTER</span> <span class="keyword">SYSTEM</span> <span class="keyword">ADD</span> COMPUTE NODE &quot;127.0.0.1:9050&quot;;  </span><br><span class="line"><span class="keyword">ALTER</span> <span class="keyword">SYSTEM</span> <span class="keyword">ADD</span> COMPUTE NODE &quot;127.0.0.1:9051&quot;;  </span><br><span class="line"><span class="keyword">show</span> compute nodes;</span><br></pre></td></tr></table></figure><p><img src="https://s2.loli.net/2025/08/01/9moNIdYTbqr3Kvu.png"></p><p>此时会出现新增的第二个节点的状态有问题，比如 <code>metrics</code> 取不到，<code>workerId</code> 是-1（-1 代表节点创建失败了，默认值是 -1)</p><p><img src="https://s2.loli.net/2025/08/01/gEvlLsZYOHG53Q4.png"><br><img src="https://s2.loli.net/2025/08/01/c6Cr4PxsR8o7UzH.png"><br>经过 debug 发现是在添加节点的时候，由于生成的 <code>workerIpPort</code> 与上一个节点相同（<code>127.0.0.1:9060)</code> 从而导致这个节点被跳过了。</p><p>也就是说我这两个 CN 节点不能是相同的 IP（用不同的端口来区分）。</p><p>解决这个问题有以下几个办法：</p><ul><li>再找一个台机器来跑 CN2 节点</li><li>启动一个虚拟机来跑 CN2 节点</li><li>使用 docker compose 来启动 CN 集群，会在集群内自动分配不同的 IP</li><li>利用 Docker Bridge 创建一个虚拟网络，由他来分配 IP</li></ul><p>第一种方案直接 Pass 了，我手上没有多余的设备。</p><p>第二种方案倒是可以直接用 <code>OrbStack</code> 启动一个 VM，但是还不如后面的 docker 来的轻量，此外还需要我安装运行环境，也 pass 了。</p><p>第三种方案看似可行，但也比较繁琐，由于 CN 给 docker compose 管理了，FE 要和 CN 网络打通也得在 docker compose 里运行，这样我 Debug 就不方便了，更别提如果需要频繁修改源码的情况。</p><blockquote><p>甚至每次修改代码后都得重新打包上传镜像，以及开启 remote debug，非常麻烦。</p></blockquote><p>这么看来就第四种方案最为合适了。</p><h1 id="使用-Docker-Bridge-网络"><a href="#使用-Docker-Bridge-网络" class="headerlink" title="使用 Docker Bridge 网络"></a>使用 Docker Bridge 网络</h1><p>我们可以使用 Docker Bridge 创建一个虚拟网络，使用这个虚拟网络启动的镜像会自动分配自定义范围的 IP；同时本地启动的 FE 也能直接访问。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker network create --subnet=172.18.0.0/16 --gateway=172.18.0.1 my_custom_net</span><br></pre></td></tr></table></figure><p>首先用 docker 创建一个 network。</p><ul><li><code>--subnet=172.18.0.0/16</code>: 定义网络的 IP 地址范围。这里我们使用了 <code>172.18.x.x</code> 这个私有网段。</li><li><code>--gateway=172.18.0.1</code>: 指定这个网络的网关地址。</li></ul><p>之后我们就可以使用这个虚拟网络来启动容器了。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">docker run --ip 172.18.0.20 --net my_custom_net -p 9060:9060 -p 8040:8040 -p 9050:9050 -p 8060:8060 -p 9070:9070 -itd --rm --name cn -e &quot;TZ=Asia/Shanghai&quot; starrocks/cn-ubuntu:3.5.2</span><br><span class="line"></span><br><span class="line">docker run --ip 172.18.0.30 --net my_custom_net -p 9061:9060 -p 8041:8040 -p 9051:9050 -p 8061:8060 -p 9071:9070 -itd --rm --name cn2 -e &quot;TZ=Asia/Shanghai&quot; starrocks/cn-ubuntu:3.5.2</span><br></pre></td></tr></table></figure><p>这样这两个容器就会被分配不同的 IP，并且网络和宿主机也是互通的。</p><p>需要注意的是这里的子网尽量选择 <code>172.16.0.0</code> 到 <code>172.31.255.255</code> 这个 IP 段，<code>192.168.0.0</code> 到 <code>192.168.255.255</code> 这个范围段很有可能家里或公司的路由器占用了。</p><p>而这里的网关 <code>--gateway=172.18.0.1</code>地址也需要在我们自定义的 IP 范围里。</p><p>同时我们也不需要在这两个容器内为 CN 指定 <code>priority_networks</code> 参数了。</p><p>同理 <code>minio</code> 也得使用这个虚拟网络启动：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">docker run -d --rm --name minio \</span><br><span class="line">  --ip 172.18.0.10 \</span><br><span class="line">  --net my_custom_net \</span><br><span class="line">  -e MINIO_ROOT_USER=miniouser \</span><br><span class="line">  -e MINIO_ROOT_PASSWORD=miniopassword \</span><br><span class="line">  -p 9001:9001 \</span><br><span class="line">  -p 9000:9000 \</span><br><span class="line">  --entrypoint sh \</span><br><span class="line">  minio/minio:latest \</span><br><span class="line">  -c &#x27;mkdir -p /minio_data/starrocks &amp;&amp; minio server /minio_data --console-address &quot;:9001&quot;&#x27;</span><br></pre></td></tr></table></figure><p>设置 <code>token</code> 的时候也要指定对应的 IP:</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mc alias set myminio http://172.18.0.10:9000 miniouser miniopassword; mc admin user svcacct add --access-key AAAAAAAAAAAAAAAAAAAA --secret-key BBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBB myminio miniouser</span><br></pre></td></tr></table></figure><p>当 CN 和 minio 都启动之后，我们在 FE 里手动绑定这两个 CN 节点:</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">ALTER</span> <span class="keyword">SYSTEM</span> <span class="keyword">ADD</span> COMPUTE NODE &quot;172.18.0.20:9050&quot;;</span><br><span class="line"><span class="keyword">ALTER</span> <span class="keyword">SYSTEM</span> <span class="keyword">ADD</span> COMPUTE NODE &quot;172.18.0.30:9050&quot;</span><br></pre></td></tr></table></figure><p>这样这两个节点就可以绑定成功了。</p><p>#Blog </p>]]></content>
    
    
    <summary type="html">&lt;p&gt;之前写过一篇 &lt;a href=&quot;https://crossoverjie.top/2025/02/26/ob/StarRocks-dev-shard-data-build/&quot;&gt;StarRocks 开发环境搭建踩坑指北之存算分离篇&lt;/a&gt;讲解如何在本地搭建一个可以 debug 的存算分离版本。&lt;/p&gt;
&lt;p&gt;但最近在本地调试一个场景，需要 CN 节点是以集群的方式启动，我还是按照&lt;a href=&quot;https://crossoverjie.top/2025/02/26/ob/StarRocks-dev-shard-data-build/&quot;&gt;老方法&lt;/a&gt;通过 docker 启动 CN，然后 export 端口的方式让 FE 进行绑定。&lt;/p&gt;
&lt;p&gt;比如用以下两个命令可以启动两个 CN 节点。&lt;/p&gt;
&lt;figure class=&quot;highlight shell&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;docker run -p 9060:9060 -p 8040:8040 -p 9050:9050 -p 8060:8060 -p 9070:9070 -itd --rm --name cn -e &amp;quot;TZ=Asia/Shanghai&amp;quot; starrocks/cn-ubuntu:3.5.2&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;

&lt;figure class=&quot;highlight shell&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;docker run -p 9061:9060 -p 8041:8040 -p 9051:9050 -p 8061:8060 -p 9071:9070 -itd --rm --name cn2 -e &amp;quot;TZ=Asia/Shanghai&amp;quot; starrocks/cn-ubuntu:3.5.2&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;</summary>
    
    
    
    <category term="OB" scheme="http://crossoverjie.top/categories/OB/"/>
    
    <category term="StarRocks" scheme="http://crossoverjie.top/categories/OB/StarRocks/"/>
    
    
    <category term="StarRocks" scheme="http://crossoverjie.top/tags/StarRocks/"/>
    
  </entry>
  
  <entry>
    <title>StarRocks 物化视图创建与刷新全流程解析</title>
    <link href="http://crossoverjie.top/2025/06/27/ob/StarRocks-create-sync/"/>
    <id>http://crossoverjie.top/2025/06/27/ob/StarRocks-create-sync/</id>
    <published>2025-06-27T09:34:15.000Z</published>
    <updated>2025-07-01T09:55:03.471Z</updated>
    
    <content type="html"><![CDATA[<p>最近在为 StarRocks 的物化视图增加<a href="https://github.com/StarRocks/starrocks/pull/60035">多表达式支持</a>的能力，于是便把物化视图（MV）的创建刷新流程完成的捋了一遍。</p><p>之前也写过一篇：<a href="https://crossoverjie.top/2024/11/18/ob/StarRocks-MV-refresh-Principle/">StarRocks 物化视图刷新流程和原理</a>，主要分析了刷新的流程，以及刷新的条件。</p><p>这次从头开始，从 MV 的创建开始来看看 StarRocks 是如何管理物化视图的。</p><h1 id="创建物化视图"><a href="#创建物化视图" class="headerlink" title="创建物化视图"></a>创建物化视图</h1><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE</span></span><br><span class="line">MATERIALIZED <span class="keyword">VIEW</span> mv_test99</span><br><span class="line">REFRESH ASYNC <span class="keyword">EVERY</span>(<span class="type">INTERVAL</span> <span class="number">60</span> <span class="keyword">MINUTE</span>)</span><br><span class="line"><span class="keyword">PARTITION</span> <span class="keyword">BY</span> p_time</span><br><span class="line">PROPERTIES (</span><br><span class="line">&quot;partition_refresh_number&quot; <span class="operator">=</span> &quot;1&quot;</span><br><span class="line">)</span><br><span class="line"><span class="keyword">AS</span></span><br><span class="line"><span class="keyword">select</span> date_trunc(&quot;day&quot;, a.datekey) <span class="keyword">as</span> p_time, <span class="built_in">sum</span>(a.v1) <span class="keyword">as</span> <span class="keyword">value</span></span><br><span class="line"><span class="keyword">from</span> par_tbl1 a</span><br><span class="line"><span class="keyword">group</span> <span class="keyword">by</span> p_time, a.item_id</span><br></pre></td></tr></table></figure><span id="more"></span><p>创建物化视图的时候首先会进入这个函数：<code>com.starrocks.sql.analyzer.MaterializedViewAnalyzer.MaterializedViewAnalyzerVisitor#visitCreateMaterializedViewStatement</code></p><p><img src="https://s2.loli.net/2025/07/01/UNapLOkBosmY95F.png"></p><blockquote><p>其实就是将我们的创建语句结构化为一个 <code>CreateMaterializedViewStatement</code> 对象，这个过程是使用 ANTLR 实现的。</p></blockquote><p>这个函数负责对创建物化视图的 SQL 语句进行语义分析、和基本的校验。</p><p>比如：</p><ul><li>分区表达式是否正确</li><li>基表、数据库这些的格是否正确</li></ul><p><img src="https://s2.loli.net/2025/07/01/9hXceIt5E6LauAK.png"></p><blockquote><p>校验分区分区表达式的各种信息。</p></blockquote><p>然后会进入函数：<code>com.starrocks.server.LocalMetastore#createMaterializedView()</code></p><p>这个函数的主要作用如下：</p><ol><li><p><strong>检查数据库和物化视图是否存在</strong>。</p></li><li><p><strong>初始化物化视图的基本信息</strong>：</p><ul><li>获取物化视图的列定义（schema）</li><li>验证列定义的合法性</li><li>初始化物化视图的属性（如分区信息）。</li></ul></li><li><p><strong>处理刷新策略</strong>：</p><ul><li>根据刷新类型（如 <code>ASYNC</code>、<code>SYNC</code>、<code>MANUAL</code> 或 <code>INCREMENTAL</code>）设置刷新方案。</li><li>对于异步刷新，设置刷新间隔、开始时间等，并进行参数校验。</li></ul></li><li><p><strong>创建物化视图对象</strong>：</p><ul><li>根据运行模式（存算分离和存算一体）创建不同类型的物化视图对象</li><li>设置物化视图的索引、排序键、注释、基础表信息等。</li></ul></li><li><p><strong>处理分区逻辑</strong>：</p><ul><li>如果物化视图是非分区的，创建单一分区并设置相关属性。</li><li>如果是分区的，解析分区表达式并生成分区映射关系</li></ul></li><li><p><strong>绑定存储卷</strong>：</p><ul><li>如果物化视图是云原生类型，绑定存储卷。<br><img src="https://s2.loli.net/2025/07/01/8B45JZMejnPmLNG.png"></li></ul></li></ol><h2 id="序列化关键数据"><a href="#序列化关键数据" class="headerlink" title="序列化关键数据"></a>序列化关键数据</h2><p>对于一些核心数据，比如分区表达式、原始的创建 SQL 等，需要再重启的时候可以再次加载到内存里供后续使用时；</p><p>就需要将这些数据序列化到元数据里。</p><p>这些数据定期保存在 <code>fe/meta</code> 目录中。<br><img src="https://s2.loli.net/2024/09/27/3C4GaXM5BlWmNIw.png"></p><p>我们需要序列化的字段需要使用 <code>@SerializedName</code>注解。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@SerializedName(value = &quot;partitionExprMaps&quot;)</span>  </span><br><span class="line"><span class="keyword">private</span> Map&lt;ExpressionSerializedObject, ExpressionSerializedObject&gt; serializedPartitionExprMaps;</span><br></pre></td></tr></table></figure><p>同时在 <code>com.starrocks.catalog.MaterializedView#gsonPreProcess/gsonPostProcess</code> 这两个函数中将数据序列化和反序列化。</p><h3 id="元数据的同步与加载"><a href="#元数据的同步与加载" class="headerlink" title="元数据的同步与加载"></a>元数据的同步与加载</h3><p>当 StarRocks 的 FE 集群部署时，会由 leader 的 FE 启动一个 checkpoint 线程，定时扫描当前的元数据是否需要生成一个 <code>image.$&#123;JournalId&#125;</code> 的文件。</p><p><img src="https://s2.loli.net/2024/09/20/lQCkBnNWIZ4GwuV.png"></p><blockquote><p>其实就是判断当前日志数量是否达到上限（默认是 5w）生成一次。</p></blockquote><p>具体的流程如下：<br><img src="https://s2.loli.net/2024/09/27/zgy6ZaQ7b1ceWkm.png"><br><img src="https://s2.loli.net/2024/09/27/QiTHLpOfJ19oAam.png"></p><p><img src="https://i.imgur.com/txqTt0U.png"></p><p>更多元数据同步和加载流程可以查看我之前的文章：<a href="https://crossoverjie.top/2024/11/11/ob/StarRocks-meta/">深入理解 StarRocks 的元数据管理</a></p><h1 id="刷新物化视图"><a href="#刷新物化视图" class="headerlink" title="刷新物化视图"></a>刷新物化视图</h1><p>创建完成后会立即触发一次 MV 的刷新逻辑。</p><h2 id="同步分区"><a href="#同步分区" class="headerlink" title="同步分区"></a>同步分区</h2><p><img src="https://s2.loli.net/2025/07/01/RiFufPw3bOa8H9T.png"><br>刷新 MV 的时候有一个很重要的步骤：<strong>同步 MV 和基表的分区</strong>。</p><blockquote><p>这个步骤在每次刷新的时候都会做，只是如果基表分区和 MV 相比没有变化的话就会跳过。</p></blockquote><p>这里我们以常用的 <code>Range</code> 分区为例，核心的函数为：<code>com.starrocks.scheduler.mv.MVPCTRefreshRangePartitioner#syncAddOrDropPartitions</code></p><p>它的主要作用是同步物化视图的分区，添加、删除分区来保持 MV 的分区与基础表的分区一致；核心流程：</p><ol><li><strong>计算分区差异</strong>：根据指定的分区范围，计算物化视图与基础表之间的分区差异。</li><li>同步分区：<ol><li><strong>删除旧分区</strong>：删除物化视图中与基础表不再匹配的分区。</li><li><strong>添加新分区</strong>：根据计算出的差异，添加新的分区到物化视图。</li></ol></li></ol><p><img src="https://s2.loli.net/2025/07/01/oi8tkKVCebH4Q5E.png"></p><p>分区同步完成之后就可以计算需要刷新的分区了：<br><img src="https://s2.loli.net/2024/11/14/QljDLmRrx97EIK6.png" alt="image.png"></p><p>以上内容再结合之前的两篇文章：</p><ul><li><a href="https://crossoverjie.top/2024/11/18/ob/StarRocks-MV-refresh-Principle/">StarRocks 物化视图刷新流程和原理</a></li><li><a href="https://crossoverjie.top/2024/11/11/ob/StarRocks-meta/">深入理解 StarRocks 的元数据管理</a></li></ul><p>就可以将整个物化视图的创建与刷新的核心流程掌握了。</p><p>#StarRocks #Blog </p>]]></content>
    
    
    <summary type="html">&lt;p&gt;最近在为 StarRocks 的物化视图增加&lt;a href=&quot;https://github.com/StarRocks/starrocks/pull/60035&quot;&gt;多表达式支持&lt;/a&gt;的能力，于是便把物化视图（MV）的创建刷新流程完成的捋了一遍。&lt;/p&gt;
&lt;p&gt;之前也写过一篇：&lt;a href=&quot;https://crossoverjie.top/2024/11/18/ob/StarRocks-MV-refresh-Principle/&quot;&gt;StarRocks 物化视图刷新流程和原理&lt;/a&gt;，主要分析了刷新的流程，以及刷新的条件。&lt;/p&gt;
&lt;p&gt;这次从头开始，从 MV 的创建开始来看看 StarRocks 是如何管理物化视图的。&lt;/p&gt;
&lt;h1 id=&quot;创建物化视图&quot;&gt;&lt;a href=&quot;#创建物化视图&quot; class=&quot;headerlink&quot; title=&quot;创建物化视图&quot;&gt;&lt;/a&gt;创建物化视图&lt;/h1&gt;&lt;figure class=&quot;highlight sql&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;11&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;CREATE&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;MATERIALIZED &lt;span class=&quot;keyword&quot;&gt;VIEW&lt;/span&gt; mv_test99&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;REFRESH ASYNC &lt;span class=&quot;keyword&quot;&gt;EVERY&lt;/span&gt;(&lt;span class=&quot;type&quot;&gt;INTERVAL&lt;/span&gt; &lt;span class=&quot;number&quot;&gt;60&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;MINUTE&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;PARTITION&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;BY&lt;/span&gt; p_time&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;PROPERTIES (&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&amp;quot;partition_refresh_number&amp;quot; &lt;span class=&quot;operator&quot;&gt;=&lt;/span&gt; &amp;quot;1&amp;quot;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;AS&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;select&lt;/span&gt; date_trunc(&amp;quot;day&amp;quot;, a.datekey) &lt;span class=&quot;keyword&quot;&gt;as&lt;/span&gt; p_time, &lt;span class=&quot;built_in&quot;&gt;sum&lt;/span&gt;(a.v1) &lt;span class=&quot;keyword&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;value&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;from&lt;/span&gt; par_tbl1 a&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;group&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;by&lt;/span&gt; p_time, a.item_id&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;</summary>
    
    
    
    <category term="OB" scheme="http://crossoverjie.top/categories/OB/"/>
    
    
    <category term="StarRocks" scheme="http://crossoverjie.top/tags/StarRocks/"/>
    
  </entry>
  
  <entry>
    <title>关于 Golang 的错误处理的讨论可以大结局了</title>
    <link href="http://crossoverjie.top/2025/06/05/ob/go-error-future/"/>
    <id>http://crossoverjie.top/2025/06/05/ob/go-error-future/</id>
    <published>2025-06-05T09:08:57.000Z</published>
    <updated>2025-06-06T08:35:14.903Z</updated>
    
    <content type="html"><![CDATA[<p>  原文链接：<a href="https://go.dev/blog/error-syntax">[ On | No ] syntactic support for error handling</a></p><hr><p>关于 Go 语言最有争论的就是错误处理：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">x, err := call()</span><br><span class="line"><span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">        <span class="comment">// handle err</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><code>if err != nil</code> 类似于这样的代码非常多，淹没了其余真正有用的代码。这通常发生在进行大量API调用的代码中，其中错误处理很普遍，只是简单地返回错误，有些最终的代码看起来像这样：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">printSum</span><span class="params">(a, b <span class="type">string</span>)</span></span> <span class="type">error</span> &#123;</span><br><span class="line">    x, err := strconv.Atoi(a)</span><br><span class="line">    <span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> err</span><br><span class="line">    &#125;</span><br><span class="line">    y, err := strconv.Atoi(b)</span><br><span class="line">    <span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> err</span><br><span class="line">    &#125;</span><br><span class="line">    fmt.Println(<span class="string">&quot;result:&quot;</span>, x + y)</span><br><span class="line">    <span class="keyword">return</span> <span class="literal">nil</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><span id="more"></span><p>在这个函数的十行代码中，只有四行看起来是有实际的作用。其余六行看起来甚至会影响主要的逻辑。所以关于错误处理的抱怨多年来一直位居我们年度用户调查的榜首也就不足为奇了。（有一段时间，缺乏泛型支持超过了对错误处理的抱怨，但现在 Go 已经支持泛型了，错误处理又回到了榜首。）</p><p>Go团队认真对待社区反馈，因此多年来我们一直在尝试为这个问题找到解决方案，并听取 Go 社区的意见。</p><p>Go 团队的第一次明确尝试可以追溯到 2018 年，当时Russ Cox<a href="https://go.googlesource.com/proposal/+/master/design/go2draft-error-handling-overview.md">正式提到了这个问题</a>，作为我们当时称为 Go2 努力的一部分。他基于 Marcel van Lohuizen 的<a href="https://go.googlesource.com/proposal/+/master/design/go2draft-error-handling.md">草案设计</a>概述了一个可能的解决方案。该设计基于<code>check</code>和<code>handle</code>机制，相当全面。草案包括对替代解决方案的详细分析，包括与其他语言采用的方法的比较。如果您想知道您的特定错误处理想法之前是否被考虑过，请阅读这份文档！</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// printSum implementation using the proposed check/handle mechanism.</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">printSum</span><span class="params">(a, b <span class="type">string</span>)</span></span> <span class="type">error</span> &#123;</span><br><span class="line">    handle err &#123; <span class="keyword">return</span> err &#125;</span><br><span class="line">    x := check strconv.Atoi(a)</span><br><span class="line">    y := check strconv.Atoi(b)</span><br><span class="line">    fmt.Println(<span class="string">&quot;result:&quot;</span>, x + y)</span><br><span class="line">    <span class="keyword">return</span> <span class="literal">nil</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><code>check</code>和<code>handle</code>方法被认为过于复杂，大约一年后，在2019年，我们推出了更加简化的、现在<a href="https://go.dev/issue/32437#issuecomment-2278932700">臭名昭著</a>的<a href="https://go.googlesource.com/proposal/+/master/design/32437-try-builtin.md"><code>try</code>提案</a>。它基于 <code>check</code> 和 <code>handle</code> 的思想，但 <code>check</code> 伪关键字变成了<code>try</code>内置函数，<code>handle</code>部分被省略了。为了探索<code>try</code>内置函数的影响，我们编写了一个简单的工具（<a href="https://github.com/griesemer/tryhard">tryhard</a>），使用<code>try</code>重写现有的错误处理代码。这个提案被激烈争论，在<a href="https://go.dev/issue/32437">GitHub问题</a>上接近900条评论。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// printSum implementation using the proposed try mechanism.</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">printSum</span><span class="params">(a, b <span class="type">string</span>)</span></span> <span class="type">error</span> &#123;</span><br><span class="line">    <span class="comment">// use a defer statement to augment errors before returning</span></span><br><span class="line">    x := try(strconv.Atoi(a))</span><br><span class="line">    y := try(strconv.Atoi(b))</span><br><span class="line">    fmt.Println(<span class="string">&quot;result:&quot;</span>, x + y)</span><br><span class="line">    <span class="keyword">return</span> <span class="literal">nil</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>然而，<code>try</code>通过在出错时从封闭函数返回来影响控制流，并且可能从深度嵌套的表达式中这样做，从而隐藏了这种控制流。这使得该提案对许多人来说难以接受，尽管在这个提案上投入了大量精力，我们还是决定放弃这项工作。回顾起来，引入一个新关键字可能会更好，这是我们现在可以做的事情，因为我们通过<code>go.mod</code>文件和特定文件的指令对语言版本有细粒度的控制。将<code>try</code>的使用限制在赋值和语句中可能会缓解一些其他的担忧。Jimmy Frasche的<a href="https://go.dev/issue/73376">最近提案</a>基本上回到了原始的<code>check</code>和<code>handle</code>设计，并解决了该设计的一些缺点，正朝着这个方向发展。</p><p><code>try</code>提案的反响导致了大量的反思，包括Russ Cox的一系列博客文章：<a href="https://research.swtch.com/proposals-intro">“关于Go提案流程的思考”</a>。其中一个结论是，我们可能通过提出一个几乎完全成熟的提案，给社区反馈留下很少的空间，以及一个”具有威胁性”的实现时间表，从而降低了获得更好结果的机会。根据<a href="https://research.swtch.com/proposals-large">“Go提案流程：大型变更”</a>：”回顾起来，<code>try</code>是一个足够大的变更，我们发布的新设计应该是第二版草案设计，而不是带有实现时间表的提案”。但不管在这种情况下可能存在的流程和沟通失败，用户对该提案有着非常强烈地抵触情绪。</p><p>当时我们没有更好的解决方案，几年来都没有为错误处理追求语法变更。不过，社区中的许多人受到了启发，我们收到了源源不断的错误处理提案，其中许多非常相似，有些有趣，有些难以理解，有些不可行。为了跟踪不断扩大的提案，一年后，Ian Lance Taylor 创建了一个<a href="https://go.dev/issue/40432">总体问题</a>，总结了改进错误处理的提议变更的当前状态。创建了一个<a href="https://go.dev/wiki/Go2ErrorHandlingFeedback">Go Wiki</a>来收集相关的反馈、讨论和文章。</p><p>关于错误处理冗长性的抱怨持续存在（参见<a href="https://go.dev/blog/survey2024-h1-results">2024年上半年Go开发者调查结果</a>），因此，在Go团队内部提案经过一系列日益完善之后，Ian Lance Taylor 在2024年发布了<a href="https://go.dev/issue/71203">“使用<code>?</code>减少错误处理样板代码”</a>。这次的想法是借鉴<a href="https://www.rust-lang.org/">Rust</a>中实现的构造，特别是<a href="https://doc.rust-lang.org/std/result/index.html#the-question-mark-operator-"><code>?</code>操作符</a>。希望通过依靠使用既定符号的现有机制，并考虑我们多年来学到的东西，我们应该能够最终取得一些进展。在一小批用户调研中，向开发者展示使用 <code>?</code> 的 Go 代码时，绝大多数参与者正确猜出了代码的含义，这进一步说服我们再试一次。为了能够看到变化的影响，Ian 编写了一个工具，将普通 Go 代码转换为使用提议的新语法的代码，我们还在编译器中对该功能进行了原型设计。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// printSum implementation using the proposed &quot;?&quot; statements.</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">printSum</span><span class="params">(a, b <span class="type">string</span>)</span></span> <span class="type">error</span> &#123;</span><br><span class="line">    x := strconv.Atoi(a) ?</span><br><span class="line">    y := strconv.Atoi(b) ?</span><br><span class="line">    fmt.Println(<span class="string">&quot;result:&quot;</span>, x + y)</span><br><span class="line">    <span class="keyword">return</span> <span class="literal">nil</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>不幸的是，与其他错误处理想法一样，这个新提案也很快被评论淹没，许多人建议进行微调，通常基于个人偏好。Ian关闭了提案，并将内容移到了<a href="https://go.dev/issue/71460">讨论区</a>，以促进对话并收集进一步的反馈。一个稍作修改的版本得到了<a href="https://github.com/golang/go/discussions/71460#discussioncomment-12060294">稍微积极一些</a>的接受，但广泛的支持仍然难以达成一致。</p><p>经过这么多年的尝试，Go团队提出了三个完整的提案，社区提出了数百个提案，其中大多数是各类提案的变体，所有这些都未能获得足够（更不用说压倒性）的支持，我们现在面临的问题是：如何继续？我们是否应该继续？</p><p><em>我们认为不应该。</em></p><p>更准确地说，我们应该停止尝试解决_语法问题_，至少在可预见的未来是这样。<a href="https://github.com/golang/proposal?tab=readme-ov-file#consensus-and-disagreement">提案流程</a>为这个决定提供了理由：</p><blockquote><p>提案流程的目标是及时就结果达成普遍共识。如果提案审查无法在问题跟踪器上的问题讨论中确定普遍共识，通常的结果是提案被拒绝。</p></blockquote><p>没有一个错误处理提案达到任何接近共识的程度，所以它们都被拒绝了。即使是 Google 的 Go 团队最资深的成员也不一致同意目前最佳的方案（也许在某个时候会改变）。但是没有具体的共识，我们就无法合理地向前推进。</p><p>有支持现状的有效证据： </p><ul><li><p>如果 Go 早期就为错误处理引入了特定的语法糖，今天几乎没有人会争论它。但我们已经走过了15年，机会已经过去了，Go 有一种完全合适的错误处理方式，即使有时看起来可能很冗长。</p></li><li><p>从另一个角度看，假设我们今天找到了完美的解决方案。将其纳入语言只会导致从一个不满意的用户群体（支持变更的）转移到另一个（喜欢现状的）。当我们决定向语言添加泛型时，我们处于类似的情况，尽管有一个重要的区别是：今天没有人被迫使用泛型，好的泛型库的编写使得用户可以基本忽略它们是不是泛型，这要归功于类型推断。相反，如果向语言添加新的错误处理语法构造，几乎每个人都需要开始使用它，以免他们的代码变得不符合最新的范式。</p></li><li><p>不添加额外的语法符合 Go 的设计规则之一：不提供多种做同一件事的方式。在” foot traffic “的领域有这个规则的例外：赋值就是一个例子。具有讽刺意味的是，在<a href="https://go.dev/ref/spec#Short_variable_declarations">短变量声明</a>（<code>:=</code>）中重新声明变量的能力是为了解决因错误处理而产生的问题而引入的：没有重新声明，错误检查序列需要为每个检查使用不同名称的<code>err</code>变量（或额外的单独变量声明）。当时更好的解决方案可能是为错误处理提供更多的语法支持。那样的话，可能就不需要重新声明规则了，没有它各种相关的<a href="https://go.dev/issue/377">复杂性</a>也就不存在了。</p></li><li><p>回到实际的错误处理代码，如果错误得到处理，冗长性就会被淡化。良好的错误处理通常需要向错误添加额外信息。例如，用户调查中的一个反复出现的评论是关于缺少与错误相关的堆栈信息。这可以通过生成并返回增强错误的支持函数来解决。在这个例子中，模板代码的相对数量要小得多：</p></li></ul><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">printSum</span><span class="params">(a, b <span class="type">string</span>)</span></span> <span class="type">error</span> &#123;</span><br><span class="line">    x, err := strconv.Atoi(a)</span><br><span class="line">    <span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> fmt.Errorf(<span class="string">&quot;invalid integer: %q&quot;</span>, a)</span><br><span class="line">    &#125;</span><br><span class="line">    y, err := strconv.Atoi(b)</span><br><span class="line">    <span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> fmt.Errorf(<span class="string">&quot;invalid integer: %q&quot;</span>, b)</span><br><span class="line">    &#125;</span><br><span class="line">    fmt.Println(<span class="string">&quot;result:&quot;</span>, x + y)</span><br><span class="line">    <span class="keyword">return</span> <span class="literal">nil</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li>新的标准库功能也可以帮助减少错误处理样板代码，这与Rob Pike 2015年的博客文章<a href="https://go.dev/blog/errors-are-values">“错误就是值”</a>的观点非常相似。例如在某些情况下，<a href="https://go.dev/pkg/cmp#Or"><code>cmp.Or</code></a>可用于一次处理一系列错误：</li></ul><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">printSum</span><span class="params">(a, b <span class="type">string</span>)</span></span> <span class="type">error</span> &#123;</span><br><span class="line">    x, err1 := strconv.Atoi(a)</span><br><span class="line">    y, err2 := strconv.Atoi(b)</span><br><span class="line">    <span class="keyword">if</span> err := cmp.Or(err1, err2); err != <span class="literal">nil</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> err</span><br><span class="line">    &#125;</span><br><span class="line">    fmt.Println(<span class="string">&quot;result:&quot;</span>, x+y)</span><br><span class="line">    <span class="keyword">return</span> <span class="literal">nil</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li><p>编写、阅读和调试代码都是完全不同的工作。编写重复的错误检查可能很乏味，但今天的 IDE 提供了强大的、甚至是 LLM 辅助的代码补全。编写基本的错误检查对这些工具来说很简单。在阅读代码时冗长性最明显，但工具在这里也可能有所帮助；例如，有 Go 语言设置的 IDE 可以提供一个切换开关来隐藏错误处理代码。</p></li><li><p>在调试错误处理代码时，能够快速添加<code>println</code>或有一个专门的行位置来在调试器中设置断点会很有帮助。当已经有专门的<code>if</code>语句时，这很容易。但如果所有错误处理逻辑都隐藏在<code>check</code>、<code>try</code>或<code>?</code>后面，代码可能必须首先更改为普通的<code>if</code>语句，这会使调试复杂化，甚至可能引入一些错误。</p></li><li><p>还有实际的考虑：想出一个新的错误处理语法想法很容易；因此社区提出了大量的提案。想出一个经得起审查的好解决方案：就不那么容易了。正确设计语言变更并实际实现它需要协调一致的努力。真正的成本仍然在后面：所有需要更改的代码、需要更新的文档、需要调整的工具。综合考虑，语法变更非常昂贵，Go 团队相对较小，还有很多其他优先事项要处理。</p></li><li><p>最后一点，我们中的一些人最近有机会参加<a href="https://cloud.withgoogle.com/next/25">Google Cloud Next 2025</a>，Go团队在那里有一个展位，我们还举办了一个小型的Go聚会。我们有机会询问的每一位Go用户都坚决认为我们不应该为了更好的错误处理而改变语言。许多人提到，当刚从另一种具有错误处理支持的语言转过来时，Go中缺乏特定的错误处理支持最为明显。随着人们使用的时间越来越久，这个问题变得不那么重要了。这当然不是一个足够大的代表性人群，但它是我们在 GitHub上 看到的不同人群。</p></li></ul><p>当然，也有支持变更的理由：</p><ul><li><p>缺乏更好的错误处理支持仍然是我们用户调查中最大的抱怨。如果Go团队真的认真对待用户反馈，我们最终应该为此做些什么。（尽管似乎也没有<a href="https://github.com/golang/go/discussions/71460#discussioncomment-11977299">压倒性的支持</a>语言变更。）</p></li><li><p>也许单一地关注减少字符数不是一个正确的方向。更好的方法可能是使用关键字使默认错误处理高度可见，同时也要删除模板代码（<code>err != nil</code>）。这种方法可能使读者（代码审查者）更容易看到错误被处理了，而不需要”看多次”，从而提高代码质量和安全性。这将使我们回到<code>check</code>和<code>handle</code>的起点。</p></li><li><p>我们真的不知道现在的冗长问题在多大程度上是错误检查直接导致的。</p></li></ul><p>尽管如此，迄今为止没有任何解决错误处理的尝试获得足够的支持。如果我们诚实地评估我们所处的位置，我们只能承认我们既没有对问题的共同理解，也不是都同意首先存在问题。考虑到这一点，我们做出以下符合当下的决定：</p><p>_在可预见的未来，Go团队将停止为错误处理追求语法语言变更。我们还将关闭所有主要涉及错误处理语法的开放和即将提交的提案，不再进一步跟进。</p><p>社区在探索、讨论和辩论这些问题上投入了巨大的努力。虽然这可能没有导致错误处理语法的任何变化，但这些努力已经为 Go 语言和我们的流程带来了许多其他改进。也许，在未来的某个时候，关于错误处理会出现更清晰的图景。在那之前，我们期待着将这种令人难以置信的热情集中在新的机会上，让Go对每个人都变得更好。</p><h1 id="总结一下"><a href="#总结一下" class="headerlink" title="总结一下"></a>总结一下</h1><ol><li><p><strong>问题背景</strong>：Go的错误处理一直被认为过于冗长，多年来一直是用户调查中的首先被抱怨的。</p></li><li><p><strong>历次尝试</strong>：</p><ul><li>2018年的 <code>check</code> 和 <code>handle</code> 机制</li><li>2019年的 <code>try</code> 提案</li><li>2024年的 <code>?</code> 操作符提案</li></ul></li><li><p><strong>最终决定</strong>：经过多年尝试和数百个提案，Go团队决定在可预见的未来停止追求错误处理的语法变更，主要原因包括：</p><ul><li>没有达成共识</li><li>现有方式虽然冗长但足够好</li><li>改变会造成社区分裂</li><li>工具和库可以帮助缓解问题</li></ul></li><li><p><strong>未来方向</strong>：团队将关注其他改进Go语言的机会，而不是继续在错误处理语法上投入精力。</p></li></ol><p>由于  Go 长期没有错误处理的解决方案，导致这个问题被拖了很久，从而每个开发者也都有自己的使用习惯，越多人参与讨论就越难以达成一致。</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;  原文链接：&lt;a href=&quot;https://go.dev/blog/error-syntax&quot;&gt;[ On | No ] syntactic support for error handling&lt;/a&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;关于 Go 语言最有争论的就是错误处理：&lt;/p&gt;
&lt;figure class=&quot;highlight go&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;x, err := call()&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;if&lt;/span&gt; err != &lt;span class=&quot;literal&quot;&gt;nil&lt;/span&gt; &amp;#123;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        &lt;span class=&quot;comment&quot;&gt;// handle err&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&amp;#125;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;


&lt;p&gt;&lt;code&gt;if err != nil&lt;/code&gt; 类似于这样的代码非常多，淹没了其余真正有用的代码。这通常发生在进行大量API调用的代码中，其中错误处理很普遍，只是简单地返回错误，有些最终的代码看起来像这样：&lt;/p&gt;
&lt;figure class=&quot;highlight go&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;12&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;function&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;func&lt;/span&gt; &lt;span class=&quot;title&quot;&gt;printSum&lt;/span&gt;&lt;span class=&quot;params&quot;&gt;(a, b &lt;span class=&quot;type&quot;&gt;string&lt;/span&gt;)&lt;/span&gt;&lt;/span&gt; &lt;span class=&quot;type&quot;&gt;error&lt;/span&gt; &amp;#123;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    x, err := strconv.Atoi(a)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &lt;span class=&quot;keyword&quot;&gt;if&lt;/span&gt; err != &lt;span class=&quot;literal&quot;&gt;nil&lt;/span&gt; &amp;#123;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        &lt;span class=&quot;keyword&quot;&gt;return&lt;/span&gt; err&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &amp;#125;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    y, err := strconv.Atoi(b)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &lt;span class=&quot;keyword&quot;&gt;if&lt;/span&gt; err != &lt;span class=&quot;literal&quot;&gt;nil&lt;/span&gt; &amp;#123;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        &lt;span class=&quot;keyword&quot;&gt;return&lt;/span&gt; err&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &amp;#125;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    fmt.Println(&lt;span class=&quot;string&quot;&gt;&amp;quot;result:&amp;quot;&lt;/span&gt;, x + y)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &lt;span class=&quot;keyword&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;literal&quot;&gt;nil&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&amp;#125;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;</summary>
    
    
    
    <category term="OB" scheme="http://crossoverjie.top/categories/OB/"/>
    
    
  </entry>
  
  <entry>
    <title>我的 CodeReview 实战经验</title>
    <link href="http://crossoverjie.top/2025/05/21/ob/codereview-practice/"/>
    <id>http://crossoverjie.top/2025/05/21/ob/codereview-practice/</id>
    <published>2025-05-21T02:39:04.000Z</published>
    <updated>2025-05-29T06:14:21.603Z</updated>
    
    <content type="html"><![CDATA[<h1 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h1><p>Code Review 是大家日常开发过程中很常见的流程，当然也不排除一些团队为了快速上线，只要功能测试没问题就直接省去了 Code Review。</p><p>我个人觉得再忙的团队  Code Review 还是很有必要的（甚至可以事后再 Review），好处很多：</p><ul><li>跳出个人开发的思维误区，更容易发现问题</li><li>增进团队交流，提高整体的技术氛围</li><li>团队水平检测器，不管是审核者还是被审核的，review 几次后大概就知道是什么水平了</li></ul><p>通常 Code Review 有两种场景，一种是公司内部，还有就是开源社区。</p><span id="more"></span><h1 id="开源社区"><a href="#开源社区" class="headerlink" title="开源社区"></a>开源社区</h1><p>先说开源社区，最近也在做 <a href="https://github.com/crossoverJie/cim/pull/170">cim</a> 项目里做 Review，同时也在 Pulsar、OpenTelemetry、StarRocks 这些项目里做过 Reviewer。</p><p>以下是一些我参与 Code Review 的一些经验：</p><h2 id="先提-issue"><a href="#先提-issue" class="headerlink" title="先提 issue"></a>先提 issue</h2><p>在提交 PR 进行 Code Review 之前最好先提交一个 issue 和社区讨论下，你的这个改动社区是否接受。</p><p>我见过一些事前没有提前沟通，然后提交了一个很复杂的 PR，会导致维护者很难 Review，同时也会打击参与者的积极性。</p><p>所以强烈建议一些复杂的修改一定先要提前和社区沟通，除非这是一些十拿九稳的问题。</p><h2 id="个人-CI"><a href="#个人-CI" class="headerlink" title="个人 CI"></a>个人 CI</h2><p>一些大型项目往往都有完善的 CI 流程来保证代码质量，通常都有以下的校验：</p><ul><li>各种测试流程（单元测试、集成测试）</li><li>代码 Code Style 检测</li><li>安全、依赖检测等</li></ul><p>如果一个 PR 连 CI 都没跑过，其实也没有提前 Review 的必要了，所以在提 PR 之前都建议先在自己的 repo 里将主要的 CI 都跑过再提交 PR。</p><p>这个在 Pulsar 的<a href="https://pulsar.apache.org/contribute/personal-ci/">官方贡献流程</a>里也有单独提到。<br><img src="https://s2.loli.net/2025/05/26/kYQj1ecNCs3HbaB.png"></p><p><img src="https://s2.loli.net/2025/05/26/eImx2GPq5AsbBap.png"></p><p>同时在 <a href="https://github.com/apache/pulsar/blob/master/.github/PULL_REQUEST_TEMPLATE.md">PR 模板</a>里也有提到，建议先在自己的 fork 的 repo 里完成 CI 之后再提交到 <code>upstream</code>。</p><p><img src="https://s2.loli.net/2025/05/29/3KhSawogqksm1I9.png"></p><p>这个其实也很简单，我们只要给自己的 repo 提交一个 PR，然后在 repo 设置中开启 Action，之后就会触发 CI 了。</p><p><img src="https://s2.loli.net/2025/05/26/QqpCzHJnjGV2R8P.png"></p><p>如果自己的 PR 还需要频繁的提交修改，那建议可以先修改为  draft，这样可以提醒维护者稍后再做 Review。</p><p>同时也不建议提交一个过大的 PR，尽量控制在 500 行改动以内，这样才方便 Review。</p><h2 id="Review-代码"><a href="#Review-代码" class="headerlink" title="Review 代码"></a>Review 代码</h2><p><img src="https://s2.loli.net/2025/05/29/RtXAc1KYJ5FhDfG.png"></p><p>Github 有提供代码对比页面，但也只是简单的代码高亮，没法像 IDE 这样提供函数跳转等功能。</p><p><img src="https://s2.loli.net/2025/05/26/2kAVKWr45T7ZFRg.png"></p><p>所以对于 Reviewer 来说，最好是在本地 IDE 中添加 PR 的 repo，这样就可以直接切换到 PR 的分支，然后再本地跟代码，也更好调试。</p><p>有相关的修改建议可以直接在 github 页面上进行评论，这样两者结合起来 Review，效率会更高。</p><p>Review 代码其实不比写代码轻松，所以对免费帮你做 Review 的要多保持一些瑞思拜。</p><h2 id="AI-Review"><a href="#AI-Review" class="headerlink" title="AI Review"></a>AI Review</h2><p>现在 Github 已经支持 copilot 自动 Review 了，它可以帮我们总结变更，同时对一些参加的错误提供修改建议。<br><img src="https://s2.loli.net/2025/05/26/1jBs9oOcMQ4t3e5.png"></p><p>使用它还是可以帮我们省不少事情，推荐开启。</p><h1 id="企业内部"><a href="#企业内部" class="headerlink" title="企业内部"></a>企业内部</h1><p>在企业内部做 Code Review 流程上要简单许多，毕竟沟通成本要低一些，往往都是达成一致之后才会开始开发，所以重点就是 Review 的过程了。</p><p>既然是在公司内部，那就要发挥线下沟通的优势了；当然在开始前还是建议在内部的代码工具里比如说 gitlab 中提交一个 MR，先让参会人员都提前看看大概修改了哪些内容，最好是提前在 gitlab 中评论，带着问题开会讨论。</p><p>实际 Review 过程应该尽量关注业务逻辑与设计，而不是代码风格、格式等细枝末节的问题。</p><p>提出修改意见的时候也要对事不对人，我见过好几次在 Review 现场吵起来的场景，就是代入了一些主观情绪，被 Review 的觉得自己能力被质疑，从而产生了一些冲突。</p><p>Code Review 做得好的话整个团队都会一起进步，对个人来说参与一些优质开源项目的 Code Review 也会学到很多东西。</p>]]></content>
    
    
    <summary type="html">&lt;h1 id=&quot;背景&quot;&gt;&lt;a href=&quot;#背景&quot; class=&quot;headerlink&quot; title=&quot;背景&quot;&gt;&lt;/a&gt;背景&lt;/h1&gt;&lt;p&gt;Code Review 是大家日常开发过程中很常见的流程，当然也不排除一些团队为了快速上线，只要功能测试没问题就直接省去了 Code Review。&lt;/p&gt;
&lt;p&gt;我个人觉得再忙的团队  Code Review 还是很有必要的（甚至可以事后再 Review），好处很多：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;跳出个人开发的思维误区，更容易发现问题&lt;/li&gt;
&lt;li&gt;增进团队交流，提高整体的技术氛围&lt;/li&gt;
&lt;li&gt;团队水平检测器，不管是审核者还是被审核的，review 几次后大概就知道是什么水平了&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;通常 Code Review 有两种场景，一种是公司内部，还有就是开源社区。&lt;/p&gt;</summary>
    
    
    
    <category term="OB" scheme="http://crossoverjie.top/categories/OB/"/>
    
    
    <category term="OpenSource" scheme="http://crossoverjie.top/tags/OpenSource/"/>
    
  </entry>
  
  <entry>
    <title>如何在本地打包 StarRocks 发行版</title>
    <link href="http://crossoverjie.top/2025/05/12/ob/StarRocks-build-in-local/"/>
    <id>http://crossoverjie.top/2025/05/12/ob/StarRocks-build-in-local/</id>
    <published>2025-05-12T09:47:52.000Z</published>
    <updated>2025-05-14T06:23:58.860Z</updated>
    
    <content type="html"><![CDATA[<p>最近我们在使用 StarRocks 的时候碰到了一些小问题：</p><ul><li>重启物化视图的时候会导致视图全量刷新，大量消耗资源。<br>  - 修复 PR：<a href="https://github.com/StarRocks/starrocks/pull/57371">https://github.com/StarRocks/starrocks/pull/57371</a></li><li>excluded_refresh_tables 参数与 MV 不在一个数据库的时候，无法生效。<ul><li>修复 PR：<a href="https://github.com/StarRocks/starrocks/pull/58752">https://github.com/StarRocks/starrocks/pull/58752</a></li></ul></li></ul><p>而提交的 PR 是有发布流程的，通常需要间隔一段时间才会发布版本，但是我们线上又等着用这些修复，没办法就只有在本地打包了。</p><p>好在社区已经考虑到这种场景了，专门为我们提供了打包的镜像。</p><span id="more"></span><blockquote><p>FE 是 Java 开发的，本地构建还比较容易，而 BE 是基于 cpp 开发的，构建环境比较复杂，在统一的 docker 镜像里构建会省去不少环境搭建流程。</p></blockquote><p>我们先要拉取对应的打包镜像：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">starrocks/dev-env-ubuntu:3.3.9</span><br></pre></td></tr></table></figure><p>根据自己的版本号拉取即可，比如我这里使用的是 3.3.9 的版本。</p><p>然后需要根据我使用的 tag 拉取一个我们自己的开发分支，在这个分支上将修复的代码手动合并进来。</p><p>然后便可以开始打包了。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">git clone git@github.com:StarRocks/starrocks.git /xx/starrocks</span><br><span class="line"></span><br><span class="line">docker run -it -v /xx/starrocks/.m2:/root/.m2 \ </span><br><span class="line">-v /xx/starrocks:/root/starrocks \ </span><br><span class="line">--name 3.3.9 -d starrocks/dev-env-ubuntu:3.3.9</span><br><span class="line"></span><br><span class="line">docker exec -it 3.3.9 bash</span><br><span class="line"></span><br><span class="line">cd /root/starrocks/</span><br><span class="line"></span><br><span class="line">./build.sh --fe --clean</span><br></pre></td></tr></table></figure><p>我们需要将宿主机的代码磁盘挂载到镜像里，这样镜像就会使用我们的源码进行编译构建。</p><p>最终会在 <code>/xx/starrocks/output</code> 目录生成我们的目标文件。</p><p><img src="https://s2.loli.net/2025/05/14/RqDW2k9telrP4YN.png"></p><h2 id="替换目标镜像"><a href="#替换目标镜像" class="headerlink" title="替换目标镜像"></a>替换目标镜像</h2><p>既然 fe 的各种 jar 包都已经构建出来了，那就可以基于这些 jar 包手动打出 fe 的 image 了。</p><p>我们可以参考官方例子，使用 <code>fe-ubuntu.Dockerfile</code> 来构建 FE 的镜像。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">DOCKER_BUILDKIT=1 docker build --build-arg ARTIFACT_SOURCE=local --build-arg LOCAL_REPO_PATH=. -f fe-ubuntu.Dockerfile -t fe-ubuntu:main ../../..</span><br></pre></td></tr></table></figure><p>除此之外还有更简单的方式，也是更加稳妥的方法。</p><p>我们可以直接使用官方的镜像作为基础镜像，只替换其中核心的 <code>starrocks-fe.jar</code> 。</p><blockquote><p>这个 jar 包会在编译的时候构建出来</p></blockquote><p>因为 <code>starrocks-fe.jar</code> 也是通过同样的镜像打包出来的，所以运行起来不会出现兼容性问题（同样的 jdk 版本），而且也能保证原有的镜像没有修改。</p><figure class="highlight dockerfile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">FROM</span> starrocks/fe-ubuntu:<span class="number">3.3</span>.<span class="number">9</span></span><br><span class="line"><span class="keyword">COPY</span><span class="language-bash"> starrocks-fe.jar /opt/starrocks/fe/lib/</span></span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker build -t fe-ubuntu:3.3.9-fix-&#123;branch&#125; .</span><br></pre></td></tr></table></figure><p>这样我们就可以放心的替换线上的镜像了。</p><p>参考链接：</p><ul><li><a href="https://docs.starrocks.io/zh/docs/developers/build-starrocks/Build_in_docker/">https://docs.starrocks.io/zh/docs/developers/build-starrocks/Build_in_docker&#x2F;</a> </li><li><a href="https://github.com/StarRocks/starrocks/blob/759a838ae15b91056233f180aedc88da67a84937/docker/dockerfiles/fe/README.md#L15">https://github.com/StarRocks/starrocks/blob/759a838ae15b91056233f180aedc88da67a84937/docker/dockerfiles/fe/README.md#L15</a></li></ul>]]></content>
    
    
    <summary type="html">&lt;p&gt;最近我们在使用 StarRocks 的时候碰到了一些小问题：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;重启物化视图的时候会导致视图全量刷新，大量消耗资源。&lt;br&gt;  - 修复 PR：&lt;a href=&quot;https://github.com/StarRocks/starrocks/pull/57371&quot;&gt;https://github.com/StarRocks/starrocks/pull/57371&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;excluded_refresh_tables 参数与 MV 不在一个数据库的时候，无法生效。&lt;ul&gt;
&lt;li&gt;修复 PR：&lt;a href=&quot;https://github.com/StarRocks/starrocks/pull/58752&quot;&gt;https://github.com/StarRocks/starrocks/pull/58752&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;而提交的 PR 是有发布流程的，通常需要间隔一段时间才会发布版本，但是我们线上又等着用这些修复，没办法就只有在本地打包了。&lt;/p&gt;
&lt;p&gt;好在社区已经考虑到这种场景了，专门为我们提供了打包的镜像。&lt;/p&gt;</summary>
    
    
    
    <category term="StarRocks" scheme="http://crossoverjie.top/categories/StarRocks/"/>
    
    
    <category term="StarRocks" scheme="http://crossoverjie.top/tags/StarRocks/"/>
    
  </entry>
  
  <entry>
    <title>一年时间从小白成为 OpenTelemetry Member 有感</title>
    <link href="http://crossoverjie.top/2025/04/15/ob/OTel-member/"/>
    <id>http://crossoverjie.top/2025/04/15/ob/OTel-member/</id>
    <published>2025-04-15T09:40:37.000Z</published>
    <updated>2025-04-17T03:09:54.636Z</updated>
    
    <content type="html"><![CDATA[<p><img src="https://s2.loli.net/2025/04/15/5mCgyLhDGfvXojx.jpg"><br><img src="https://s2.loli.net/2025/04/16/KdHYWrMjm5qXlsw.png"><br>前段时间申请成为了 OpenTelemetry 的 Member 通过了，算是完成了一个阶段性目标；从 24 年的 2 月份的第一个 issue 到现在刚好一年的时间。</p><span id="more"></span><hr><p><img src="https://s2.loli.net/2025/04/15/rVMBdSCNvt4Wu6l.jpg"></p><p>这事也挺突然的，源自于年初我发了一个 24 年的年终总结，提到了希望在今年争取成为 Member，然后<a href="https://github.com/JaredTan95">谭总</a>就提醒我可以自己去申请，只要找到两个 <code>sponsors</code> 支持就可以了。</p><blockquote><p>我之前不知道这个 Member 是自己申请的，没注意看社区的文档（之前的 <code>Apache</code> 社区都是邀请制）。</p></blockquote><p><img src="https://s2.loli.net/2025/04/16/LsOdlTzYXP7pUrb.jpg"></p><p>于是我提交了相关的 <a href="https://github.com/open-telemetry/community/issues/2642">issue</a>，列举了自己做的一些贡献（PR 和 issue），也找到了之前经常帮我 review 的<a href="https://github.com/steverao">Rao</a> 哥作为 sponsor.</p><p>不出意外，没等两天就收到了邀请。</p><h1 id="参与社区"><a href="#参与社区" class="headerlink" title="参与社区"></a>参与社区</h1><p>OpenTelemetry 作为和厂商无关的可观测标准，非常开放和包容，也是我参与过的社区最多元的开源项目，几乎每个子项目都有上百人参与，他们都来自于不同的公司和个人，在这样的背景下社区自然就会更佳和谐，很难出现某个公司或者个人主导项目的发，风险自然也会小很多。</p><p><img src="https://s2.loli.net/2025/04/16/3BzuCehpcf4Ek2j.png"></p><p>OTel 的技术栈主要是可以分为下面三个部分：</p><ul><li>客户端：负责上报可观测数据（Trace、Metrics、Logs）</li><li>OTel collector：处理客户端上报的数据</li><li>数据存储：存储日志、指标、trace 等数据</li></ul><p>以上每个模块都是 OpenTelemetry 非常重要的组成部分，大家可以都挑感兴趣的部分去参与。</p><p>作为一个可观测标准，客户端自然就需要支持大部分的技术栈，所以我们常用的语言和技术栈都有对应的实现：<br><img src="https://s2.loli.net/2024/04/16/zWAVoHaZORI83js.png"></p><p>这一部分的工作量也非常大，靠个人实现和维护肯定不现实，所以社区非常欢迎大家都来做贡献。</p><hr><p><img src="https://s2.loli.net/2025/04/16/IzJl4feYQoZ1iKH.png"></p><p><img src="https://s2.loli.net/2025/04/16/gqwplH3s7NGOvnI.png"></p><p>拿我常用的 Java 来说目前支持了这些框架和库，但依然没有支持全，我们可以在这里的 <a href="https://github.com/open-telemetry/opentelemetry-java-instrumentation/issues?q=sort:updated-desc+state:open+label:%22contribution+welcome%22">issue</a> 列表里找到社区需要大家贡献的内容。</p><h2 id="SIG-小组"><a href="#SIG-小组" class="headerlink" title="SIG 小组"></a>SIG 小组</h2><p>社区也准备许多兴趣小组（<a href="https://github.com/open-telemetry/community#special-interest-groups">SIG</a>）来解决特定领域的问题：<br><img src="https://s2.loli.net/2025/04/16/3yDvJUBHj2KwNnk.png"></p><p><img src="https://s2.loli.net/2025/04/16/vHGnjZPdtR9yauI.png"></p><p>大家也可以订阅日历参与周会，基本上每个兴趣小组都会定期组织，拿 Java 的来说就是每周四的 UTC+8 的早上九点都会举行。</p><p><img src="https://s2.loli.net/2025/04/15/EvgYrcqA36mwf8e.png"><br><img src="https://s2.loli.net/2025/04/15/pxw6dDBaZLW4hRc.png"></p><p>之前参加过两次，都是 zoom 的线上会议（老外的习惯是开摄像头），如果自己口语尚可的话和社区主要的 maintainer 直接沟通效率会高很多。</p><p>当然如果不能开口的话， zoom 也是实时字幕的功能，理解起来问题也不是很大。</p><p><img src="https://s2.loli.net/2025/04/16/pSDJUFRe6fwy4ct.png"></p><p>如果以可以成为 Member 的角度，目前我看了一些申请，提交了两个或以上的 PR 应该都可以申请通过，前提是线下提前和你找的 sponsor 达成一致就可以了。</p><blockquote><p>带着这个目的也挺好的，做开源项目往往就是靠爱发电，有这个 Member 的身份也可以作为正向激励，鼓励继续参与。</p></blockquote><h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>当然成为 Member 只是第一步，随着社区参与的深入度后面还有<a href="https://github.com/open-telemetry/community/blob/main/guides/contributor/membership.md#membership-levels">其他的角色</a>：<br><img src="https://s2.loli.net/2025/04/16/ebtp5I9wByNYmkd.png"></p><p>比如 triager 可以分配 issue、approver 可以批准代码、maintainer 就是某个模块的具体负责人了，后面就再接再厉吧。</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;&lt;img src=&quot;https://s2.loli.net/2025/04/15/5mCgyLhDGfvXojx.jpg&quot;&gt;&lt;br&gt;&lt;img src=&quot;https://s2.loli.net/2025/04/16/KdHYWrMjm5qXlsw.png&quot;&gt;&lt;br&gt;前段时间申请成为了 OpenTelemetry 的 Member 通过了，算是完成了一个阶段性目标；从 24 年的 2 月份的第一个 issue 到现在刚好一年的时间。&lt;/p&gt;</summary>
    
    
    
    <category term="OpenTelemetry" scheme="http://crossoverjie.top/categories/OpenTelemetry/"/>
    
    
    <category term="OpenTelemetry" scheme="http://crossoverjie.top/tags/OpenTelemetry/"/>
    
  </entry>
  
  <entry>
    <title>StarRocks 升级注意事项</title>
    <link href="http://crossoverjie.top/2025/03/14/starrocks/StarRocks-upgrade/"/>
    <id>http://crossoverjie.top/2025/03/14/starrocks/StarRocks-upgrade/</id>
    <published>2025-03-14T09:16:35.000Z</published>
    <updated>2025-03-18T06:35:10.890Z</updated>
    
    <content type="html"><![CDATA[<p>前段时间升级了生产环境的 <code>StarRocks</code>，从 3.3.3 升级到了 3.3.9，期间还是踩了不少坑所以在这里记录下。</p><p><img src="https://s2.loli.net/2025/03/17/uGyo2HULqzQ1j7W.png"></p><p> 因为我们的集群使用的是存算分离的版本，也是使用官方提供的 operator 部署在 kubernetes 里的，所以没法按照官方的流程进入虚拟机手动启停对应的服务。</p><p>只能使用 operator 提供的方案手动修改对应组件的镜像版本，后续的升级操作交给 operator 去完成。</p><span id="more"></span><p><img src="https://s2.loli.net/2025/03/17/7YwRaKzbPo4dAEs.png"></p><p>理论上这个升级流程没什么问题，修改镜像版本之后只需要安静等待他滚动更新即可。</p><h1 id="元数据备份与恢复"><a href="#元数据备份与恢复" class="headerlink" title="元数据备份与恢复"></a>元数据备份与恢复</h1><p>但考虑到之前在社区看到有存算分离集群升级失败导致数据丢失的案例，我们的全量业务已经切换到 StarRocks，如果数据丢失那需要花几天时间进行数据同步，这在业务上是无法接受的，所以我们最好是可以在升级前备份数据，即便是升级失败数据依然还在。</p><p><img src="https://s2.loli.net/2025/03/17/g1q7NbX6H9t5oce.png"></p><p>原本官方社区是有提供数据备份与恢复能力的，但是我们使用的存算分离集群不支持😂，而想要获得社区版的支持应该还要等一段时间，即便是支持了我们升级到那个版本依然是需要备份的。</p><p><img src="https://s2.loli.net/2025/03/17/l6Dfcs4JYV52pQE.png"></p><blockquote><p>好消息，在最新的 3.4.1 版本中已经支持了快照备份了，只是作为一个新 feature，稳定性还有待观察。</p></blockquote><p>所以我们的计划是在当前这个版本（3.3.3）能否自己备份数据，由于我们是存算分离的版本，所以数据主要分为两部分：</p><ul><li>存储在所有 FE 节点里的 meta 元数据</li><li>存储在云存储里的业务数据</li></ul><p>备份的时候自然就需要备份这两部分的数据。</p><h2 id="备份元数据"><a href="#备份元数据" class="headerlink" title="备份元数据"></a>备份元数据</h2><p>在元数据里存放了所有的数据库、表、视图等信息，具体在磁盘的结构如下：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">|-- bdb</span><br><span class="line">|   |-- 00000000.jdb</span><br><span class="line">|   |-- je.config.csv</span><br><span class="line">|   |-- je.info.0</span><br><span class="line">|   |-- je.info.0.lck</span><br><span class="line">|   |-- je.lck</span><br><span class="line">|   `-- je.stat.csv</span><br><span class="line">|-- image</span><br><span class="line">|   |-- ROLE</span><br><span class="line">|   |-- VERSION</span><br><span class="line">|   |-- image.327375</span><br><span class="line">|   |-- starmgr</span><br><span class="line">|   |   `-- image.390</span><br><span class="line">|   `-- v2</span><br><span class="line">|       |-- checksum.327375</span><br><span class="line">|       `-- image.327375</span><br></pre></td></tr></table></figure><p>bdb 目录主要是用于 leader 选举的，理论上并不需要备份，真正需要的是 <code>image</code> 目录下的 <code>image.327375</code> 等元数据文件。</p><p><img src="https://s2.loli.net/2025/03/17/KpVCBqJGjXQctah.png"></p><p><img src="https://s2.loli.net/2025/03/17/CMAiILF3ZHaouY6.png"></p><p>里面是用 JSON 存储的各种类型的元数据，FE 在启动的时候会读取该文件，然后根据不同的类型取不同的偏移量读取其中的元数据加载到内存里。</p><p>我们的 FE 一共有三个节点，需要找到其中的 leader 节点（理论上只需要备份 leader 节点即可，其他节点会在 leader 启动后同步过去），直接将这个 meta 目录备份到本地即可：</p><p>在开始之前需要停掉所有的写入任务，暂停所有的物化视图刷新。</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"># inactive 所有的物化视图</span><br><span class="line"><span class="keyword">SELECT</span> CONCAT(<span class="string">&#x27;ALTER MATERIALIZED VIEW &#x27;</span>, TABLE_NAME, <span class="string">&#x27; INACTIVE;&#x27;</span>) <span class="keyword">FROM</span> information_schema.materialized_views;</span><br><span class="line"></span><br><span class="line"># 手动创建镜像</span><br><span class="line"><span class="keyword">ALTER</span> <span class="keyword">SYSTEM</span> <span class="keyword">CREATE</span> IMAGE;</span><br><span class="line"></span><br><span class="line"># 找到 leader 节点</span><br><span class="line"><span class="keyword">SHOW</span> FRONTENDS;</span><br></pre></td></tr></table></figure><p>然后进入 leader 节点备份元数据：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">k exec -it kube-starrocks-fe-0-n sr -- bash</span><br><span class="line"></span><br><span class="line">tar -zcvf meta.tar.gz meta/</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">下载备份元数据到本地</span></span><br><span class="line">k cp starrocks-fe-0:/opt/starrocks/fe/meta/image.tar.gz image.tar.gz -n starrocks -c fe --retries=5</span><br></pre></td></tr></table></figure><h2 id="备份云存储数据"><a href="#备份云存储数据" class="headerlink" title="备份云存储数据"></a>备份云存储数据</h2><p>云存储的备份就需要结合你使用的云厂商来备份了，通常他们都有提供对应的备份能力。</p><p>要注意的是我们再备份的时候需要记录在存储桶里的目录名称，之后还原的时候名称得保持一致才行。</p><h2 id="恢复元数据"><a href="#恢复元数据" class="headerlink" title="恢复元数据"></a>恢复元数据</h2><p>当出现极端情况升级失败的时候，我们需要把元数据覆盖回去；但由于我们的应用运行在容器里，不可以在应用启动之后再替换元数据。</p><p>只能在应用启动之前将之前备份的元数据覆盖回去，这里可以使用 kubernetes 中的 <code>initContainers</code> 提前将数据复制到应用容器里。</p><p>在开始之前我们需要先把备份的元数据打包为一个镜像。</p><figure class="highlight dockerfile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">FROM</span> busybox  </span><br><span class="line"><span class="keyword">ADD</span><span class="language-bash"> meta.tar.gz /temp</span></span><br></pre></td></tr></table></figure><p>然后我们需要手动修改 FE 的 <code>statefulset</code> 的资源，创建一个 initContainers。</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">initContainers:</span>  </span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">copy-file-init</span>  </span><br><span class="line">    <span class="attr">image:</span> <span class="string">meta:0.0.1</span>  </span><br><span class="line">    <span class="attr">command:</span> [<span class="string">&quot;/bin/sh&quot;</span>, <span class="string">&quot;-c&quot;</span>]  </span><br><span class="line">    <span class="attr">args:</span> [<span class="string">&quot;rm -rf /meta-target/* &amp;&amp; cp -r /temp/meta/. /meta-target&quot;</span>]  </span><br><span class="line">    <span class="attr">volumeMounts:</span>  </span><br><span class="line">      <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">fe-meta</span>  </span><br><span class="line">        <span class="attr">mountPath:</span> <span class="string">&quot;/meta-target&quot;</span></span><br></pre></td></tr></table></figure><p>原理就是在 initContainers 中挂载原本 FE 的元数据目录，这样就可以直接将之前备份的元数据覆盖过去。</p><blockquote><p>当然也可以直接使用 k8s 的 go client 用代码的方式来修改，会更容易维护。</p></blockquote><p>还原的时候需要先将云存储里的数据先还原之后再还原元数据。</p><h1 id="物化视图刷新策略"><a href="#物化视图刷新策略" class="headerlink" title="物化视图刷新策略"></a>物化视图刷新策略</h1><p>真正升级的时候倒是没有碰到升级失败的情况，所以没有走恢复流程；但是却碰到了一个更麻烦的事情。</p><h2 id="物化视图作为基表"><a href="#物化视图作为基表" class="headerlink" title="物化视图作为基表"></a>物化视图作为基表</h2><p>我们在升级前将所有的物化视图设置为了 <code>INACTIVE</code>，升级成功后需要将他们都改为 <code>ACTIVE</code>。</p><p>第一个问题是如果某个物化视图 <code>MV1</code> 的基表也是一个物化视图 <code>MV-base</code>，这样会导致 <code>MV1</code> 的全量刷新。</p><p>我之前在这个 <a href="https://github.com/StarRocks/starrocks/pull/50926">PR</a> 里新增了一个参数：<code>excluded_refresh_tables</code> 可以用于排除基表发生变化的时候刷新物化视图，但是忘记了基表也是物化视图的场景。</p><p><img src="https://s2.loli.net/2025/03/18/nf3QioRgc96ze2p.png"></p><p>所以在这个 <a href="https://github.com/StarRocks/starrocks/pull/56428">PR</a> 中修复了该问题，现在基表是物化视图的时候也可以使用了。</p><h2 id="物化视图手动-ACTIVE"><a href="#物化视图手动-ACTIVE" class="headerlink" title="物化视图手动 ACTIVE"></a>物化视图手动 ACTIVE</h2><p>前面提到在升级之前需要将所有的物化视图设置为 <code>INACTIVE</code>，升级成功后再手动设置为 ACTIVE。</p><p>我们在手动 ACTIVE 之后发现这些物化视图又在做全量刷新了，于是我们检查了代码。</p><p><img src="https://s2.loli.net/2025/03/18/DMNQsxH5ZqaKpFb.png"></p><p>发现在使用 <code>ALTER MATERIALIZED VIEW order_mv ACTIVE;</code> 修改视图状态的时候会强制刷新物化视图的所有分区。</p><p><img src="https://s2.loli.net/2025/03/18/GP6Bzl7Zxq29FoD.png"></p><blockquote><p>force: true 的时候会直接跳过基表的分区检查，导致分区的全量刷新。</p></blockquote><p><img src="https://s2.loli.net/2025/03/18/PG8WVKrpfoTz61I.png"></p><p>同时会在 ACTIVE 的时候将视图基表的 <code>baseTableVisibleVersionMap</code> 版本号缓存清空，FE 需要在刷新的时候判断当前需要刷新的分区是否存在与缓存中，如果存在的话说明不需要刷新，现在被清空后就一定会被刷新。</p><p>所以我提了一个 PR 可以在 <code>ACTIVE</code> 物化视图的时候人工判断是否需要刷新:</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">alter</span> materialized <span class="keyword">view</span> mv_test1 ACTIVE <span class="keyword">WITH</span> NO_VALIDATION</span><br></pre></td></tr></table></figure><p>这样带上 <code>NO_VALIDATION</code> 参数后就 <code>force=false</code> 也就不会全量刷新了。</p><p>如果在 ACTIVE 物化视图的时候碰到类似场景，可以在这个 <code>PR</code> 发布之后加上 <code>NO_VALIDATION</code> 来跳过刷新。</p><p>参考链接：</p><ul><li><a href="https://github.com/StarRocks/starrocks/pull/50926">https://github.com/StarRocks/starrocks/pull/50926</a></li><li><a href="https://github.com/StarRocks/starrocks/pull/56428">https://github.com/StarRocks/starrocks/pull/56428</a></li><li><a href="https://github.com/StarRocks/starrocks/pull/56864">https://github.com/StarRocks/starrocks/pull/56864</a></li></ul>]]></content>
    
    
    <summary type="html">&lt;p&gt;前段时间升级了生产环境的 &lt;code&gt;StarRocks&lt;/code&gt;，从 3.3.3 升级到了 3.3.9，期间还是踩了不少坑所以在这里记录下。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://s2.loli.net/2025/03/17/uGyo2HULqzQ1j7W.png&quot;&gt;&lt;/p&gt;
&lt;p&gt; 因为我们的集群使用的是存算分离的版本，也是使用官方提供的 operator 部署在 kubernetes 里的，所以没法按照官方的流程进入虚拟机手动启停对应的服务。&lt;/p&gt;
&lt;p&gt;只能使用 operator 提供的方案手动修改对应组件的镜像版本，后续的升级操作交给 operator 去完成。&lt;/p&gt;</summary>
    
    
    
    <category term="OB" scheme="http://crossoverjie.top/categories/OB/"/>
    
    
    <category term="StarRocks" scheme="http://crossoverjie.top/tags/StarRocks/"/>
    
  </entry>
  
  <entry>
    <title>我的 2024</title>
    <link href="http://crossoverjie.top/2025/03/03/annual-summary/2024/"/>
    <id>http://crossoverjie.top/2025/03/03/annual-summary/2024/</id>
    <published>2025-03-03T09:47:52.000Z</published>
    <updated>2025-03-10T06:07:24.193Z</updated>
    
    <content type="html"><![CDATA[<p>这些年我一直都是按照农历新年来写年终总结的，都说不出正月都是年，前些年一直都比较规律，今年确实是时间超了一些。</p><p>主要原因还是年末接了个活，需要在年初上线，导致这段时间都没太多时间写内容。</p><p>最近事情终于告一段落后才开始码字。</p><span id="more"></span><blockquote><p>本来打算用 AI 来写的，想想还是算了，现在 AI 大热的时代，越是手工打造的内容越是珍贵🐶</p></blockquote><h1 id="健身"><a href="#健身" class="headerlink" title="健身"></a>健身</h1><p><img src="https://s2.loli.net/2025/03/04/t6FN7hjiUdXYJTZ.jpg"></p><p><img src="https://s2.loli.net/2025/03/04/vdDmtrcTGAxXsyC.jpg"></p><p>回想起来 2024 年投入最多的还是健身，手上的老茧都换了几轮了；</p><p>以前还不信真有人一天没事就往健身房跑吗？现在回想起来在健身房的那 1～2 小时是一天最放松的时间，带个耳机听着播客，感受肌肉的发力（听着是有点油腻）完全进入心流的状态。</p><p>不过因为我大部分的时间都是自己练，所以对自己也不够狠，全是自己能接受的强度，加上也没啥天赋（从小体育就是我的弱项）所以肌肉线条也不是很明显。</p><p><img src="https://s2.loli.net/2025/03/04/dfIL87FvXVqy5Pk.png" alt="image.png"></p><p><img src="https://s2.loli.net/2025/03/04/8dxzbyH1PA7X2R4.jpg"></p><p>以上都是凹了半天造型才拍出来的，和健身大佬完全没法比；去年 11 月份从乐刻换到了一个有自由卧推和深蹲的健身房，动作基本上都是从零开始，现在卧推 70kg、深蹲 80kg 已经比较满意了。</p><p>我的要求不高，保证在不受伤的前提下卧推能到 80kg 做组就满意了。</p><blockquote><p>就像我朋友说的，看你也练了一年多了咋还这么菜？我的回复是：这一年多如果不练，那岂不是更菜，现在还在打基础的阶段🙂</p></blockquote><h1 id="工作"><a href="#工作" class="headerlink" title="工作"></a>工作</h1><p>今年的工作依然是按部就班的进行，在公司依然是负责基础架构，主要还是维护内部的消息队列 Pulsar、可观测性工具 OpenTelemetry、服务网格、StarRocks 等。</p><p>当然 24 年还是完成了一个小目标：成为了两个 Apache 项目的 Committer。</p><p><img src="https://s2.loli.net/2025/03/04/PCmnARseYq9DiaV.png"></p><p>为此我还写了一篇文章：<a href="https://mp.weixin.qq.com/s/YV31IjbFNd__U0cf70V4pQ">我是如何从零到成为 Apache 顶级项目的 Committer</a>，感兴趣的朋友可以看看详细过程。</p><h2 id="副业"><a href="#副业" class="headerlink" title="副业"></a>副业</h2><p>23 年的时候第一次接到了咨询相关的付费业务，也就是从那时候开始尝试做一些副业，目前咨询服务了几个客户，反馈都还不错：<br><img src="https://s2.loli.net/2025/03/05/FENVYphcQHuC7xa.png"><br><img src="https://s2.loli.net/2025/03/05/wRTvW5AVimYfjLb.png"><br><img src="https://s2.loli.net/2025/03/05/lxzBEsVGOkorNXq.png"></p><p>今年准备加大力度再宣传一下：<br><img src="https://s2.loli.net/2025/03/05/2iKaFwIoRr1tjHV.png"></p><p>同时 24 年在咨询的基础上开了知识星球，也没有认真宣传，目前有大约 90 个用户，非常感谢他们的支持：<br><img src="https://s2.loli.net/2025/03/05/E8xkw2HUWrQOL5D.jpg"></p><p>有需要的朋友也可以扫码关注下，等这段时间忙过之后会重点运营。</p><h2 id="掘金签约作者"><a href="#掘金签约作者" class="headerlink" title="掘金签约作者"></a>掘金签约作者</h2><p><img src="https://s2.loli.net/2025/03/05/SVoyfepc6umUl2X.jpg"></p><p>去年也和掘金签约了半年时间：也就是这半年期间写的文章需要首发在掘金平台，同时还能拿到相应的佣金；对创作者和平台来说确实是双赢的结果。</p><p>平台收获了优质的文章，作者也能获得一定的激励；希望国内越来越多的平台可以效仿，而不是往自家平台里倒垃圾（DDDD）。</p><h1 id="技能"><a href="#技能" class="headerlink" title="技能"></a>技能</h1><h2 id="博客"><a href="#博客" class="headerlink" title="博客"></a>博客</h2><p><img src="https://s2.loli.net/2025/03/05/uU8JDoKjSVdGbp5.png"></p><p>去年 24 年因为签约了掘金，所以写的还是比较积极，一共写了 53 篇博客，平均每个月写 4 篇+。</p><p>今年写的内容主要包含了：<br><img src="https://s2.loli.net/2025/03/06/5qp4uHWetQSlxvZ.png"></p><p>这里我问了下 AI，其实几乎都是我工作中接触到的技术问题，比如 Pulsar、OpenTelemetry、StarRocks 等。</p><h2 id="开源"><a href="#开源" class="headerlink" title="开源"></a>开源</h2><p><img src="https://s2.loli.net/2025/03/05/JWmG2ybEvrZswOx.jpg"></p><p><img src="https://s2.loli.net/2025/03/05/aF4lM51XgmZ9INd.png"></p><p>24年投入开源的时间还是蛮多的，毕竟我的工作中的有部分时间也是和开源相关的。</p><h3 id="Apache-Pulsar"><a href="#Apache-Pulsar" class="headerlink" title="Apache Pulsar"></a>Apache Pulsar</h3><p>Pulsar 的贡献主要是分为主仓库和 pulsar-client-go 两个。</p><p><img src="https://s2.loli.net/2025/03/05/N68UXVC2eqQksFM.png"><br>主仓库这边我的改动不是很多，比较大的就是重构了 cli，其他的都是些边角料。</p><p><img src="https://s2.loli.net/2025/03/05/LKXCBa8m1OVxboA.png"></p><p>其余在 pulsar-client-go 中主要是同步了一些 java-client 的 feature 过来，以及修复一些 bug。</p><hr><h3 id="Apache-HertzBeat"><a href="#Apache-HertzBeat" class="headerlink" title="Apache HertzBeat"></a>Apache HertzBeat</h3><p><img src="https://s2.loli.net/2025/03/05/ACvfe5dnRPhN1lp.png"></p><p>除此之外在空余时间我还参与了 Apache HertzBeat 项目（一个开源的实时监控项目），当时项目刚进入 Apache 孵化器不久，我主要是帮助完善了一些单元测试、优化了 CI 流程、代码 checkstyle 等工作。<br>后来由于时间限制参与的不多了，但也在一直有在关注着。</p><h3 id="OpenTelemetry"><a href="#OpenTelemetry" class="headerlink" title="OpenTelemetry"></a>OpenTelemetry</h3><p><img src="https://s2.loli.net/2025/03/06/pg3Be5s7A91GKLh.png"></p><p>去年年中的时候由于公司可观测的技术栈全面迁移到 OpenTelemetry，所以也花了一些时间学习并使用它，并结合我们的场景给社区提了一些 PR.</p><ul><li>Instrumentation<ul><li>Pulsar 相关的 metrics 埋点： <a href="https://github.com/open-telemetry/opentelemetry-java-instrumentation/pull/11591">https://github.com/open-telemetry/opentelemetry-java-instrumentation/pull/11591</a></li><li>支持 PowerJob: <a href="https://github.com/open-telemetry/opentelemetry-java-instrumentation/pull/12086">https://github.com/open-telemetry/opentelemetry-java-instrumentation/pull/12086</a></li></ul></li><li>Operator<ul><li>Operator 支持部署 java extensions: <a href="https://github.com/open-telemetry/opentelemetry-operator/pull/2761">https://github.com/open-telemetry/opentelemetry-operator/pull/2761</a></li></ul></li><li>Convention:<ul><li>完善了 RPC 的一些语义: <a href="https://github.com/open-telemetry/semantic-conventions/pull/1281">https://github.com/open-telemetry/semantic-conventions/pull/1281</a></li><li>补全了 Pulsar 的一些语义： <a href="https://github.com/open-telemetry/semantic-conventions/pull/1099">https://github.com/open-telemetry/semantic-conventions/pull/1099</a></li></ul></li></ul><p>本来准备下半年再接再厉多贡献一些，争取成为 Member，结果因为把重心切到 Starrocks 之后这边暂时就没在跟进了，今年也许会重启更新。</p><h3 id="StarRocks"><a href="#StarRocks" class="headerlink" title="StarRocks"></a>StarRocks</h3><p>这也是去年第一次接触到的技术栈，和大部分业务开发一样，以前顶多接触过关系型数据库，对这类大数据产品接触很少。</p><p>第一次参与是领导让我看看能否给它的物化视图加一个参数，好在我要修改的部分（FrontEnd)都是 Java 写的（BackEnd 是 cpp 写的），至少代码看起来无压力。</p><p><img src="https://s2.loli.net/2025/03/06/T61ny2uMZNk9Rxt.png"></p><p>所以就花了一些时间来从头研究，到目前为止也给社区提交了一些 feature 和修复了 bug，主要都是和物化视图相关的内容。</p><blockquote><p>这里也额外提一下：即便是对毫不熟悉的项目，哪怕看起来是数据库这种比较复杂的技术栈，只要能看懂代码、复现问题，那就都可以解决，首先心理上就不要害怕。</p></blockquote><h1 id="目标"><a href="#目标" class="headerlink" title="目标"></a>目标</h1><p><img src="https://s2.loli.net/2025/03/06/mVY5wcBpy7zJtux.png"></p><p>最后再看看去年的目标，完成率不说 100% 吧，80% 还是有的，今年目标看来要再定高一些了：</p><ul><li>卧推 PR 85kg</li><li>体脂达到一次 13%</li><li>国内游一次</li><li>再完成一个开源社区的 Member</li></ul><p>好了，流水账记完了，今年也要抓紧开始搬砖了，咱们明年再见。</p><h2 id="往年记录"><a href="#往年记录" class="headerlink" title="往年记录"></a>往年记录</h2><ul><li><p><a href="https://crossoverjie.top/2023/01/18/annual-summary/2023/">2023</a></p></li><li><p><a href="https://crossoverjie.top/2023/01/18/annual-summary/2022/">2022</a></p></li><li><p><a href="https://crossoverjie.top/2022/01/27/annual-summary/2021/">2021</a></p></li><li><p><a href="https://crossoverjie.top/2021/03/02/annual-summary/2020/">2020</a></p></li><li><p><a href="https://crossoverjie.top/2019/12/30/annual-summary/2019/">2019</a></p></li><li><p><a href="https://crossoverjie.top/2018/12/30/annual-summary/2018/">2018</a></p></li><li><p><a href="https://crossoverjie.top/2018/12/30/annual-summary/2018/">2016</a></p></li></ul>]]></content>
    
    
    <summary type="html">&lt;p&gt;这些年我一直都是按照农历新年来写年终总结的，都说不出正月都是年，前些年一直都比较规律，今年确实是时间超了一些。&lt;/p&gt;
&lt;p&gt;主要原因还是年末接了个活，需要在年初上线，导致这段时间都没太多时间写内容。&lt;/p&gt;
&lt;p&gt;最近事情终于告一段落后才开始码字。&lt;/p&gt;</summary>
    
    
    
    <category term="OB" scheme="http://crossoverjie.top/categories/OB/"/>
    
    
  </entry>
  
  <entry>
    <title>StarRocks 开发环境搭建踩坑指北之存算分离篇</title>
    <link href="http://crossoverjie.top/2025/02/26/ob/StarRocks-dev-shard-data-build/"/>
    <id>http://crossoverjie.top/2025/02/26/ob/StarRocks-dev-shard-data-build/</id>
    <published>2025-02-26T02:30:08.849Z</published>
    <updated>2025-02-26T02:30:08.849Z</updated>
    
    <content type="html"><![CDATA[<p>前段时间碰到一个 StarRocks 物化视图的 <a href="https://github.com/StarRocks/starrocks/issues/55301">bug</a>: <a href="https://github.com/StarRocks/starrocks/issues/55301">https://github.com/StarRocks/starrocks/issues/55301</a></p><p>但是这个问题只能在存算分离的场景下才能复现，为了找到问题原因我便尝试在本地搭建一个可以 Debug 的存算分离版本。</p><p>之前也分享过在<a href="https://crossoverjie.top/2024/10/09/ob/StarRocks-dev-env-build/">本地 Debug StarRocks</a>，不过那是存算一体的版本，而存算分离稍微要复杂一些。</p><blockquote><p>这里提到的本地 Debug 主要是指可以调试 FE，而 CN&#x2F;BE 则是运行在容器环境，避免本地打包和构建运行环境。</p></blockquote><hr><span id="more"></span><p>当前 StarRocks 以下的存算分离部署方式，在本地推荐直接使用 <code>MinIO</code> 部署。</p><p><img src="https://s2.loli.net/2025/02/14/pTWsfE6XUxuCeiL.png"></p><h2 id="启动-MinIO"><a href="#启动-MinIO" class="headerlink" title="启动 MinIO"></a>启动 MinIO</h2><p>首先第一步启动 MinIO:</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">docker run -d --rm --name minio \</span><br><span class="line">  -e MINIO_ROOT_USER=miniouser \</span><br><span class="line">  -e MINIO_ROOT_PASSWORD=miniopassword \</span><br><span class="line">  -p 9001:9001 \</span><br><span class="line">  -p 9000:9000 \</span><br><span class="line">  --entrypoint sh \</span><br><span class="line">  minio/minio:latest \</span><br><span class="line">  -c &#x27;mkdir -p /minio_data/starrocks &amp;&amp; minio server /minio_data --console-address &quot;:9001&quot;&#x27;</span><br></pre></td></tr></table></figure><p>进入 MinIO 容器设置 access token:</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">docker exec -it minio sh</span><br><span class="line">mc alias set myminio http://10.0.9.20:9000 miniouser miniopassword; mc admin user svcacct add --access-key AAAAAAAAAAAAAAAAAAAA --secret-key BBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBB myminio miniouser</span><br></pre></td></tr></table></figure><h2 id="启动-cn"><a href="#启动-cn" class="headerlink" title="启动 cn:"></a>启动 cn:</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker run -p 9060:9060 -p 8040:8040 -p 9050:9050 -p 8060:8060 -p 9070:9070 -itd --rm --name cn -e &quot;TZ=Asia/Shanghai&quot; starrocks/cn-ubuntu:3.4-latest</span><br></pre></td></tr></table></figure><p>修改 <code>cn.conf</code> :</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cd cn/config/</span><br><span class="line">echo &quot;priority_networks = 10.0.9.20/24&quot; &gt;&gt; cn.properties</span><br></pre></td></tr></table></figure><p> 使用脚本手动启动 cn:</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/start_cn.sh --daemon</span><br></pre></td></tr></table></figure><p>使用以下配置在本地 IDEA 中启动 FE:</p><figure class="highlight properties"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">LOG_DIR</span> = <span class="string">$&#123;STARROCKS_HOME&#125;/log  </span></span><br><span class="line">  </span><br><span class="line"><span class="attr">DATE</span> = <span class="string">&quot;$(date +%Y%m%d-%H%M%S)&quot;  </span></span><br><span class="line">  </span><br><span class="line"><span class="attr">sys_log_level</span> = <span class="string">INFO  </span></span><br><span class="line">  </span><br><span class="line"><span class="attr">http_port</span> = <span class="string">8030  </span></span><br><span class="line"><span class="attr">rpc_port</span> = <span class="string">9020  </span></span><br><span class="line"><span class="attr">query_port</span> = <span class="string">9030  </span></span><br><span class="line"><span class="attr">edit_log_port</span> = <span class="string">9010  </span></span><br><span class="line"><span class="attr">mysql_service_nio_enabled</span> = <span class="string">true  </span></span><br><span class="line">  </span><br><span class="line"><span class="attr">run_mode</span> = <span class="string">shared_data  </span></span><br><span class="line"><span class="attr">cloud_native_storage_type</span> = <span class="string">S3  </span></span><br><span class="line"><span class="attr">aws_s3_endpoint</span> = <span class="string">10.0.9.20:9000  </span></span><br><span class="line"><span class="comment"># set the path in MinIO  </span></span><br><span class="line"><span class="attr">aws_s3_path</span> = <span class="string">starrocks  </span></span><br><span class="line"><span class="comment"># credentials for MinIO object read/write  </span></span><br><span class="line"><span class="comment"># 这里的 key 为刚才设置的 access token</span></span><br><span class="line"><span class="attr">aws_s3_access_key</span> = <span class="string">AAAAAAAAAAAAAAAAAAAA  </span></span><br><span class="line"><span class="attr">aws_s3_secret_key</span> = <span class="string">BBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBB  </span></span><br><span class="line"><span class="attr">aws_s3_use_instance_profile</span> = <span class="string">false  </span></span><br><span class="line"><span class="attr">aws_s3_use_aws_sdk_default_behavior</span> = <span class="string">false  </span></span><br><span class="line"><span class="comment"># Set this to false if you do not want default  </span></span><br><span class="line"><span class="comment"># storage created in the object storage using  </span></span><br><span class="line"><span class="comment"># the details provided above  </span></span><br><span class="line"><span class="attr">enable_load_volume_from_conf</span> = <span class="string">true  </span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment"># 本机 IP，需要与 cn 中的配置对齐</span></span><br><span class="line"><span class="attr">priority_networks</span> = <span class="string">10.0.9.20/24</span></span><br></pre></td></tr></table></figure><p>启动 FE 之前最好先删除 <code>meta/.</code> 下的所有元数据文件然后再启动。</p><h2 id="添加-CN-节点"><a href="#添加-CN-节点" class="headerlink" title="添加 CN 节点"></a>添加 CN 节点</h2><p>FE 启动成功之后连接上 FE，然后手动添加 CN 节点。</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">ALTER</span> <span class="keyword">SYSTEM</span> <span class="keyword">ADD</span> COMPUTE NODE &quot;127.0.0.1:9050&quot;;</span><br><span class="line"><span class="keyword">show</span> compute nodes;</span><br></pre></td></tr></table></figure><p><img src="https://s2.loli.net/2025/01/20/OBXjoYAqP6DhMKs.png"></p><p>然后就可以创建存算分离的表了。</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> IF <span class="keyword">NOT</span> <span class="keyword">EXISTS</span> par_tbl1</span><br><span class="line">(</span><br><span class="line">    datekey DATETIME,</span><br><span class="line">    k1      <span class="type">INT</span>,</span><br><span class="line">    item_id STRING,</span><br><span class="line">    v2      <span class="type">INT</span></span><br><span class="line">)<span class="keyword">PRIMARY</span> KEY (`datekey`,`k1`)</span><br><span class="line"> <span class="keyword">PARTITION</span> <span class="keyword">BY</span> date_trunc(<span class="string">&#x27;day&#x27;</span>, `datekey`)</span><br><span class="line"> PROPERTIES (</span><br><span class="line">&quot;compression&quot; <span class="operator">=</span> &quot;LZ4&quot;,</span><br><span class="line">&quot;datacache.enable&quot; <span class="operator">=</span> &quot;true&quot;,</span><br><span class="line">&quot;enable_async_write_back&quot; <span class="operator">=</span> &quot;false&quot;,</span><br><span class="line">&quot;enable_persistent_index&quot; <span class="operator">=</span> &quot;true&quot;,</span><br><span class="line">&quot;persistent_index_type&quot; <span class="operator">=</span> &quot;LOCAL&quot;,</span><br><span class="line">&quot;replication_num&quot; <span class="operator">=</span> &quot;1&quot;,</span><br><span class="line">&quot;storage_volume&quot; <span class="operator">=</span> &quot;builtin_storage_volume&quot;</span><br><span class="line">);</span><br></pre></td></tr></table></figure><p>最终其实是参考官方提供的 docker-compose 的编排文件进行部署的：<br><a href="https://raw.githubusercontent.com/StarRocks/demo/master/documentation-samples/quickstart/docker-compose.yml">https://raw.githubusercontent.com/StarRocks/demo/master/documentation-samples/quickstart/docker-compose.yml</a></p><blockquote><p>如果只是想在本地搭建一个存算分离的版本，可以直接使用这个 docker compose.</p></blockquote><p>其中有两个坑需要注意：</p><h2 id="创建表超时"><a href="#创建表超时" class="headerlink" title="创建表超时"></a>创建表超时</h2><p>建表出现超时，提示需要配置时间:</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">admin <span class="keyword">set</span> frontend config(&quot;tablet_create_timeout_second&quot;<span class="operator">=</span>&quot;50&quot;)</span><br></pre></td></tr></table></figure><p>配置也不能解决问题，依然会超时，可以看看本地是否有开启代理，尝试关闭代理试试看。</p><h2 id="unknown-compression-type-0-backend-id-x3D-10002"><a href="#unknown-compression-type-0-backend-id-x3D-10002" class="headerlink" title="unknown compression type(0) backend [id&#x3D;10002]"></a>unknown compression type(0) backend [id&#x3D;10002]</h2><p>不支持的压缩类型：这个问题我在使用 main 分支的 FE 与最新的 <code>starrocks/cn-ubuntu:3.4-latest</code> 的镜像会触发，当我把 FE 降低到具体到 tag 分支，比如 3.3.9 的时候就可以了。</p><p>具体原因就没有细究了，如果要本地 debug 使用最新的 tag 也能满足调试的需求。</p><p>参考链接：</p><ul><li><a href="https://github.com/StarRocks/starrocks/issues/55301">https://github.com/StarRocks/starrocks/issues/55301</a></li><li><a href="https://docs.starrocks.io/zh/docs/deployment/shared_data/minio/">https://docs.starrocks.io/zh/docs/deployment/shared_data/minio/</a></li></ul>]]></content>
    
    
    <summary type="html">&lt;p&gt;前段时间碰到一个 StarRocks 物化视图的 &lt;a href=&quot;https://github.com/StarRocks/starrocks/issues/55301&quot;&gt;bug&lt;/a&gt;: &lt;a href=&quot;https://github.com/StarRocks/starrocks/issues/55301&quot;&gt;https://github.com/StarRocks/starrocks/issues/55301&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;但是这个问题只能在存算分离的场景下才能复现，为了找到问题原因我便尝试在本地搭建一个可以 Debug 的存算分离版本。&lt;/p&gt;
&lt;p&gt;之前也分享过在&lt;a href=&quot;https://crossoverjie.top/2024/10/09/ob/StarRocks-dev-env-build/&quot;&gt;本地 Debug StarRocks&lt;/a&gt;，不过那是存算一体的版本，而存算分离稍微要复杂一些。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;这里提到的本地 Debug 主要是指可以调试 FE，而 CN&amp;#x2F;BE 则是运行在容器环境，避免本地打包和构建运行环境。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;hr&gt;</summary>
    
    
    
    <category term="OB" scheme="http://crossoverjie.top/categories/OB/"/>
    
    <category term="StarRocks" scheme="http://crossoverjie.top/categories/OB/StarRocks/"/>
    
    
    <category term="StarRocks" scheme="http://crossoverjie.top/tags/StarRocks/"/>
    
  </entry>
  
  <entry>
    <title>k8s 云原生应用如何接入监控</title>
    <link href="http://crossoverjie.top/2025/01/02/ob/k8s-monitor-pod/"/>
    <id>http://crossoverjie.top/2025/01/02/ob/k8s-monitor-pod/</id>
    <published>2025-01-02T06:00:50.000Z</published>
    <updated>2025-01-02T06:44:07.208Z</updated>
    
    <content type="html"><![CDATA[<p>前段时间有朋友问我如何在 kubernetes 里搭建监控系统，恰好在公司也在维护内部的可观测平台，正好借这个机会整理下目前常见的自建监控方案。</p><p>一个完整的监控系统通常包含以下的内容：</p><ul><li>指标暴露：将系统内部需要关注的指标暴露出去</li><li>指标采集：收集并存储暴露出来的指标</li><li>指标展示：以各种图表展示和分析收集到的数据</li><li>监控告警：当某些关键指标在一定时间周期内出现异常时，可以及时通知相关人员</li></ul><p><img src="https://s2.loli.net/2024/12/20/nAOS5E1YzWDoZyF.png" alt="image.png"></p><p>对于 k8s 的监控通常分为两个部分：</p><ul><li>k8s 自带的系统组建</li><li>业务 Pod 暴露出来的监控指标</li></ul><span id="more"></span><h1 id="系统组建"><a href="#系统组建" class="headerlink" title="系统组建"></a>系统组建</h1><p>对于 kubernetes 系统组建可以由 <code>cAdvisor</code> 提供监控能力，默认情况下这个功能是开箱即用的，我们只需要在 Prometheus 中配置相关的任务抓取即可：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="bullet">-</span> <span class="attr">job_name:</span> <span class="string">nodeScrape/monitoring/cadvisor-scrape/0</span></span><br><span class="line">  <span class="attr">scrape_interval:</span> <span class="string">30s</span></span><br><span class="line">  <span class="attr">scrape_timeout:</span> <span class="string">15s</span></span><br><span class="line">  <span class="attr">scheme:</span> <span class="string">https</span></span><br><span class="line">  <span class="attr">bearer_token_file:</span> <span class="string">/var/run/secrets/kubernetes.io/serviceaccount/token</span></span><br><span class="line">  <span class="attr">tls_config:</span></span><br><span class="line">    <span class="attr">insecure_skip_verify:</span> <span class="literal">true</span></span><br><span class="line">  <span class="attr">relabel_configs:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">source_labels:</span> [<span class="string">__meta_kubernetes_node_name</span>]</span><br><span class="line">    <span class="attr">target_label:</span> <span class="string">node</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">action:</span> <span class="string">replace</span></span><br><span class="line">    <span class="attr">source_labels:</span> [<span class="string">__meta_kubernetes_node_name</span>]</span><br><span class="line">    <span class="attr">separator:</span> <span class="string">;</span></span><br><span class="line">    <span class="attr">target_label:</span> <span class="string">__address__</span></span><br><span class="line">    <span class="attr">regex:</span> <span class="string">(.*)</span></span><br><span class="line">    <span class="attr">replacement:</span> <span class="string">kubernetes.default.svc:443</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">action:</span> <span class="string">replace</span></span><br><span class="line">    <span class="attr">source_labels:</span> [<span class="string">__meta_kubernetes_node_name</span>]</span><br><span class="line">    <span class="attr">separator:</span> <span class="string">;</span></span><br><span class="line">    <span class="attr">target_label:</span> <span class="string">__metrics_path__</span></span><br><span class="line">    <span class="attr">regex:</span> <span class="string">(.+)</span></span><br><span class="line">    <span class="attr">replacement:</span> <span class="string">/api/v1/nodes/$&#123;1&#125;/proxy/metrics/cadvisor</span></span><br><span class="line"></span><br><span class="line">  <span class="attr">kubernetes_sd_configs:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">role:</span> <span class="string">node</span></span><br></pre></td></tr></table></figure><p><img src="https://s2.loli.net/2024/12/20/RhKZGp94sUTbvFa.png" alt="image.png"><br>这样的话就可以监控 k8s 的内存、CPU 之类的数据。</p><p>具体提供了哪些指标可以参考这里：<br><a href="https://github.com/google/cadvisor/blob/master/docs/storage/prometheus.md#prometheus-container-metrics">https://github.com/google/cadvisor/blob/master/docs/storage/prometheus.md#prometheus-container-metrics</a></p><p>也可以找一些常用的监控面板:<br><a href="https://grafana.com/grafana/dashboards/13077-kubernetes-monitoring-dashboard-kubelet-cadvisor-node-exporter/">https://grafana.com/grafana/dashboards/13077-kubernetes-monitoring-dashboard-kubelet-cadvisor-node-exporter/</a></p><p>k8s 不但提供了 cAdvisor 的数据，还有其他类似的 endpoint: <code>/metrics/resource &amp; /metrics/probes</code> </p><p>具体暴露出来的指标可以参考官方文档：<br><a href="https://kubernetes.io/docs/concepts/cluster-administration/system-metrics/">https://kubernetes.io/docs/concepts/cluster-administration/system-metrics/</a></p><h1 id="业务指标"><a href="#业务指标" class="headerlink" title="业务指标"></a>业务指标</h1><p>对于业务应用来说第一步也是需要将自己的指标暴露出去，如果是 Java 的话可以使用 Prometheus 提供的库：</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">&lt;!-- The client --&gt;</span>  </span><br><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span>  </span><br><span class="line">  <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>io.prometheus<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span>  </span><br><span class="line">  <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>simpleclient<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span>  </span><br><span class="line">  <span class="tag">&lt;<span class="name">version</span>&gt;</span>0.16.0<span class="tag">&lt;/<span class="name">version</span>&gt;</span>  </span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span>  </span><br><span class="line"><span class="comment">&lt;!-- Hotspot JVM metrics--&gt;</span>  </span><br><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span>  </span><br><span class="line">  <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>io.prometheus<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span>  </span><br><span class="line">  <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>simpleclient_hotspot<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span>  </span><br><span class="line">  <span class="tag">&lt;<span class="name">version</span>&gt;</span>0.16.0<span class="tag">&lt;/<span class="name">version</span>&gt;</span>  </span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure><p> 它会自动将 JVM 相关的指标暴露出去，如果是在 VM 中的应用，那只需要简单的配置下 <code>static_configs</code> 就可以抓取指标了：</p> <figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"> <span class="attr">scrape_configs:</span>  </span><br><span class="line"><span class="bullet">-</span> <span class="attr">job_name:</span> <span class="string">&#x27;springboot&#x27;</span>  </span><br><span class="line"><span class="attr">scrape_interval:</span> <span class="string">10s</span>  </span><br><span class="line"><span class="attr">static_configs:</span>  </span><br><span class="line"><span class="bullet">-</span> <span class="attr">targets:</span> [<span class="string">&#x27;localhost:8080&#x27;</span>] <span class="comment"># Spring Boot ip+port</span></span><br></pre></td></tr></table></figure><p>但在 kubernetes 中这个 IP 是不固定的，每次重建应用的时候都会发生变化，所以我们需要一种服务发现机制来动态的找到 Pod 的 IP。</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="bullet">-</span> <span class="attr">job_name:</span> <span class="string">&#x27;kubernetes-pods&#x27;</span></span><br><span class="line">  <span class="attr">kubernetes_sd_configs:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">role:</span> <span class="string">pod</span></span><br><span class="line">  <span class="attr">relabel_configs:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">source_labels:</span> [<span class="string">__meta_kubernetes_pod_annotation_prometheus_io_scrape</span>]</span><br><span class="line">    <span class="attr">action:</span> <span class="string">keep</span></span><br><span class="line">    <span class="attr">regex:</span> <span class="literal">true</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">source_labels:</span> [<span class="string">__meta_kubernetes_pod_annotation_prometheus_io_path</span>]</span><br><span class="line">    <span class="attr">action:</span> <span class="string">replace</span></span><br><span class="line">    <span class="attr">target_label:</span> <span class="string">__metrics_path__</span></span><br><span class="line">    <span class="attr">regex:</span> <span class="string">(.+)</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">source_labels:</span> [<span class="string">__address__</span>, <span class="string">__meta_kubernetes_pod_annotation_prometheus_io_port</span>]</span><br><span class="line">    <span class="attr">action:</span> <span class="string">replace</span></span><br><span class="line">    <span class="attr">regex:</span> <span class="string">([^:]+)(?::\d+)?;(\d+)</span></span><br><span class="line">    <span class="attr">replacement:</span> <span class="string">$1:$2</span></span><br><span class="line">    <span class="attr">target_label:</span> <span class="string">__address__</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">action:</span> <span class="string">labelmap</span></span><br><span class="line">    <span class="attr">regex:</span> <span class="string">__meta_kubernetes_pod_label_(.+)</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">source_labels:</span> [<span class="string">__meta_kubernetes_namespace</span>]</span><br><span class="line">    <span class="attr">action:</span> <span class="string">replace</span></span><br><span class="line">    <span class="attr">target_label:</span> <span class="string">kubernetes_namespace</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">source_labels:</span> [<span class="string">__meta_kubernetes_pod_label_component</span>]</span><br><span class="line">    <span class="attr">action:</span> <span class="string">replace</span></span><br><span class="line">    <span class="attr">target_label:</span> <span class="string">job</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">source_labels:</span> [<span class="string">__meta_kubernetes_pod_name</span>]</span><br><span class="line">    <span class="attr">action:</span> <span class="string">replace</span></span><br><span class="line">    <span class="attr">target_label:</span> <span class="string">kubernetes_pod_name</span></span><br></pre></td></tr></table></figure><p>Prometheus 提供了一个 <code>kubernetes_sd_configs</code> 的服务发现机制，他会在 kubernetes 中查找 Pod 中是否有配置以下的注解：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">template:</span></span><br><span class="line">  <span class="attr">metadata:</span></span><br><span class="line">    <span class="attr">annotations:</span></span><br><span class="line">      <span class="attr">prometheus.io/path:</span> <span class="string">/metrics</span></span><br><span class="line">      <span class="attr">prometheus.io/port:</span> <span class="string">&quot;8082&quot;</span></span><br><span class="line">      <span class="attr">prometheus.io/scrape:</span> <span class="string">&quot;true&quot;</span></span><br></pre></td></tr></table></figure><p>都配置成功后我们便可以在 Prometheus 的管理后台查看到具体的服务信息：<br><img src="https://s2.loli.net/2024/12/23/9tZ3uJTpvQY278D.png" alt="image.png"><br>状态是 UP 则表明抓取数据成功，这样我们就可以在 Prometheus 中查询到数据了。</p><p><img src="https://s2.loli.net/2024/12/23/rM7nDiWgTUmA8h3.png" alt="image.png"></p><p>Prometheus 除了支持 k8s 的服务发现之外还支持各种各样的服务发现，比如你已经使用了  Consul 或者是 Erueka 作为注册中心，也可以直接配置他们的地址然后进行服务发现，这样应用信息发生变化时 Prometheus 也能及时感知到。</p><p>当然 <code>docker/http/docker</code> 等都是支持的，可以按需选择。</p><h2 id="OpenTelemetry"><a href="#OpenTelemetry" class="headerlink" title="OpenTelemetry"></a>OpenTelemetry</h2><p>随着这两年可观测性标准的完善，许多厂商都在往 <code>OpenTelemetry</code> 上进行迁移，接入 OpenTelemetry 与直接使用 Prometheus 最大的不同是：</p><blockquote><p>不再由 Prometheus 主动抓取应用指标，而是由应用给 <code>OpenTelemetry-Collector</code> 推送标准化的可观测数据（包含日志、trace、指标），再由它远程写入 Prometheus 这类时序数据库中。</p></blockquote><p>整体流程图如下：<br><img src="https://s2.loli.net/2024/07/22/oUPjd4KlX7niBaI.png" alt="image.png"></p><p>对应用的最大的区别就是可以不再使用刚才提到 Prometheus 依赖，而是只需要挂载一个 javaagent 即可：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">java -javaagent:opentelemetry-javaagent-2.4.0-SNAPSHOT.jar \  </span><br><span class="line">-Dotel.traces.exporter=otlp \  </span><br><span class="line">-Dotel.metrics.exporter=otlp \  </span><br><span class="line">-Dotel.logs.exporter=none \  </span><br><span class="line">-Dotel.service.name=java-demo \  </span><br><span class="line">-Dotel.exporter.otlp.protocol=grpc \  </span><br><span class="line">-Dotel.propagators=tracecontext,baggage \  </span><br><span class="line">-Dotel.exporter.otlp.endpoint=http://127.0.0.1:5317 -jar target/demo-0.0.1-SNAPSHOT.jar</span><br></pre></td></tr></table></figure><p>而其中会新增的一个 <code>OpenTelemetry-Collector</code>项目，由它将收到的指标数据转发给 Prometheus，所以在它的配置里会配置 Prometheus 的地址：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">exporters:</span></span><br><span class="line">  <span class="attr">otlphttp/prometheus:</span></span><br><span class="line">    <span class="attr">endpoint:</span> <span class="string">http://prometheus:9292/api/v1/otlp</span></span><br><span class="line">    <span class="attr">tls:</span></span><br><span class="line">      <span class="attr">insecure:</span> <span class="literal">true</span></span><br></pre></td></tr></table></figure><p>之前也写过两篇 <code>OpenTelemetry</code> 和监控相关的文章，可以一起阅读体验更佳：</p><ul><li><a href="https://crossoverjie.top/2024/06/13/ob/OpenTelemetry-metrics-concept/">从 Prometheus 到 OpenTelemetry：指标监控的演进与实践</a></li><li><a href="https://crossoverjie.top/2024/08/27/ob/OpenTelemetry-02-metrics/">OpenTelemetry 实战：从零实现应用指标监控</a></li></ul><h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>关于 Prometheus 的安装可以参考官方的 operator 或者是 helm：<br><a href="https://github.com/prometheus-operator/kube-prometheus">https://github.com/prometheus-operator/kube-prometheus</a></p><p>当然如果不想使用 Prometheus 也推荐使用 <a href="https://victoriametrics.com/">VictoriaMetrics</a>，是一个完全兼容 Prometheus 但是资源占用更少的时序数据库。</p><p>参考链接：</p><ul><li><a href="https://kubernetes.io/docs/concepts/cluster-administration/system-metrics/">https://kubernetes.io/docs/concepts/cluster-administration/system-metrics/</a></li><li><a href="https://github.com/google/cadvisor/blob/master/docs/storage/prometheus.md">https://github.com/google/cadvisor/blob/master/docs/storage/prometheus.md</a></li><li><a href="https://prometheus.io/docs/prometheus/latest/configuration/configuration/">https://prometheus.io/docs/prometheus/latest/configuration/configuration/</a></li></ul>]]></content>
    
    
    <summary type="html">&lt;p&gt;前段时间有朋友问我如何在 kubernetes 里搭建监控系统，恰好在公司也在维护内部的可观测平台，正好借这个机会整理下目前常见的自建监控方案。&lt;/p&gt;
&lt;p&gt;一个完整的监控系统通常包含以下的内容：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;指标暴露：将系统内部需要关注的指标暴露出去&lt;/li&gt;
&lt;li&gt;指标采集：收集并存储暴露出来的指标&lt;/li&gt;
&lt;li&gt;指标展示：以各种图表展示和分析收集到的数据&lt;/li&gt;
&lt;li&gt;监控告警：当某些关键指标在一定时间周期内出现异常时，可以及时通知相关人员&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&quot;https://s2.loli.net/2024/12/20/nAOS5E1YzWDoZyF.png&quot; alt=&quot;image.png&quot;&gt;&lt;/p&gt;
&lt;p&gt;对于 k8s 的监控通常分为两个部分：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;k8s 自带的系统组建&lt;/li&gt;
&lt;li&gt;业务 Pod 暴露出来的监控指标&lt;/li&gt;
&lt;/ul&gt;</summary>
    
    
    
    <category term="OB" scheme="http://crossoverjie.top/categories/OB/"/>
    
    <category term="kubernetes" scheme="http://crossoverjie.top/categories/OB/kubernetes/"/>
    
    
    <category term="kubernetes" scheme="http://crossoverjie.top/tags/kubernetes/"/>
    
  </entry>
  
  <entry>
    <title>Istio 安装过程中遇到的坑</title>
    <link href="http://crossoverjie.top/2024/12/25/ob/istio-install-problem/"/>
    <id>http://crossoverjie.top/2024/12/25/ob/istio-install-problem/</id>
    <published>2024-12-25T05:48:35.000Z</published>
    <updated>2024-12-26T03:52:47.449Z</updated>
    
    <content type="html"><![CDATA[<h1 id="安装-Istio"><a href="#安装-Istio" class="headerlink" title="安装 Istio"></a>安装 Istio</h1><p>最近这段时间一直在做服务网格（Istio）相关的工作，背景是我们准备自建 Istio，首先第一件事情就是要安装。</p><p>我这里直接使用官网推荐的 <a href="https://istio.io/v1.18/docs/setup/install/istioctl">istioctl</a> 进行安装：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">$ <span class="built_in">cat</span> &lt;&lt;<span class="string">EOF &gt; ./my-config.yaml</span></span><br><span class="line"><span class="string">apiVersion: install.istio.io/v1alpha1  </span></span><br><span class="line"><span class="string">kind: IstioOperator  </span></span><br><span class="line"><span class="string">metadata:  </span></span><br><span class="line"><span class="string">  namespace: istio-1-18-5  </span></span><br><span class="line"><span class="string">spec:  </span></span><br><span class="line"><span class="string">  profile: minimal  </span></span><br><span class="line"><span class="string">  revision: istio-1-18-5  </span></span><br><span class="line"><span class="string">  meshConfig:  </span></span><br><span class="line"><span class="string">    accessLogFile: /dev/stdout</span></span><br><span class="line"><span class="string">EOF</span></span><br><span class="line">$ istioctl install -f my-config.yaml -n istio-1-18-5</span><br></pre></td></tr></table></figure><p>这里我使用的 profile 是 minimal，它只会安装核心的控制面，具体差异见下图：<br><img src="https://s2.loli.net/2024/12/25/KBu5w4WjLU9zTH3.png" alt="image.png"></p><span id="more"></span><p>输出以下内容时代表安装成功：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">This will install the Istio 1.18.5 minimal profile with [<span class="string">&quot;Istio core&quot;</span> <span class="string">&quot;Istiod&quot;</span>] components into the cluster. Proceed? (y/N) y</span><br><span class="line">✔ Istio core installed                                                                                                                                   </span><br><span class="line">✔ Istiod installed                                                                         </span><br><span class="line">✔ Installation complete  </span><br></pre></td></tr></table></figure><p>之后我们便可以在指定的 <code>namespace</code> 下查询到控制面的 Pod：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">k get pod -n istio-1-18-5</span><br><span class="line">NAME                                   READY   STATUS    RESTARTS   AGE</span><br><span class="line">istiod-istio-1-18-5-6cb9898585-64jtg   1/1     Running   0          22h</span><br></pre></td></tr></table></figure><p>然后只需要将需要注入 sidecar 的 namespace 中开启相关的配置即可，比如我这里将 test 这个 namespace 开启 sidecar 注入：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Namespace</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">labels:</span></span><br><span class="line">    <span class="attr">istio.io/rev:</span> <span class="string">istio-1-18-5</span></span><br><span class="line">    <span class="attr">kubernetes.io/metadata.name:</span> <span class="string">test</span></span><br></pre></td></tr></table></figure><p>最主要的就是加上 <code>istio.io/rev: istio-1-18-5</code> 的标签，标签的值就是我们在安装 istio 时指定的值：<code>revision: istio-1-18-5</code>。</p><p>此时只要我们在这个 namespace 下部署一个 Pod 就会为这个 Pod 挂载一个 sidecar。</p><p><img src="https://s2.loli.net/2024/12/25/Jdrx47cosVtqBv3.png" alt="image.png"></p><h1 id="更新配置的坑"><a href="#更新配置的坑" class="headerlink" title="更新配置的坑"></a>更新配置的坑</h1><p><img src="https://s2.loli.net/2024/12/25/WJjBgqIxCMN1Tz3.png" alt="image.png"><br><img src="https://s2.loli.net/2024/12/25/n4bQDHys9hMoR6c.png" alt="image.png"></p><p><a href="https://istio.io/latest/docs/ops/integrations/prometheus/#option-1-metrics-merging">默认情况</a>下 Istio 会将应用 Pod 的暴露出来的 metrics 和 sidecar 的指标合并在一起，然后暴露为 <code>:15020/stats/prometheus</code> 这个 endpoint。</p><p>而我们自己在 Pod 上定义的注解则是被覆盖掉了：<br><img src="https://s2.loli.net/2024/12/25/vCpUEJgnTYI5rje.png" alt="image.png"></p><p>但我们是将应用和 sidecar 的指标分开采集的，所以我们不需要这个自动合并。</p><p><img src="https://s2.loli.net/2024/12/25/5bQ71OYxmkBFXh6.png"></p><blockquote><p>会单独配置 15090 端口的采集任务</p></blockquote><p>所以我需要将这个功能关闭，安装文档的说明只需要在控制面中将 <code>enablePrometheusMerge</code> 修改为 false 即可。</p><p>安装好 Istio 控制面之后会创建一个 IstioOperator 的 CRD 资源：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">k get IstioOperator -A</span><br><span class="line">NAMESPACE      NAME                           REVISION       STATUS   AGE</span><br><span class="line">istio-1-18-5   installed-state-istio-1-18-5   istio-1-18-5            27h</span><br></pre></td></tr></table></figure><p>所有控制面的配置都可以在这里面修改，所以我想当然的在这里加入了 <code>enablePrometheusMerge: false</code> 的配置。</p><p><img src="https://s2.loli.net/2024/12/25/bCdUxLRQDFEOI6j.png" alt="image.png"></p><p>加上之后我重启了 Pod 发现依然还是 Istio 的注解：</p><p><img src="https://s2.loli.net/2024/12/25/n4bQDHys9hMoR6c.png" alt="image.png"></p><p>也就是说这个配置并没有生效，即便是我把控制面也重启了也没有效果。</p><p>按照原理来说，这些配置应该是控制面下发给数据面的，大胆猜测下也就是控制面没有拿到最新的配置。</p><p>但是我卸载控制面，再安装的时候就指定这个配置确是生效的，也就是说配置没问题，只是我在安装完成后再修改就没法同步。</p><p>之后我在 <a href="https://stackoverflow.com/questions/70076326/how-to-update-istio-configuration-after-installation">stackoverflow</a> 上找到了类似的问题：<br><img src="https://s2.loli.net/2024/12/25/SybMZeG6fc1pjhd.png" alt="image.png"></p><p>简单来说安装好 istio 之后我们也可以继续使用 <code>istioctl install -f xx.yaml</code> 进行更新。</p><h1 id="原理"><a href="#原理" class="headerlink" title="原理"></a>原理</h1><p>后来我仔细看了下 istioctl 这个命令的 help 文档，发现其实已经在描述里写清楚了：<br><img src="https://s2.loli.net/2024/12/26/rv9nkiIO6wgbj5s.png" alt="image.png"><br>甚至还有个别名就叫 <code>apply</code> 这就和 <code>kubectl apply</code> 的命令非常类似了，也更容易理解了，任何的修改只需要 <code>apply</code> 执行一次就可以了。</p><p>不过我也在好奇，既然创建的是一个 <code>IstioOperator</code> 的 CRD，理论上是需要一个 Operator 来读取这里的数据然后再创建一个控制面，同步配置之类的操作。</p><p>但当我安装好 Istio 之后并没看到有一个 Operator 的 Pod 在运行，所以就比较好奇 <code>install</code> 这个命令是如何实现配置同步的。</p><p>经过对 <code>istioctl</code> 的 debug 找到了具体的原因：</p><p><img src="https://s2.loli.net/2024/12/26/2bWSIDsf5gXdkHt.png" alt="WeChatWorkScreenshot_bab3706b-2815-46a6-961e-408439b81841.png"><br><img src="https://s2.loli.net/2024/12/26/XNtGeqnvZiEomfc.png" alt="WeChatWorkScreenshot_8f421734-f1e7-4a07-a676-84300187485d.png"></p><p>在 <code>istioctl install -f xx.yaml</code> 执行之后会直接解析 <code>xx.yaml</code> 里的 <code>IstioOperator</code> 生成所有的 <code>manifest</code> 资源，在这个过程中也会生成一个 <code>ConfigMap</code>，所有的配置都是存放在其中的。</p><p>所以其实我手动修改这个 <code>ConfigMap</code> 也可以动态更新控制面的配置，之前我只是修改了 CRD，我以为还有一个 Operator 来监听这里的变化然后同步数据；实际上并不存在这个逻辑，而是直接应用的 <code>manifest</code>。</p><p>参考链接：</p><ul><li><a href="https://istio.io/v1.18/docs/setup/install/istioctl">https://istio.io/v1.18/docs/setup/install/istioctl</a></li><li><a href="https://istio.io/latest/docs/ops/integrations/prometheus/#option-1-metrics-merging">https://istio.io/latest/docs/ops/integrations/prometheus/#option-1-metrics-merging</a></li><li><a href="https://stackoverflow.com/questions/70076326/how-to-update-istio-configuration-after-installation">https://stackoverflow.com/questions/70076326/how-to-update-istio-configuration-after-installation</a></li></ul>]]></content>
    
    
    <summary type="html">&lt;h1 id=&quot;安装-Istio&quot;&gt;&lt;a href=&quot;#安装-Istio&quot; class=&quot;headerlink&quot; title=&quot;安装 Istio&quot;&gt;&lt;/a&gt;安装 Istio&lt;/h1&gt;&lt;p&gt;最近这段时间一直在做服务网格（Istio）相关的工作，背景是我们准备自建 Istio，首先第一件事情就是要安装。&lt;/p&gt;
&lt;p&gt;我这里直接使用官网推荐的 &lt;a href=&quot;https://istio.io/v1.18/docs/setup/install/istioctl&quot;&gt;istioctl&lt;/a&gt; 进行安装：&lt;/p&gt;
&lt;figure class=&quot;highlight bash&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;12&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;$ &lt;span class=&quot;built_in&quot;&gt;cat&lt;/span&gt; &amp;lt;&amp;lt;&lt;span class=&quot;string&quot;&gt;EOF &amp;gt; ./my-config.yaml&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;string&quot;&gt;apiVersion: install.istio.io/v1alpha1  &lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;string&quot;&gt;kind: IstioOperator  &lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;string&quot;&gt;metadata:  &lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;string&quot;&gt;  namespace: istio-1-18-5  &lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;string&quot;&gt;spec:  &lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;string&quot;&gt;  profile: minimal  &lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;string&quot;&gt;  revision: istio-1-18-5  &lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;string&quot;&gt;  meshConfig:  &lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;string&quot;&gt;    accessLogFile: /dev/stdout&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;string&quot;&gt;EOF&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;$ istioctl install -f my-config.yaml -n istio-1-18-5&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;

&lt;p&gt;这里我使用的 profile 是 minimal，它只会安装核心的控制面，具体差异见下图：&lt;br&gt;&lt;img src=&quot;https://s2.loli.net/2024/12/25/KBu5w4WjLU9zTH3.png&quot; alt=&quot;image.png&quot;&gt;&lt;/p&gt;</summary>
    
    
    
    <category term="Istio" scheme="http://crossoverjie.top/categories/Istio/"/>
    
    <category term="k8s" scheme="http://crossoverjie.top/categories/Istio/k8s/"/>
    
    
    <category term="Istio" scheme="http://crossoverjie.top/tags/Istio/"/>
    
  </entry>
  
  <entry>
    <title>如何在平淡的工作中整理出有价值的简历</title>
    <link href="http://crossoverjie.top/2024/12/10/ob/%E5%A6%82%E4%BD%95%E5%9C%A8%E5%B9%B3%E6%B7%A1%E7%9A%84%E5%B7%A5%E4%BD%9C%E4%B8%AD%E6%95%B4%E7%90%86%E5%87%BA%E6%9C%89%E4%BB%B7%E5%80%BC%E7%9A%84%E7%AE%80%E5%8E%86/"/>
    <id>http://crossoverjie.top/2024/12/10/ob/%E5%A6%82%E4%BD%95%E5%9C%A8%E5%B9%B3%E6%B7%A1%E7%9A%84%E5%B7%A5%E4%BD%9C%E4%B8%AD%E6%95%B4%E7%90%86%E5%87%BA%E6%9C%89%E4%BB%B7%E5%80%BC%E7%9A%84%E7%AE%80%E5%8E%86/</id>
    <published>2024-12-10T07:07:10.000Z</published>
    <updated>2024-12-09T07:09:39.100Z</updated>
    
    <content type="html"><![CDATA[<p>今天在 HackNews 上看到一个<a href="https://news.ycombinator.com/item?id=41937892">帖子</a>：你们是否很难回忆起在工作中做了哪些贡献？</p><p><img src="https://s2.loli.net/2024/10/25/ItaHwFoWzG3ASZV.png"></p><p>我觉得挺多人都有类似的问题，通常都是在需要面试或者内部晋升的时候才开始思考这些问题，这时候在想的话难免会有遗漏。</p><p>结合帖子里的回答我整理了以下以下方法。</p><span id="more"></span><h2 id="每日记录"><a href="#每日记录" class="headerlink" title="每日记录"></a>每日记录</h2><p>好记性不如烂笔头，每日做好工作记录，周末再做一次汇总；<br>有部分公司应该就有类似的制度（日报、周报），但那是写给公司看的，这是写给自己整理的；<br>对自己来说只需要整理有用的内容，去掉那些工作中需要的废话。</p><p>这里推荐可以使用 Obsidian 的 daily 插件，每天点击一下日历就会生成一份文档，周末的时候再点击就会自动将周一到周五的内容进行汇总。<br><img src="https://s2.loli.net/2024/10/25/vQVkq34zCsTMDZh.png"><br><img src="https://s2.loli.net/2024/10/25/RvtwnAP4DQmbYWz.png"><br><img src="https://s2.loli.net/2024/10/25/iCV5YKoyXOmxhsA.png"></p><blockquote><p>建议是在做之前就记录下来，而不是等到今天结束了再记录，此时要么不想记，要么已经忘了。<br>周末汇总的时候可以提炼下，如果是要写到简历里应该怎么写？</p></blockquote><p>同样的观点我在播客<a href="https://www.xiaoyuzhoufm.com/episode/65954bca6d045a7f5e7a9286">代码之外</a>中也有听到，每天在下班的时候进行总结有以下的好处：</p><ul><li>更有仪式感，做完这个后一天的工作就结束了。</li><li>可以学会将任务切分，提高对工作的掌控感。</li><li>长期坚持下来可以增强对任务完成时间的准确预估。</li></ul><h2 id="Git-log-汇总"><a href="#Git-log-汇总" class="headerlink" title="Git log 汇总"></a>Git log 汇总</h2><p>还可以使用 <code>git log --author=&#39;&lt;Your Name&gt;</code> 汇总你对提交记录，然后交给 AI 帮我们总结，这个感觉更适合做工作汇报。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git log --pretty=format:&quot;%h - %an, %ar : %s&quot; --author=&#x27;crossoverJie&#x27; | pbcopy</span><br></pre></td></tr></table></figure><p>在 macOS 中可以使用 <code>pbcopy</code> 命令将输出内容复制到粘贴板，然后我们只需要复制到 chatgpt 中就可以帮我们提炼总结了（但这里的前提是自己的每次提交都是有意义的备注）</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git log --author=&quot;your_username&quot; --since=&quot;2024-01-01&quot; --until=&quot;2024-12-31&quot;</span><br></pre></td></tr></table></figure><p>也可以加上时间筛选，更加精确的统计。</p><h2 id="定时更新简历"><a href="#定时更新简历" class="headerlink" title="定时更新简历"></a>定时更新简历</h2><p>我个人是建议每个季度都更新一下自己的简历，看看有哪些新的东西可以写上去，这也是回顾自己这段时间工作的有效手段，毕竟简历就是要给人看的美化版自己。</p><p><img src="https://s2.loli.net/2024/10/25/BpqVocTehZbUFD6.png"><br> <br>这个帖子还有提到面试时不要害怕写自己不熟的技术栈，即便是只在自己的个人项目中使用过（看来国外和我们也类似）</p><p>这个我觉得得是面试情况而定，如果应聘的 1~3 年的初中级岗位，也不是大厂，那可以这么写，但对于业界都知道的一些大厂（比如阿里、字节）这些面试大概率不会只问表面问题，技术栈写的越多对自己也越没有好处。</p><p>本质上就是需要大家多总结，多参考。</p><p>参考链接：</p><ul><li><a href="https://news.ycombinator.com/item?id=41937892">https://news.ycombinator.com/item?id=41937892</a></li><li><a href="https://www.xiaoyuzhoufm.com/episode/65954bca6d045a7f5e7a9286">https://www.xiaoyuzhoufm.com/episode/65954bca6d045a7f5e7a9286</a></li></ul>]]></content>
    
    
    <summary type="html">&lt;p&gt;今天在 HackNews 上看到一个&lt;a href=&quot;https://news.ycombinator.com/item?id=41937892&quot;&gt;帖子&lt;/a&gt;：你们是否很难回忆起在工作中做了哪些贡献？&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://s2.loli.net/2024/10/25/ItaHwFoWzG3ASZV.png&quot;&gt;&lt;/p&gt;
&lt;p&gt;我觉得挺多人都有类似的问题，通常都是在需要面试或者内部晋升的时候才开始思考这些问题，这时候在想的话难免会有遗漏。&lt;/p&gt;
&lt;p&gt;结合帖子里的回答我整理了以下以下方法。&lt;/p&gt;</summary>
    
    
    
    <category term="OB" scheme="http://crossoverjie.top/categories/OB/"/>
    
    
  </entry>
  
  <entry>
    <title>如何选择可以搞钱的技术栈</title>
    <link href="http://crossoverjie.top/2024/11/26/ob/%E5%A6%82%E4%BD%95%E9%80%89%E6%8B%A9%E5%8F%AF%E4%BB%A5%E6%90%9E%E9%92%B1%E7%9A%84%E6%8A%80%E6%9C%AF%E6%A0%88/"/>
    <id>http://crossoverjie.top/2024/11/26/ob/%E5%A6%82%E4%BD%95%E9%80%89%E6%8B%A9%E5%8F%AF%E4%BB%A5%E6%90%9E%E9%92%B1%E7%9A%84%E6%8A%80%E6%9C%AF%E6%A0%88/</id>
    <published>2024-11-26T14:50:58.000Z</published>
    <updated>2024-11-26T14:57:10.858Z</updated>
    
    <content type="html"><![CDATA[<h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>之前在公司主要负责可观测性和 Pulsar 消息队列相关的内容，最近系统比较稳定，只需要做日常运维，所以就抽出时间逐步在接触 OLAP 相关的技术栈。</p><p>我们用的是 <a href="https://www.starrocks.io/">StarRocks</a>，也是目前比较流行的 OLAP 数据库；在接触的这段时间以来，让我越发感觉到选对一个靠谱的技术方向的重要性。</p><span id="more"></span><p>这里以 <a href="https://pulsar.apache.org/">Pulsar</a> 举例，Pulsar 也是 Apache 的顶级项目，有一定的技术门槛，同时也解决以往消息队列的一些问题（多租户、低延迟、存算分离等） 但如果把它作为一个商业产品的话，相对来说付费能力还不够强。</p><p>其实也能想得到，就单纯的消息中间件在市场上能讲的故事不多，可以将它融入到其他的生态里，比如数据处理、业务解耦等，但总归是配角，没有它虽然没那么优雅，但也可以玩。</p><p>同理 OpenTelemetry 也是类似的，它用于可观测性系统，主要是就是拿来排查问题的，对于企业来说也谈不上刚需。</p><p>他们两个都有一个共同的特点：小公司不需要（或者自己维护开源版，量小也不容易暴露问题），大公司选择单独的团队自己维护，市场蛋糕较小。</p><p>即便是部分中厂可能选择购买云服务，一般也会选择和自己现有技术栈配套的云厂商，比如已经用了大部分阿里云的产品，这种周边服务也会尽可能的在阿里云上选择替代方案，毕竟这样的风险更小，而且国内的产品大多都写还 ALL IN。</p><blockquote><p>可能更多的还是一些政企、金融等业务会选择这些开源产品的企业版，大部分因为需要私有化部署，不太方便直接使用公有云。</p></blockquote><p>而更刚需的往往都是和数据相关的，比如数据库、MongoDB、ElasticSearch 、kubernetes 等，如果想要提升下非业务水平，倒是可以深入一下这些技术栈。</p><h1 id="举例"><a href="#举例" class="headerlink" title="举例"></a>举例</h1><p>拿数据库来说，任何公司都需要，即便是小公司也不敢在生产环境自己维护数据库，一般也会购买云产品，或者是招一个 DBA。</p><p>同理还有云原生相关的基础技术栈，比如 kubernetes 以及围绕着 kubernetes 周边的生态。</p><p>k8s 作为云原生的基础底座，只要涉及到上云就离不开它，不管小厂选择云服务还是大厂自己托管都得需要相关技能。</p><p>即便不是直接做 kubernetes 开发也得需要了解相关的知识，对自己理解整个系统是如何运转的很大的帮助。</p><p>除此之外还有也有个简单的方法：就是看看你们公司为哪些服务买单。</p><p>以我最近接触到的 StarRocks 为例，也是和数据处理相关的公司，他们在疫情期间成立的商业化公司，这几年非但没受到影响反而还在增长。</p><p><img src="https://s2.loli.net/2024/10/10/26uepDnY1yPzBaV.png"></p><blockquote><p>看到他们的招聘还蛮活跃。</p></blockquote><p>即便是厂商更倾向于选择云厂商的数据服务，StarRocks 这类原厂公司或多或少也会参与进去提供一些技术支持。</p><p>不过可能有人的第一反应是这些产品的技术门槛较高，上手比较困难，但其实这些往往都是自己给自己上的难度。</p><p>以我最近提交的一个 PR 来说:<br><a href="https://github.com/StarRocks/starrocks/pull/50926">https://github.com/StarRocks/starrocks/pull/50926</a></p><p>我之前根本就没有接触过 OLAP 相关的内容，但只要有场景，可以在本地 debug 复现，任何问题都很好解决，即便是这是你不熟的技术栈。</p><p>比如 ES 也是 Java 写的，如果你们公司为它付费了，那不如多花时间研究一下，不一定是需要改它的核心逻辑，上层也有很多东西可以参与的。</p><p>而一旦我们对这些技术栈熟悉之后，今后在换工作时就有着其他人不具备的优势，甚至可以加入这些技术背后的商业公司。</p><p>而这些公司大部分都是满足开发者的喜好：比如远程办公、技术驱动等，大家不妨从现在就可以试试。</p><h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>不管是哪种技术最终都是要转换为我们到手的收入，所以选择对收入更加敏感的技术栈还是很有必要的。</p><p>以上的内容主要是针对后端开发，当然这里并不包含想要做独立开发的技术栈，主要还是用于求职。</p><p>大家可以看看自己公司以及曾经的公司有对哪些技术付费，或者是一些都需要的刚需通用的技术栈，深入这些技能对搞钱或多或少都有好处。</p>]]></content>
    
    
    <summary type="html">&lt;h1 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h1&gt;&lt;p&gt;之前在公司主要负责可观测性和 Pulsar 消息队列相关的内容，最近系统比较稳定，只需要做日常运维，所以就抽出时间逐步在接触 OLAP 相关的技术栈。&lt;/p&gt;
&lt;p&gt;我们用的是 &lt;a href=&quot;https://www.starrocks.io/&quot;&gt;StarRocks&lt;/a&gt;，也是目前比较流行的 OLAP 数据库；在接触的这段时间以来，让我越发感觉到选对一个靠谱的技术方向的重要性。&lt;/p&gt;</summary>
    
    
    
    <category term="OB" scheme="http://crossoverjie.top/categories/OB/"/>
    
    
  </entry>
  
  <entry>
    <title>推荐一些值得学习的开源项目和框架</title>
    <link href="http://crossoverjie.top/2024/11/20/ob/%E6%8E%A8%E8%8D%90%E4%B8%80%E4%BA%9B%E5%80%BC%E5%BE%97%E5%AD%A6%E4%B9%A0%E7%9A%84%E5%BC%80%E6%BA%90%E9%A1%B9%E7%9B%AE%E5%92%8C%E6%A1%86%E6%9E%B6/"/>
    <id>http://crossoverjie.top/2024/11/20/ob/%E6%8E%A8%E8%8D%90%E4%B8%80%E4%BA%9B%E5%80%BC%E5%BE%97%E5%AD%A6%E4%B9%A0%E7%9A%84%E5%BC%80%E6%BA%90%E9%A1%B9%E7%9B%AE%E5%92%8C%E6%A1%86%E6%9E%B6/</id>
    <published>2024-11-20T09:06:46.000Z</published>
    <updated>2024-11-20T09:07:50.027Z</updated>
    
    <content type="html"><![CDATA[<p><img src="https://s2.loli.net/2024/11/06/YtoOV3dMNEsqw4u.png" alt="image.png"><br>今天收到球友的问题，让推荐一些值得看的开源项目，觉得 netty 这些太复杂了不太好上手。</p><p>确实如此，我们日常常用的 Spring、Netty 确实由于发展了多年，看起来比较头大。</p><p>下面我来推荐一些我看过同时觉得不错的项目(几乎都是我参与过的），由易到难，其中也会包含 Java 和 Go 的项目，包含主流的中间件和云原生项目。</p><span id="more"></span><h1 id="Java-项目"><a href="#Java-项目" class="headerlink" title="Java 项目"></a>Java 项目</h1><h2 id="xxl-job"><a href="#xxl-job" class="headerlink" title="xxl-job"></a>xxl-job</h2><p>难度：🌟🌟<br>推荐指数：🌟🌟🌟</p><p><img src="https://s2.loli.net/2024/11/06/xuLRoCfVhiFcjbz.png"></p><p><a href="https://github.com/xuxueli/xxl-job">xxl-job</a> 是一个很经典的调度框架，目前在 GitHub 上也有 27k star 的关注，因为功能不复杂所以最近也没有怎么更新了。</p><p>大家日常都会使用这类调度框架，所以理解难度非常低，加上他的实现也比较简单，比如：</p><ul><li>使用 MySQL 的锁来简单粗暴的解决分布式锁的问题</li><li>线程池的使用：因为每个任务的调度都需要尽可能的互相不影响，所以里面大量使用了线程池，同时对如何获取异步任务结果也有一些最佳实践。</li><li>RPC 调用：里面内置了一个 <a href="https://github.com/xuxueli/xxl-rpc">RPC</a> 框架，也是作者编写的，其中的实现原理也不复杂，建议看看源码，可以更好的理解我们在工作中用到 rpc 框架。</li></ul><h2 id="cim"><a href="#cim" class="headerlink" title="cim"></a>cim</h2><p>难度：🌟🌟🌟<br>推荐指数：🌟🌟🌟<br>这里夹了一点私货，就是我自己开源的一个<a href="https://github.com/crossoverJie/cim">分布式即时通讯系统</a>，其实现在来看上一个版本的代码写的挺烂的，不过好在最近发布了 v2.0.0，提升了不少代码质量。</p><p><img src="https://s2.loli.net/2024/10/14/pBvDML4HVgyYZxS.gif" alt="Oct-14-2024 11-09-54-min.gif"><br>它具备 IM 即时通讯的基本功能，同时基于它可以实现：</p><ul><li>即时通讯</li><li>消息推送</li><li>IOT 消息平台</li></ul><p>通过 cim 你可以学习到分布式系统中：</p><ul><li>元数据是如何存放和同步的。</li><li>RPC 调用如何实现。</li><li>长链接系统如何实现。</li><li>复杂的分布式系统如何做集成测试等。</li></ul><p>详细的介绍可以查看项目首页的 <a href="https://github.com/crossoverJie/cim">readme</a>，发现有什么需要优化的地方（其实还蛮多 todo 没有做）都欢迎提交 PR。</p><h2 id="PowerJob"><a href="#PowerJob" class="headerlink" title="PowerJob"></a>PowerJob</h2><p>难度：🌟🌟🌟<br>推荐指数：🌟🌟🌟🌟<br><a href="https://github.com/PowerJob/PowerJob">PowerJob</a> 也是一个调度框架，只是他有后发优势，结合了市面上其他调度系统的优点同时也新增了一些功能，以下是他功能的官方对比图：<br><img src="https://s2.loli.net/2024/11/07/Ngab96HlYstJOyT.png"><br>社区相对于 xxl-job 也更加活跃，目前刚发布了 <code>5.1.0</code> 版本，同时社区也整理许多学习的文章和<a href="https://www.yuque.com/powerjob/guidence/wu2e93">资料</a>：</p><p><img src="https://s2.loli.net/2024/11/07/aGUzAwhX5CE2Lbj.png" alt="image.png"></p><p>它使用了 Akka 来实现远程通信，对这部分内容感兴趣的朋友不容错过，可以看到一些最佳实践。<br>其中的代码写的也很规范，一些类的设计很好，可扩展性很高，比如常用的执行器都是通过一个<br><code>MapProcessor</code> 扩展而来的。<br><img src="https://s2.loli.net/2024/11/07/SO2eRbvqrI5EGyU.png" alt="image.png"><br><img src="https://s2.loli.net/2024/11/07/rvabkCdo4g3FTyU.png" alt="image.png"></p><p>推荐大家从任务调度那一块开始看：<code>tech.powerjob.worker.actors.TaskTrackerActor#onReceiveServerScheduleJobReq</code></p><h2 id="Pulsar"><a href="#Pulsar" class="headerlink" title="Pulsar"></a>Pulsar</h2><p>难度：🌟🌟🌟🌟<br>推荐指数：🌟🌟🌟🌟<br><img src="https://s2.loli.net/2024/11/07/2MFiE1vPSfl69ty.png" alt="image.png"><br>Pulsar 是目前主流的云原生消息队列中间件，现在使用的公司也非常多，通过他你可以学习到：</p><ul><li>API 设计：Pulsar 的 client 是直接面向开发者的，在易用性的前提下每次迭代升级还要考虑到兼容性。</li><li>异步调用：Pulsar 里几乎所有的请求都是异步的，所以大量使用了异步➕回调（虽然也有一些坑），可以学到一些高性能代码的编写方式。</li><li>Netty 的最佳用法：消息收发的底层网络框架也是 Netty 支撑的，Pulsar 对它做了封装。</li><li>基于 protocol 的多语言客户端。<ul><li>因为 Pulsar 的通信编解码使用的是 protocol，本身是可以基于它生成各种语言的 API，所以在此基础上编写其他语言的客户端就非常方便。</li></ul></li></ul><p>不过由于 Pulsar 本身的复杂性，上手起来门槛还是不低，推荐先从客户端的代码（Java 和  Go 的都可以）上手。</p><h2 id="StarRocks"><a href="#StarRocks" class="headerlink" title="StarRocks"></a>StarRocks</h2><p>难度：🌟🌟🌟🌟🌟<br>推荐指数：🌟🌟🌟🌟<br><img src="https://s2.loli.net/2024/11/08/zZ8jD9JU1tSkm6A.png" alt="image.png"></p><p>StarRocks 也是我最近才接触到的 OLAP 数据库项目，以前对这个领域的积累几乎为零，所以也是从头学习。</p><p>好在这段时间因为有需求也给它提交了几个 PR，逐渐熟悉起来了。<br><img src="https://s2.loli.net/2024/11/08/gVb15UWrwXHq8YI.png" alt="image.png"></p><p>我接触下来这些开源项目，发现 StarRocks 这类数据库项目是最有前（钱）景的，毕竟和数据打交道的产品公司的付费意愿会更高一些。</p><p>不过该项目确实对新手不太友好，最好是已经接触过大数据领域再学习会更合适一些，但也不要怕，我就是一个纯小白，没基础就跟着代码 debug，反正都是 Java 写的总能看懂。</p><p>这里推荐先看看我之前写的<a href="https://crossoverjie.top/2024/10/09/ob/StarRocks-dev-env-build/">本地搭建开发环境</a>，这样就可以在 idea 里 debug 了。</p><h2 id="OpenTelemetry"><a href="#OpenTelemetry" class="headerlink" title="OpenTelemetry"></a>OpenTelemetry</h2><p>难度：🌟🌟🌟🌟<br>推荐指数：🌟🌟🌟🌟🌟<br><img src="https://s2.loli.net/2024/08/08/p5WkVbSarUdIQwT.png"><br>OpenTelemetry 现在作为云原生可观测性的事实标准，现在已经逐步成为各大公司必备的技术栈了。</p><p>通过一个 <code>javaagent</code> 就可以自动采集应用的 trace、metrics、logs 等数据，这里先推荐 <a href="https://github.com/open-telemetry/opentelemetry-java-instrumentation/">opentelemetry-java-instrumentation</a>，因为我们日常使用最多的就是基于这个项目打包出来的 <code>javaagent</code>，通过它可以学习到：</p><ul><li>如何编写任意函数的拦截器</li><li>trace 信息是如何在线程和进程之间传递的</li><li>一些常用框架是如何运行的<ul><li>比如你需要了解 <a href="https://github.com/open-telemetry/opentelemetry-java-instrumentation/tree/main/instrumentation/grpc-1.6">gRPC</a> 的原理，就可以查看 OpenTelemetry 是如何对他埋点的，从而知晓他的核心原理。</li></ul></li><li>优雅的 API 设计</li></ul><p><img src="https://s2.loli.net/2024/11/08/1yenwuxJ9C6tOSb.png" alt="image.png"><br>同时 OpenTelemetry 算是我看过最优雅的代码之一了，非常建议大家都看看。</p><p>如果对 OpenTelemetry 还不太熟悉，可以先看看我<a href="https://crossoverjie.top/tags/OpenTelemetry/">之前写过的文章</a>。</p><h1 id="Go（云原生项目）"><a href="#Go（云原生项目）" class="headerlink" title="Go（云原生项目）"></a>Go（云原生项目）</h1><h2 id="cprobe"><a href="#cprobe" class="headerlink" title="cprobe"></a>cprobe</h2><p>难度：🌟🌟🌟<br>推荐指数：🌟🌟🌟</p><p><a href="https://github.com/cprobe/cprobe">cprobe</a> 属于可观测性项目，他的目的是可以把各种 exporter 都整合在一起，比如 <code>kafka_exporter</code>, <code>nginx_exporter</code>, <code>mysql_exporter</code> 等。</p><p>同时还做了上层抽象，可以统一管理各种监控对象的配置，这样就可以部署一个进程监控所有的应用了。</p><p>通过这个项目可以学到：</p><ul><li>监控体系的基础知识，比如 Prometheus 和 metrics 等</li><li>Go 语言的基本用法</li></ul><p>我之前写过一篇 <a href="https://crossoverjie.top/2024/01/25/ob/create-a-plugin-for-cprobe/">手把手教你为开源项目贡献代码</a>就是以 cprobe 为例来介绍的。</p><h2 id="VictoriaLogs"><a href="#VictoriaLogs" class="headerlink" title="VictoriaLogs"></a>VictoriaLogs</h2><p>难度：🌟🌟🌟🌟<br>推荐指数：🌟🌟🌟🌟</p><p>这是一个属于 <a href="https://github.com/VictoriaMetrics/VictoriaMetrics/tree/master/app/victoria-logs">VictoriaMetrics</a> 的一个子项目，通过这个名字应该会知道他主要用于处理日志，可以把他理解为 ElasticSearch 的简易版，虽然功能简单了但资源消耗也会比 ES 低很多，具体可以看下面的压测图：</p><p><img src="https://s2.loli.net/2023/08/23/3Epxdzie8q5tVmY.png" alt="image.png"></p><p>通过这个项目可以学到：</p><ul><li>数据在磁盘中是如何存储和查询的</li><li>Go 语言中关于 <code>goroutine</code> 和 <code>channel</code> 的一些最佳实践<br>目前的版本还比较早，所以代码都不太复杂，建议大家可以从查询的入口开始<a href="https://github.com/VictoriaMetrics/VictoriaMetrics/blob/master/lib/logstorage/storage_search.go">看起</a>。</li></ul><h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>以上都是我正经接触过的项目，如果是想长期耕耘同时搞钱的话，推荐 <code>StarRocks</code>，目前也很火。</p><p>如果只是想提升在 Java 领域的水平，那推荐 Pulsar 和 OpenTelemetry，都有很多代码最佳实践。</p><p>如果想要入坑云原生和 Go 项目，那 cprobe 是比较合适的。</p><p>当然不管是哪个项目最主要的还是坚持，很多项目如果只是偶尔看一下很容易忘记，起码要做到真正运行起来然后 debug 过代码。</p><p>参考链接：</p><ul><li><a href="https://www.yuque.com/powerjob/guidence/wu2e93">https://www.yuque.com/powerjob/guidence/wu2e93</a></li><li><a href="https://github.com/VictoriaMetrics/VictoriaMetrics/blob/master/lib/logstorage/storage_search.go">https://github.com/VictoriaMetrics/VictoriaMetrics/blob/master/lib/logstorage/storage_search.go</a></li><li><a href="https://crossoverjie.top/tags/OpenTelemetry/">https://crossoverjie.top/tags/OpenTelemetry/</a></li><li><a href="https://crossoverjie.top/2024/10/09/ob/StarRocks-dev-env-build/">https://crossoverjie.top/2024/10/09/ob/StarRocks-dev-env-build/</a></li></ul>]]></content>
    
    
    <summary type="html">&lt;p&gt;&lt;img src=&quot;https://s2.loli.net/2024/11/06/YtoOV3dMNEsqw4u.png&quot; alt=&quot;image.png&quot;&gt;&lt;br&gt;今天收到球友的问题，让推荐一些值得看的开源项目，觉得 netty 这些太复杂了不太好上手。&lt;/p&gt;
&lt;p&gt;确实如此，我们日常常用的 Spring、Netty 确实由于发展了多年，看起来比较头大。&lt;/p&gt;
&lt;p&gt;下面我来推荐一些我看过同时觉得不错的项目(几乎都是我参与过的），由易到难，其中也会包含 Java 和 Go 的项目，包含主流的中间件和云原生项目。&lt;/p&gt;</summary>
    
    
    
    <category term="OpenSource" scheme="http://crossoverjie.top/categories/OpenSource/"/>
    
    
    <category term="OpenSource" scheme="http://crossoverjie.top/tags/OpenSource/"/>
    
  </entry>
  
  <entry>
    <title>StarRocks 物化视图刷新流程和原理</title>
    <link href="http://crossoverjie.top/2024/11/18/ob/StarRocks-MV-refresh-Principle/"/>
    <id>http://crossoverjie.top/2024/11/18/ob/StarRocks-MV-refresh-Principle/</id>
    <published>2024-11-18T14:35:25.000Z</published>
    <updated>2024-11-18T10:46:12.231Z</updated>
    
    <content type="html"><![CDATA[<p>前段时间给 StarRocks 的物化视图新增了一个<a href="https://github.com/StarRocks/starrocks/pull/50926">特性</a>，那也是我第一次接触 StarRocks，因为完全不熟悉这个数据库，所以很多东西都是从头开始了解概念。</p><p>为了能顺利的新增这个特性（具体内容可以见后文），我需要把整个物化视图的流程串联一遍，于是便有了这篇文章。</p><p>在开始之前简单了解下物化视图的基本概念：</p><p><img src="https://s2.loli.net/2024/11/13/TMAjuUsEZGJiFDS.png" alt="image.png"></p><p>简单来说，视图和 MySQL 这类传统数据库的概念类似，也是用于解决大量消耗性能的 SQL 的，可以提前将这些数据查询好然后放在一张单独的表中，这样再查询的时候性能消耗就比较低了。</p><span id="more"></span><h1 id="刷新条件"><a href="#刷新条件" class="headerlink" title="刷新条件"></a>刷新条件</h1><p>为了保证视图数据的实时性，还需要在数据发生变化的时候能够及时刷新视图里的数据，目前有这几个地方会触发视图刷新：<br><img src="https://s2.loli.net/2024/11/13/vJFQBAyfus5ZwIT.png" alt="image.png"></p><ul><li>手动刷新视图，使用 <code>REFRESH MATERIALIZED VIEW order_mv;</code> 语句</li><li>将视图设置为 active 状态：<code>ALTER MATERIALIZED VIEW order_mv ACTIVE;</code></li><li>基表数据发生变化时触发刷新。<ul><li><img src="https://s2.loli.net/2024/11/13/6QCojHZEJcUL4t2.png" alt="image.png"></li></ul></li><li>truncate 基表时触发刷新：<code>truncate table trunc_db.t1;</code> </li><li>drop partition 时触发：<code>ALTER TABLE &lt;tbl_name&gt; DROP PARTITION(S) p0, p1 [, ...];</code></li></ul><p>这里的 truncate table  和 drop partition 目前的版本还存在 bug：当基表和物化视图不在一个数据库时不会触发自动刷新，目前已经修复了。</p><p><img src="https://s2.loli.net/2024/11/13/2wtZfnFTUbsHaY4.png" alt="image.png"></p><ul><li><a href="https://github.com/StarRocks/starrocks/pull/52618">https://github.com/StarRocks/starrocks/pull/52618</a></li><li><a href="https://github.com/StarRocks/starrocks/pull/52295">https://github.com/StarRocks/starrocks/pull/52295</a></li></ul><h1 id="刷新流程"><a href="#刷新流程" class="headerlink" title="刷新流程"></a>刷新流程</h1><p><img src="https://s2.loli.net/2024/11/14/QljDLmRrx97EIK6.png" alt="image.png"></p><p>如图所示，当触发一次刷新之后主要就是需要计算出需要刷新的分区。</p><p>第一次触发刷新的时候是不会带上周期（比如时间范围），然后根据过滤计算出来的周期，默认情况下只会使用第一个周期（我们可以通过 <code>partition_refresh_number</code> 参数来调整单次刷新的分区数量）。</p><p><img src="https://s2.loli.net/2024/11/14/3QFtkXRfvhCdNrS.png"></p><p>然后如果还有其余的周期，会将这些周期重新触发一次刷新任务（会带上刚才剩余的周期数据），这样进行递归执行。</p><p><img src="https://s2.loli.net/2024/11/15/OqjuMl1LNkWh39g.png"></p><p>通过日志会看到返回的分区数据。</p><h1 id="新增优化参数"><a href="#新增优化参数" class="headerlink" title="新增优化参数"></a>新增优化参数</h1><p>我们在使用物化视图的时候，碰到一个场景：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> IF <span class="keyword">NOT</span> <span class="keyword">EXISTS</span> test.par_tbl1</span><br><span class="line">(</span><br><span class="line">    datekey DATETIME,</span><br><span class="line">    k1      <span class="type">INT</span>,</span><br><span class="line">    item_id STRING,</span><br><span class="line">    v2      <span class="type">INT</span></span><br><span class="line">)<span class="keyword">PRIMARY</span> KEY (`datekey`,`k1`)</span><br><span class="line"> <span class="keyword">PARTITION</span> <span class="keyword">BY</span> date_trunc(<span class="string">&#x27;day&#x27;</span>, `datekey`);</span><br><span class="line"></span><br><span class="line"> <span class="keyword">CREATE</span> <span class="keyword">TABLE</span> IF <span class="keyword">NOT</span> <span class="keyword">EXISTS</span> test.par_tbl2</span><br><span class="line">(</span><br><span class="line">    datekey DATETIME,</span><br><span class="line">    k1      <span class="type">INT</span>,</span><br><span class="line">    item_id STRING,</span><br><span class="line">    v2      <span class="type">INT</span></span><br><span class="line">)<span class="keyword">PRIMARY</span> KEY (`datekey`,`k1`)</span><br><span class="line"> <span class="keyword">PARTITION</span> <span class="keyword">BY</span> date_trunc(<span class="string">&#x27;day&#x27;</span>, `datekey`);</span><br><span class="line"></span><br><span class="line"> <span class="keyword">CREATE</span> <span class="keyword">TABLE</span> IF <span class="keyword">NOT</span> <span class="keyword">EXISTS</span> test.par_tbl3</span><br><span class="line">(</span><br><span class="line">    datekey DATETIME,</span><br><span class="line">    k1      <span class="type">INT</span>,</span><br><span class="line">    item_id STRING,</span><br><span class="line">    v2      <span class="type">INT</span></span><br><span class="line">)</span><br><span class="line"> <span class="keyword">PRIMARY</span> KEY (`datekey`,`k1`);</span><br></pre></td></tr></table></figure><p>但我们有三张基表，其中 1 和 2 都是分区表，但是 3 是非分区表。</p><p>此时基于他们新建了一个物化视图：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE</span></span><br><span class="line">MATERIALIZED <span class="keyword">VIEW</span> test.mv_test</span><br><span class="line">REFRESH ASYNC</span><br><span class="line"><span class="keyword">PARTITION</span> <span class="keyword">BY</span> a_time</span><br><span class="line">PROPERTIES (</span><br><span class="line">&quot;excluded_trigger_tables&quot; <span class="operator">=</span> &quot;par_tbl3&quot;</span><br><span class="line">)</span><br><span class="line"><span class="keyword">AS</span></span><br><span class="line"><span class="keyword">select</span> date_trunc(&quot;day&quot;, a.datekey) <span class="keyword">as</span> a_time, date_trunc(&quot;day&quot;, b.datekey) <span class="keyword">as</span> b_time,date_trunc(&quot;day&quot;, c.datekey) <span class="keyword">as</span> c_time</span><br><span class="line"><span class="keyword">from</span> test.par_tbl1 a</span><br><span class="line">         <span class="keyword">left</span> <span class="keyword">join</span> test.par_tbl2 b <span class="keyword">on</span> a.datekey <span class="operator">=</span> b.datekey <span class="keyword">and</span> a.k1 <span class="operator">=</span> b.k1</span><br><span class="line">         <span class="keyword">left</span> <span class="keyword">join</span> test.par_tbl3 c <span class="keyword">on</span> a.k1 <span class="operator">=</span> c.k1;</span><br></pre></td></tr></table></figure><p>当我同时更新了分区表和非分区表的数据时：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">UPDATE</span> `par_tbl1` <span class="keyword">SET</span> `v2` <span class="operator">=</span> <span class="number">2</span> <span class="keyword">WHERE</span> `datekey` <span class="operator">=</span> <span class="string">&#x27;2024-08-05 01:00:00&#x27;</span> <span class="keyword">AND</span> `k1` <span class="operator">=</span> <span class="number">3</span>;</span><br><span class="line"><span class="keyword">UPDATE</span> `par_tbl3` <span class="keyword">SET</span> `item_id` <span class="operator">=</span> <span class="string">&#x27;3&#x27;</span> <span class="keyword">WHERE</span> `datekey` <span class="operator">=</span> <span class="string">&#x27;2024-10-01 01:00:00&#x27;</span> <span class="keyword">AND</span> `k1` <span class="operator">=</span> <span class="number">3</span>;</span><br></pre></td></tr></table></figure><p>预期的结果是只有 <code>par_tbl1</code> 表里修改的数据会被同步到视图（<code>&quot;excluded_trigger_tables&quot; = &quot;par_tbl3&quot;</code>已经被设置为不会触发视图刷新），但实际情况是 <code>par_tbl1</code> 和 <code>par_tbl2</code> 表里所有的数据都会被刷新到物化视图中。</p><p>我们可以使用这个 SQL 查询无刷视图任务的运行状态：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> information_schema.task_runs <span class="keyword">order</span> <span class="keyword">by</span> create_time <span class="keyword">desc</span>;</span><br></pre></td></tr></table></figure><p>这样就会造成资源损耗，如果这两张基表的数据非常大，本次刷新会非常耗时。</p><p>所以我们的需求是在这样的场景下也只刷新修改的数据。</p><p>因此我们在新建物化视图的时候新增了一个参数：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE</span></span><br><span class="line">MATERIALIZED <span class="keyword">VIEW</span> test.mv_test</span><br><span class="line">REFRESH ASYNC</span><br><span class="line"><span class="keyword">PARTITION</span> <span class="keyword">BY</span> a_time</span><br><span class="line">PROPERTIES (</span><br><span class="line">&quot;excluded_trigger_tables&quot; <span class="operator">=</span> &quot;par_tbl3&quot;,</span><br><span class="line">&quot;excluded_refresh_tables&quot;<span class="operator">=</span>&quot;par_tbl3&quot;</span><br><span class="line">)</span><br><span class="line"><span class="keyword">AS</span></span><br><span class="line"><span class="keyword">select</span> date_trunc(&quot;day&quot;, a.datekey) <span class="keyword">as</span> a_time, date_trunc(&quot;day&quot;, b.datekey) <span class="keyword">as</span> b_time,date_trunc(&quot;day&quot;, c.datekey) <span class="keyword">as</span> c_time</span><br><span class="line"><span class="keyword">from</span> test.par_tbl1 a</span><br><span class="line">         <span class="keyword">left</span> <span class="keyword">join</span> test.par_tbl2 b <span class="keyword">on</span> a.datekey <span class="operator">=</span> b.datekey <span class="keyword">and</span> a.k1 <span class="operator">=</span> b.k1</span><br><span class="line">         <span class="keyword">left</span> <span class="keyword">join</span> test.par_tbl3 c <span class="keyword">on</span> a.k1 <span class="operator">=</span> c.k1;</span><br></pre></td></tr></table></figure><p>这样当在刷新数据的时候，会判断 <code>excluded_refresh_tables</code> 配置的表是否有发生数据变化，如果有的话则不能将当前计算出来的分区（1,2 两张表的全量数据）全部刷新，而是继续求一个交集，只计算基表发生变化的数据。</p><p>这样就可以避免 par_tbl1、par_tbl2 的数据全量刷新，而只刷新修改的数据。</p><p>这样的场景通常是在关联的基表中有一张字典表，通常数据量不大，所以也不需要分区的场景。</p><p>这样在创建物化视图的时候就可以使用这两个参数 <code>excluded_trigger_tables，excluded_refresh_tables</code> 将它排除掉了。</p><p><img src="https://s2.loli.net/2024/11/15/lrGJEnRgyQDd2Pc.png"></p><p>整体的刷新逻辑并不复杂，主要就是几个不同的刷新入口以及刷新过程中计算分区的逻辑。</p><p>参考链接：</p><ul><li><a href="https://docs.starrocks.io/zh/docs/using_starrocks/async_mv/Materialized_view/#%E7%90%86%E8%A7%A3-starrocks-%E7%89%A9%E5%8C%96%E8%A7%86%E5%9B%BE">https://docs.starrocks.io/zh/docs/using_starrocks/async_mv/Materialized_view/#%E7%90%86%E8%A7%A3-starrocks-%E7%89%A9%E5%8C%96%E8%A7%86%E5%9B%BE</a></li><li><a href="https://docs.starrocks.io/zh/docs/using_starrocks/async_mv/use_cases/data_modeling_with_materialized_views/#%E5%88%86%E5%8C%BA%E5%BB%BA%E6%A8%A1">https://docs.starrocks.io/zh/docs/using_starrocks/async_mv/use_cases/data_modeling_with_materialized_views/#%E5%88%86%E5%8C%BA%E5%BB%BA%E6%A8%A1</a></li><li><a href="https://github.com/StarRocks/starrocks/pull/52295">https://github.com/StarRocks/starrocks/pull/52295</a></li><li><a href="https://github.com/StarRocks/starrocks/pull/52618">https://github.com/StarRocks/starrocks/pull/52618</a></li></ul>]]></content>
    
    
    <summary type="html">&lt;p&gt;前段时间给 StarRocks 的物化视图新增了一个&lt;a href=&quot;https://github.com/StarRocks/starrocks/pull/50926&quot;&gt;特性&lt;/a&gt;，那也是我第一次接触 StarRocks，因为完全不熟悉这个数据库，所以很多东西都是从头开始了解概念。&lt;/p&gt;
&lt;p&gt;为了能顺利的新增这个特性（具体内容可以见后文），我需要把整个物化视图的流程串联一遍，于是便有了这篇文章。&lt;/p&gt;
&lt;p&gt;在开始之前简单了解下物化视图的基本概念：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://s2.loli.net/2024/11/13/TMAjuUsEZGJiFDS.png&quot; alt=&quot;image.png&quot;&gt;&lt;/p&gt;
&lt;p&gt;简单来说，视图和 MySQL 这类传统数据库的概念类似，也是用于解决大量消耗性能的 SQL 的，可以提前将这些数据查询好然后放在一张单独的表中，这样再查询的时候性能消耗就比较低了。&lt;/p&gt;</summary>
    
    
    
    <category term="StarRocks" scheme="http://crossoverjie.top/categories/StarRocks/"/>
    
    
    <category term="StarRocks" scheme="http://crossoverjie.top/tags/StarRocks/"/>
    
  </entry>
  
  <entry>
    <title>深入理解 StarRocks 的元数据管理</title>
    <link href="http://crossoverjie.top/2024/11/11/ob/StarRocks-meta/"/>
    <id>http://crossoverjie.top/2024/11/11/ob/StarRocks-meta/</id>
    <published>2024-11-11T10:44:37.000Z</published>
    <updated>2024-11-11T13:54:42.770Z</updated>
    
    <content type="html"><![CDATA[<h1 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h1><p>最近在排查 <code>starrocks</code> 线上的一个告警日志：</p><p><img src="https://s2.loli.net/2024/09/26/QtMIBdmL7OciVJa.png"></p><p>每隔一段时间都会打印 <code>base-table</code> 也就是物化视图的基表被删除了，但其实表还在，也没人去删除；我们就怀疑是否真的表被删除了（可能是 bug）。</p><p>与此同时还有物化视图 inactive 的日志，也怀疑如果视图是 inactive 之后会导致业务使用有问题。</p><p>为了确认这个日志是否对使用影响，就得需要搞清楚它出现的原因；于是我就着手从日志打印的地方开始排查。</p><span id="more"></span><h1 id="问题排查"><a href="#问题排查" class="headerlink" title="问题排查"></a>问题排查</h1><p><img src="https://s2.loli.net/2024/09/26/2T4sGfw1YC63EuP.png"><br>从这个代码可以看出，是在查询表的信息的时候没有查到，从而导致日志打印 base-table 被 dropped 了。</p><p>而我查询了几天的 <code>drop table</code> 的日志，依然没有找到可能是程序 bug 导致被删除的痕迹。</p><blockquote><p>好在 starrocks 的日志打印非常详细，包含了线程名称、类+方法名称，还有具体的代码函数，很容易就定位日志输出的地方。</p></blockquote><h2 id="元数据"><a href="#元数据" class="headerlink" title="元数据"></a>元数据</h2><p>只是为何会调用到这里还需要阅读源码从而找到原因，在开始之前需要先了解一下 starrocks 元数据的一些基本概念。</p><blockquote><p>其实在这篇文章：<a href="https://xie.infoq.cn/article/6f2f9f56916f0eb2fdb6b001a">StarRocks 元数据管理及 FE 高可用机制</a>中已经有全面的介绍，只是这篇文章有点早了，和现在最新的代码不太匹配。</p></blockquote><p>在 StarRocks 元数据中会保存 Database、Table 等信息。</p><p>这些数据定期保存在 <code>fe/meta</code> 目录中。<br><img src="https://s2.loli.net/2024/09/27/3C4GaXM5BlWmNIw.png"></p><p>StarRocks 对元数据的每一次操作（增删改查数据库、表、物化视图）都会生成 editLog 的操作日志。</p><p><img src="https://s2.loli.net/2024/09/27/5hbDBHGwtarE8fj.png" alt="image.png"></p><blockquote><p>新建数据库、修改表名称等</p></blockquote><p>当 StarRocks 的 FE 集群部署时，会由 leader 的 FE 启动一个 checkpoint 线程，定时扫描当前的元数据是否需要生成一个 <code>image.$&#123;JournalId&#125;</code> 的文件。</p><p><img src="https://s2.loli.net/2024/09/20/lQCkBnNWIZ4GwuV.png"></p><blockquote><p>其实就是判断当前日志数量是否达到上限（默认是 5w）生成一次。</p></blockquote><p>具体的流程如下：<br><img src="https://s2.loli.net/2024/09/27/zgy6ZaQ7b1ceWkm.png"></p><ul><li>判断当前是否需要将日志生成 image</li><li>加载当前 image 里的元数据到内存</li><li>从 bdb 中读取最新的 Journal，然后进行重放（replay）：其实就是更新刚才加载到内存中的元数据。</li><li>基于内存中的元数据重新生成一份 image 文件</li><li>删除历史的 image 文件</li><li>将生成的 image 文件名称通知 FE 的 follower 节点，让他们下载到本地，从而可以实现 image 同步。</li></ul><p><img src="https://s2.loli.net/2024/09/27/Hd1NRzgfSy2xECW.png"><br><img src="https://s2.loli.net/2024/09/27/QiTHLpOfJ19oAam.png"></p><blockquote><p>通知 follower 下载 image。</p></blockquote><h2 id="元数据同步流程"><a href="#元数据同步流程" class="headerlink" title="元数据同步流程"></a>元数据同步流程</h2><p>完整的流程图如下图：<br><img src="https://i.imgur.com/txqTt0U.png"></p><p>在这个流程图有一个关键 <code>loadImage</code> 流程：<br><img src="https://s2.loli.net/2024/09/27/MoWjm8SKsgx2GXh.png"></p><p>他会读取 image 这个文件里的数据，然后反序列化后加载到内存里，主要就是恢复数据库和表。</p><p>还会对每个表调用一次 <code>onReload()</code> 函数，而这个函数会只 MV(<code>MATERIALIZED VIEWS</code>) 生效。</p><p>这个函数正好就是在文初提到的这个函数 <code>com.starrocks.catalog.MaterializedView#onReloadImpl</code>：<br><img src="https://s2.loli.net/2024/09/26/2T4sGfw1YC63EuP.png"></p><p>从他的实现来看就是判断视图所依赖的基表是否存在，如果有一个不存在就会将当前基表置为 inactive。</p><p>如果碰到视图的基表也是视图，那就递归再 reload 一次。</p><h2 id="复现问题"><a href="#复现问题" class="headerlink" title="复现问题"></a>复现问题</h2><p>既然知晓了这个加载流程，再结合源码应该不难看出这里的问题所在了。</p><p><img src="https://s2.loli.net/2024/09/27/MoWjm8SKsgx2GXh.png"><br>从这里的加载数据库可以看出端倪，如果我的视图和基表不在同一个数据库里，此时先加载视图是不是就会出现问题？</p><p>加载视图的时候会判断基表是否存在，而此时基表所在的数据库还没加载到内存里，自然就会查询不到从而出现那个日志。</p><p>我之前一直在本地模拟，因为都是在同一个数据库里的基表和视图，所以一直不能复现。</p><p>只要将基表和视图分开在不同的数据库中，让视图先于数据库前加载就会触发这个日志。</p><h1 id="修复问题"><a href="#修复问题" class="headerlink" title="修复问题"></a>修复问题</h1><p>要修复这个问题也很简单，只要等到所有的数据库都表都加载完毕后再去 reload 物化视图就可以了。</p><p>当我回到 main 分支准备着手修改时，发现这个问题已经被修复了：<br><a href="https://github.com/StarRocks/starrocks/pull/51002">https://github.com/StarRocks/starrocks/pull/51002</a></p><p><img src="https://s2.loli.net/2024/09/27/pzWPnoF2MIji9Kw.png"></p><p>修复过程也很简单，就是 reload 时跳过了 MV，等到所有的数据都加载完之后会在 <code>com.starrocks.server.GlobalStateMgr#postLoadImage</code> 手动加载 <code>MV</code>。</p><p><img src="https://s2.loli.net/2024/09/27/7JCLyU6umlRnqvE.png"></p><p>这个 PR 修复的问题也是我一开始提到的，会打印许多令人误解的日志。</p><p>到这里就可以解释文章开头的那个问题了：打印的这个 base-table 被删除的日志对业务来说没有影响，只是一个 bug 导致出现了这个日志。</p><p>额外提一句，这个日志也比较迷，没有打印数据库名称，如果有数据库名称的话可能会更快定位到这个问题。</p><p>参考文章：</p><ul><li><a href="https://xie.infoq.cn/article/6f2f9f56916f0eb2fdb6b001a">https://xie.infoq.cn/article/6f2f9f56916f0eb2fdb6b001a</a></li><li><a href="https://github.com/StarRocks/starrocks/pull/51002">https://github.com/StarRocks/starrocks/pull/51002</a></li></ul>]]></content>
    
    
    <summary type="html">&lt;h1 id=&quot;背景&quot;&gt;&lt;a href=&quot;#背景&quot; class=&quot;headerlink&quot; title=&quot;背景&quot;&gt;&lt;/a&gt;背景&lt;/h1&gt;&lt;p&gt;最近在排查 &lt;code&gt;starrocks&lt;/code&gt; 线上的一个告警日志：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://s2.loli.net/2024/09/26/QtMIBdmL7OciVJa.png&quot;&gt;&lt;/p&gt;
&lt;p&gt;每隔一段时间都会打印 &lt;code&gt;base-table&lt;/code&gt; 也就是物化视图的基表被删除了，但其实表还在，也没人去删除；我们就怀疑是否真的表被删除了（可能是 bug）。&lt;/p&gt;
&lt;p&gt;与此同时还有物化视图 inactive 的日志，也怀疑如果视图是 inactive 之后会导致业务使用有问题。&lt;/p&gt;
&lt;p&gt;为了确认这个日志是否对使用影响，就得需要搞清楚它出现的原因；于是我就着手从日志打印的地方开始排查。&lt;/p&gt;</summary>
    
    
    
    <category term="StarRocks" scheme="http://crossoverjie.top/categories/StarRocks/"/>
    
    
    <category term="StarRocks" scheme="http://crossoverjie.top/tags/StarRocks/"/>
    
  </entry>
  
  <entry>
    <title>时隔五年 9K star 的 IM 项目发布 v2.0.0 了</title>
    <link href="http://crossoverjie.top/2024/11/04/ob/cim-2.0.0/"/>
    <id>http://crossoverjie.top/2024/11/04/ob/cim-2.0.0/</id>
    <published>2024-11-04T03:11:48.000Z</published>
    <updated>2024-11-04T10:28:18.438Z</updated>
    
    <content type="html"><![CDATA[<p>最近业余时间花了小三个月重构了 <a href="https://github.com/crossoverJie/cim">cim</a>，也将版本和升级到了 <a href="https://github.com/crossoverJie/cim/releases/tag/v2.0.0">v2.0.0</a>，合并了十几个 PR 同时也新增了几位开发者。</p><p><img src="https://s2.loli.net/2024/10/12/yKzedUZ8DQlVwTC.png" alt="image.png"></p><blockquote><p>其中有两位也是咱们星球里的小伙伴🎉</p></blockquote><span id="more"></span><h1 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h1><p>上次发版还是在五年前了：<br><img src="https://s2.loli.net/2024/10/12/WCP1Vn62SeBNAmZ.png"></p><p>因为确实已经很久没有更新了，在开始之前还是先介绍 <a href="https://github.com/crossoverJie/cim/">cim</a> 是什么。</p><p>这里有一张简单的使用图片：<br><img src="https://s2.loli.net/2024/10/14/pBvDML4HVgyYZxS.gif" alt="Oct-14-2024 11-09-54-min.gif"><br>同时以前也有录过相关的视频：</p><p>通过 <a href="https://github.com/crossoverJie/cim">cim</a> 这个名字和视频可以看出，它具备 IM 即时通讯的基本功能，同时基于它可以实现：</p><ul><li>即时通讯</li><li>消息推送</li><li>IOT 消息平台</li></ul><p>现在要在本地运行简单许多了，前提是有 docker 就可以了。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">docker run --<span class="built_in">rm</span> --name zookeeper -d -p 2181:2181 zookeeper:3.9.2</span><br><span class="line">docker run --<span class="built_in">rm</span> --name redis -d -p 6379:6379 redis:7.4.0</span><br><span class="line"></span><br><span class="line">git <span class="built_in">clone</span> https://github.com/crossoverJie/cim.git</span><br><span class="line"><span class="built_in">cd</span> cim</span><br><span class="line">mvn clean package -DskipTests=<span class="literal">true</span></span><br><span class="line"><span class="built_in">cd</span> cim-server &amp;&amp; cim-client &amp;&amp; cim-forward-route</span><br><span class="line">mvn clean package spring-boot:repackage -DskipTests=<span class="literal">true</span></span><br></pre></td></tr></table></figure><h2 id="架构"><a href="#架构" class="headerlink" title="架构"></a>架构</h2><p><a href="https://github.com/crossoverJie/cim">cim</a> 的架构图如下：<br><img src="https://s2.loli.net/2024/10/13/O7wVi8QYr3lMFJo.png"><br>主要分为三个部分：</p><ul><li>Client 基本交互功能<ul><li>消息收发</li><li>消息查询</li><li>延迟消息</li></ul></li><li>Route 提供了消息路由以及相关的管理功能<ul><li>API 转发</li><li>消息推送</li><li>会话管理</li><li>可观测性</li></ul></li><li>Server 主要就提供长链接能力，以及真正的消息推送</li></ul><p>同时还有元数据中心（支持扩展实现）、消息存储等组件；</p><p>不管是客户端、route、server 都是支持集群：</p><ul><li>route 由于是无状态，可以任意扩展</li><li>server 通过注册中心也支持集群部署，当发生宕机或者是扩容时，客户端会通过心跳和重连机制保证可用性。</li></ul><p>所以整个架构不存在<strong>单点</strong>，同时比较简单清晰的，大部分组件都支持可扩展。</p><h2 id="流程"><a href="#流程" class="headerlink" title="流程"></a>流程</h2><p><img src="https://s2.loli.net/2024/10/13/8teMn7BSa5VWuvi.png"></p><p>为了更方便理解，花了一个流程图。</p><ul><li>server 在启动之后会先在元数据中心注册</li><li>同时 route 会订阅元数据中的 server 信息</li><li>客户端登陆时会调用 route 获取一个 server 的节点信息</li><li>然后发起登陆请求。<ul><li>成功之后会保持长链接。</li></ul></li><li>客户端向发送消息时会调用 route 接口来发起消息<ul><li>route 根据长链接关系选择 server 进行消息推送</li></ul></li></ul><h2 id="v2-0-0"><a href="#v2-0-0" class="headerlink" title="v2.0.0"></a>v2.0.0</h2><p>接下来介绍下本次 <a href="https://github.com/crossoverJie/cim/releases/tag/v2.0.0">v2.0.0</a> 有哪些重大变更，毕竟是修改了大的版本号。</p><p>这里列举一些重大的改动：<br><img src="https://s2.loli.net/2024/10/12/mRGDV6hBCTAblcI.png" alt="image.png"></p><ul><li>首先是支持了元数据中心，解耦了 zookeeper，也支持自定义实现。</li><li>支持了集成测试，可以保证提交的 PR 对现有功能的影响降到最低，代码质量有一定保证；review 代码时更加放心。</li><li>单独抽离了 <code>client-sdk</code>，代码耦合性更好且更易维护。</li><li>服务之间调用的 RPC 完成了重构<ul><li>支持了动态 URL</li><li>泛型数据解析</li></ul></li><li>还有社区小伙伴贡献的一些 bug 修复、<code>RpcProxyManager</code> 的 IOC 支持等特性。</li></ul><h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>更多的部署和使用可以参考项目首页的 README，有详细的介绍。</p><p><a href="https://github.com/crossoverJie/cim">cim</a> 目前还需要优化的地方非常多；接下来的重点是实现 ACK，同时会完善一下通讯协议。<br><img src="https://s2.loli.net/2024/10/14/l7RIZfYOsmM1N3P.png" alt="image.png"></p><p>todo 列表我也添加了很多，所以非常推荐感兴趣的朋友可以先看看 todo 列表，说不定就有你感兴趣的可以参与一下。</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;最近业余时间花了小三个月重构了 &lt;a href=&quot;https://github.com/crossoverJie/cim&quot;&gt;cim&lt;/a&gt;，也将版本和升级到了 &lt;a href=&quot;https://github.com/crossoverJie/cim/releases/tag/v2.0.0&quot;&gt;v2.0.0&lt;/a&gt;，合并了十几个 PR 同时也新增了几位开发者。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://s2.loli.net/2024/10/12/yKzedUZ8DQlVwTC.png&quot; alt=&quot;image.png&quot;&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;其中有两位也是咱们星球里的小伙伴🎉&lt;/p&gt;
&lt;/blockquote&gt;</summary>
    
    
    
    <category term="IM" scheme="http://crossoverjie.top/categories/IM/"/>
    
    
    <category term="IM" scheme="http://crossoverjie.top/tags/IM/"/>
    
  </entry>
  
  <entry>
    <title>💢线上高延迟请求排查</title>
    <link href="http://crossoverjie.top/2024/10/29/ob/%F0%9F%92%A2%E7%BA%BF%E4%B8%8A%E9%AB%98%E5%BB%B6%E8%BF%9F%E8%AF%B7%E6%B1%82%E6%8E%92%E6%9F%A5/"/>
    <id>http://crossoverjie.top/2024/10/29/ob/%F0%9F%92%A2%E7%BA%BF%E4%B8%8A%E9%AB%98%E5%BB%B6%E8%BF%9F%E8%AF%B7%E6%B1%82%E6%8E%92%E6%9F%A5/</id>
    <published>2024-10-29T10:21:42.000Z</published>
    <updated>2024-10-28T10:29:17.642Z</updated>
    
    <content type="html"><![CDATA[<p>前几天排查了一个业务接口执行高延迟的问题，也挺有参考意义的，分享一下排查过程。</p><p>现象是业务反馈有一个接口业务逻辑其实很简单，但是调用一次耗时，如下图所示：<br><img src="https://s2.loli.net/2024/10/16/Am9VkNZ5Ep4Uj6G.png"></p><span id="more"></span><h1 id="排查应用运行状态"><a href="#排查应用运行状态" class="headerlink" title="排查应用运行状态"></a>排查应用运行状态</h1><p>首先第一步需要查看当时的应用运行状态，包含当时的日志、JVM 的各种监控等。</p><p>因为我们接入了 <code>OpenTelemetry</code>，所以 <code>trace</code> 和日志是可以关联起来的。</p><blockquote><p>点击链路系统旁边的日志按钮可以直接跳转。</p></blockquote><p>可以通过 <code>trace_id</code> 查询到相关日志：<br><img src="https://s2.loli.net/2024/10/16/W5ow6KpdCaOk2f7.png"></p><p>通过日志可以看出耗时大约在 4s 多一点，然后结合代码发现这两段日志分别是在进入一个核心业务方法之前和方法内打印的。</p><p><img src="https://s2.loli.net/2024/10/16/XeqoaGPx8kEmSrD.png"></p><p>而第一行日志是在一个自定义限流器中打印的，这个限流器是使用 <code>Guava</code> 的 <code>RateLimiter</code>实现的。</p><p>我的第一反应是不是这个限流器当时限流了，从而导致阻塞了；但查看了当时的 QPS 发现完全低于限流器的配置，所以基本可以排除它的嫌疑了。</p><h2 id="JVM-监控"><a href="#JVM-监控" class="headerlink" title="JVM 监控"></a>JVM 监控</h2><p><img src="https://s2.loli.net/2024/10/16/f3H6VBFRpCN7Yza.png"></p><p><img src="https://s2.loli.net/2024/10/16/zvKPyXuScQwmiYN.png"></p><p>之后我们查询当时的 JVM 监控发现当时的 GC  频繁，而堆内存也正好发生了一次回收，初步判断是 GC 导致的本次问题。</p><p>但为啥会导致频繁的 GC 呢，还需要继续排查。</p><h2 id="内存排查"><a href="#内存排查" class="headerlink" title="内存排查"></a>内存排查</h2><p>我们在应用诊断中集成了 <a href="https://github.com/grafana/pyroscope">Pyroscope</a>的持续剖析，可以实时查看内存的占用情况。<br><img src="https://s2.loli.net/2024/10/16/Ow5WksxJan9G8py.png"></p><p><img src="https://s2.loli.net/2024/10/16/CbPhVJ4mDyFxicX.png" alt="image.png"></p><p>通过内存分析发现有大量的 JSON 序列化占用了大量的内存，同时还发现 Pod 已经被重启好几次了：<br><img src="https://s2.loli.net/2024/10/16/iKHCFodeVPM9A68.png" alt="image.png"></p><p><img src="https://s2.loli.net/2024/10/16/31aTS7yqNCKlFJQ.png" alt="image.png"></p><p>查看原因发现是 Pod OOM 导致的。</p><p>因此非常有可能是 GC 导致的，恰好那段时间发生了 GC 内存也有明显变化。</p><p><img src="https://s2.loli.net/2024/10/16/f3H6VBFRpCN7Yza.png"></p><p><img src="https://s2.loli.net/2024/10/16/zvKPyXuScQwmiYN.png"></p><p><img src="https://s2.loli.net/2024/10/16/hsXUAZCIGY12gFk.png"></p><p>最后再通过 arthas 确认了 GC 非常频繁，可以确认目前的资源是是非常紧张的，咨询业务之后得知该应用本身占用的资源就比较大，没有太多优化空间，所以最终决定还是加配置。<br><img src="https://s2.loli.net/2024/10/16/VGyrCAZgjx64wHP.png"><br><img src="https://s2.loli.net/2024/10/17/zIEjeMxvkgLomZ4.png" alt="image.png"><br>还是提高硬件效率最高，目前运行半个月之后 Pod 内存表现稳定，没有出现一次 OOM 的异常。</p><h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>虽然最后的处理的方式是简单粗暴的，但其中的过程还是有意义的，遇到不同的情况也有不同的处理方式。</p><p>比如在排查过程中发现内存消耗异常，通过内存分析发现代码可以优化，那就优化代码逻辑。</p><p>如果是堆内存占用不大，但是 Pod 还是 OOM 导致重启，那就要看看 JVM 的内存分配是否合理，应该多预留一些内存给堆外使用。</p><p>但这个过程需要有<strong>完善的可观测系统的</strong>支撑，比如日志、监控等，如果没有这些数据，再回头排查问题就会比较困难。</p><p>总之这个排查过程才是最主要的，大家还有什么排查问题的小 tips 也欢迎在评论区分享。</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;前几天排查了一个业务接口执行高延迟的问题，也挺有参考意义的，分享一下排查过程。&lt;/p&gt;
&lt;p&gt;现象是业务反馈有一个接口业务逻辑其实很简单，但是调用一次耗时，如下图所示：&lt;br&gt;&lt;img src=&quot;https://s2.loli.net/2024/10/16/Am9VkNZ5Ep4Uj6G.png&quot;&gt;&lt;/p&gt;</summary>
    
    
    
    <category term="问题排查" scheme="http://crossoverjie.top/categories/%E9%97%AE%E9%A2%98%E6%8E%92%E6%9F%A5/"/>
    
    
    <category term="Java" scheme="http://crossoverjie.top/tags/Java/"/>
    
  </entry>
  
  <entry>
    <title>IM系统重构到 SDK 设计的最佳实践</title>
    <link href="http://crossoverjie.top/2024/10/13/ob/cim-client-sdk/"/>
    <id>http://crossoverjie.top/2024/10/13/ob/cim-client-sdk/</id>
    <published>2024-10-13T14:04:45.000Z</published>
    <updated>2024-10-13T06:00:43.572Z</updated>
    
    <content type="html"><![CDATA[<p><img src="https://s2.loli.net/2024/10/13/PW1J2bXx39cfpnC.png"></p><h1 id="SDK-设计"><a href="#SDK-设计" class="headerlink" title="SDK 设计"></a>SDK 设计</h1><p><img src="https://s2.loli.net/2024/09/17/Ck6AfdGOPISDrVN.png"></p><p>在之前提到了 <a href="https://github.com/crossoverJie/cim">cim</a> 在做集成测试的时候遇到的问题，需要提供一个 SDK 来解决，于是我花了一些时间编写了 SDK，同时也将 cim-client 重构了。</p><span id="more"></span><p>重构后的代码长这个样子：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Bean</span></span><br><span class="line"><span class="keyword">public</span> Client <span class="title function_">buildClient</span><span class="params">(<span class="meta">@Qualifier(&quot;callBackThreadPool&quot;)</span> ThreadPoolExecutor callbackThreadPool,</span></span><br><span class="line"><span class="params">                          Event event)</span> &#123;</span><br><span class="line">    <span class="type">OkHttpClient</span> <span class="variable">okHttpClient</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">OkHttpClient</span>.Builder().connectTimeout(<span class="number">3</span>, TimeUnit.SECONDS)</span><br><span class="line">            .readTimeout(<span class="number">3</span>, TimeUnit.SECONDS)</span><br><span class="line">            .writeTimeout(<span class="number">3</span>, TimeUnit.SECONDS)</span><br><span class="line">            .retryOnConnectionFailure(<span class="literal">true</span>).build();</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> Client.builder()</span><br><span class="line">            .auth(ClientConfigurationData.Auth.builder()</span><br><span class="line">                    .userName(appConfiguration.getUserName())</span><br><span class="line">                    .userId(appConfiguration.getUserId())</span><br><span class="line">                    .build())</span><br><span class="line">            .routeUrl(appConfiguration.getRouteUrl())</span><br><span class="line">            .loginRetryCount(appConfiguration.getReconnectCount())</span><br><span class="line">            .event(event)</span><br><span class="line">            .reconnectCheck(client -&gt; !shutDownSign.checkStatus())</span><br><span class="line">            .okHttpClient(okHttpClient)</span><br><span class="line">            .messageListener(<span class="keyword">new</span> <span class="title class_">MsgCallBackListener</span>(msgLogger))</span><br><span class="line">            .callbackThreadPool(callbackThreadPool)</span><br><span class="line">            .build();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>配合 <code>springboot</code> 使用时只需要创建一个 <code>Client</code> 即可，这个 <code>Client</code> 里维护了核心的：</p><ul><li>长链接创建、状态维护</li><li>心跳检测</li><li>超时、网络异常重连等</li></ul><p>同时也提供了简易的 API 可以直接收发消息：<br><img src="https://s2.loli.net/2024/09/17/2tCXEo9nLvIrNTf.png"></p><p>这样在集成到业务代码中时会更方便。</p><p>以前的代码耦合度非常高，同时因为基础代码是 18 年写的，现在真的没有眼看了；</p><p>重构的过程中使用一些 Java8+ 的一些语法糖精简了许多代码，各个模块间的组织关系也重新梳理，现在会更易维护了。</p><p>比如由于创建客户端需要许多可选参数，于是就提供了 Builder 模式的创建选项：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">interface</span> <span class="title class_">ClientBuilder</span> &#123;  </span><br><span class="line">  </span><br><span class="line">    Client <span class="title function_">build</span><span class="params">()</span>;  </span><br><span class="line">    ClientBuilder <span class="title function_">auth</span><span class="params">(ClientConfigurationData.Auth auth)</span>;  </span><br><span class="line">    ClientBuilder <span class="title function_">routeUrl</span><span class="params">(String routeUrl)</span>;  </span><br><span class="line">    ClientBuilder <span class="title function_">loginRetryCount</span><span class="params">(<span class="type">int</span> loginRetryCount)</span>;  </span><br><span class="line">    ClientBuilder <span class="title function_">event</span><span class="params">(Event event)</span>;  </span><br><span class="line">    ClientBuilder <span class="title function_">reconnectCheck</span><span class="params">(ReconnectCheck reconnectCheck)</span>;  </span><br><span class="line">    ClientBuilder <span class="title function_">okHttpClient</span><span class="params">(OkHttpClient okHttpClient)</span>;  </span><br><span class="line">    ClientBuilder <span class="title function_">messageListener</span><span class="params">(MessageListener messageListener)</span>;  </span><br><span class="line">    ClientBuilder <span class="title function_">callbackThreadPool</span><span class="params">(ThreadPoolExecutor callbackThreadPool)</span>;  </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><blockquote><p>以上部分 API 的设计借鉴了 Pulsar。</p></blockquote><h1 id="Proxy-优化"><a href="#Proxy-优化" class="headerlink" title="Proxy 优化"></a>Proxy 优化</h1><p>除此之外还优化了请求代理，这个 Proxy 主要是用于方便在各个服务中发起 rest 调用，我这里为了轻量也没有使用 Dubbo、SpringCloud 这类服务框架。</p><p>但如果都硬编码 http client 去请求时会有许多重复冗余的代码，比如创建连接、请求参数、响应解析、异常处理等。</p><p>于是在之前的版本中就提供了一个 <code>ProxyManager</code> 的基本实现：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Override</span>  </span><br><span class="line"><span class="keyword">public</span> List&lt;OnlineUsersResVO.DataBodyBean&gt; onlineUsers() <span class="keyword">throws</span> Exception&#123;  </span><br><span class="line">    <span class="type">RouteApi</span> <span class="variable">routeApi</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">ProxyManager</span>&lt;&gt;(RouteApi.class, routeUrl, okHttpClient).getInstance();  </span><br><span class="line">  </span><br><span class="line">    <span class="type">Response</span> <span class="variable">response</span> <span class="operator">=</span> <span class="literal">null</span>;  </span><br><span class="line">    <span class="type">OnlineUsersResVO</span> <span class="variable">onlineUsersResVO</span> <span class="operator">=</span> <span class="literal">null</span>;  </span><br><span class="line">    <span class="keyword">try</span> &#123;  </span><br><span class="line">        response = (Response) routeApi.onlineUser();  </span><br><span class="line">        <span class="type">String</span> <span class="variable">json</span> <span class="operator">=</span> response.body().string() ;  </span><br><span class="line">        onlineUsersResVO = JSON.parseObject(json, OnlineUsersResVO.class);  </span><br><span class="line">  </span><br><span class="line">    &#125;<span class="keyword">catch</span> (Exception e)&#123;  </span><br><span class="line">        log.error(<span class="string">&quot;exception&quot;</span>,e);  </span><br><span class="line">    &#125;<span class="keyword">finally</span> &#123;  </span><br><span class="line">        response.body().close();  </span><br><span class="line">    &#125;  </span><br><span class="line">    <span class="keyword">return</span> onlineUsersResVO.getDataBody();  </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>虽然提供了一些连接管理和参数封装等基础功能，但只实现了一半。</p><p>从上面的代码也可以看出序列化都得自己实现，这些代码完全是冗余的。</p><p>经过重构后以上的代码可以精简到如下：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 声明接口</span></span><br><span class="line"><span class="meta">@Request(method = Request.GET)</span>  </span><br><span class="line">BaseResponse&lt;Set&lt;CIMUserInfo&gt;&gt; <span class="title function_">onlineUser</span><span class="params">()</span> <span class="keyword">throws</span> Exception;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 初始化</span></span><br><span class="line">routeApi = RpcProxyManager.create(RouteApi.class, routeUrl, okHttpClient);</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> Set&lt;CIMUserInfo&gt; <span class="title function_">onlineUser</span><span class="params">()</span> <span class="keyword">throws</span> Exception &#123;  </span><br><span class="line">    BaseResponse&lt;Set&lt;CIMUserInfo&gt;&gt; onlineUsersResVO = routeApi.onlineUser();  </span><br><span class="line">    <span class="keyword">return</span> onlineUsersResVO.getDataBody();  </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这个调整之后就非常类似于 Dubbo gRPC 这类 RPC 框架的使用，只需要把接口定义好，就和调用本地函数一样的简单。</p><p>为了方便后续可能调用一些外部系统，在此基础上还支持了指定多种请求 method、指定 URL 、返回结果嵌套泛型等。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Request(url = &quot;sample-request?author=beeceptor&quot;)</span>  </span><br><span class="line">EchoGeneric&lt;EchoResponse.HeadersDTO&gt; echoGeneric(EchoRequest message);</span><br><span class="line"></span><br><span class="line"><span class="meta">@Test</span>  </span><br><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">testGeneric</span><span class="params">()</span> &#123;  </span><br><span class="line">    <span class="type">OkHttpClient</span> <span class="variable">client</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">OkHttpClient</span>();  </span><br><span class="line">    <span class="type">String</span> <span class="variable">url</span> <span class="operator">=</span> <span class="string">&quot;http://echo.free.beeceptor.com&quot;</span>;  </span><br><span class="line">    <span class="type">Echo</span> <span class="variable">echo</span> <span class="operator">=</span> RpcProxyManager.create(Echo.class, url, client);  </span><br><span class="line">    <span class="type">EchoRequest</span> <span class="variable">request</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">EchoRequest</span>();  </span><br><span class="line">    request.setName(<span class="string">&quot;crossoverJie&quot;</span>);  </span><br><span class="line">    request.setAge(<span class="number">18</span>);  </span><br><span class="line">    request.setCity(<span class="string">&quot;shenzhen&quot;</span>);  </span><br><span class="line">    <span class="comment">// 支持泛型解析</span></span><br><span class="line">    EchoGeneric&lt;EchoResponse.HeadersDTO&gt; response = echo.echoGeneric(request);  </span><br><span class="line">    Assertions.assertEquals(response.getHeaders().getHost(), <span class="string">&quot;echo.free.beeceptor.com&quot;</span>);  </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="支持动态-URL-调用"><a href="#支持动态-URL-调用" class="headerlink" title="支持动态 URL 调用"></a>支持动态 URL 调用</h2><p><img src="https://s2.loli.net/2024/09/19/v8NgprfJ5PWAsER.png"></p><p>还有一个 todo：希望可以将 <code>ProxyManager</code> 交给 <code>Spring</code> 去管理，之前是在每次调用的地方都会创建一个 Proxy 对象，完全没有必要，代码也很冗余。</p><p>但有网友在实现过程中发现，有个场景的请求地址是动态的，如果是交给 Spring 管理为单例后是没法修改 URL 地址的，因为这个地址是在创建对象的时候初始化的。</p><p>所以我就在这里新增了一个动态 URL 的特性：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">EchoResponse <span class="title function_">echoTarget</span><span class="params">(EchoRequest message, <span class="meta">@DynamicUrl(useMethodEndpoint = false)</span> String url)</span>;</span><br><span class="line"></span><br><span class="line"><span class="type">Echo</span> <span class="variable">echo</span> <span class="operator">=</span> RpcProxyManager.create(Echo.class, client);</span><br><span class="line"><span class="type">String</span> <span class="variable">url</span> <span class="operator">=</span> <span class="string">&quot;http://echo.free.beeceptor.com/sample-request?author=beeceptor&quot;</span>;</span><br><span class="line"><span class="type">EchoResponse</span> <span class="variable">response</span> <span class="operator">=</span> echo.echoTarget(request, url);</span><br></pre></td></tr></table></figure><p>在声明接口的时候使用 <code>@DynamicUrl</code> 的方法参数注解，告诉代理这个参数是 URL。<br>这样就可以允许在创建  <code>Proxy</code> 对象的时候不指定 URL，而是在实际调用时候再传入具体的 URL，更方便创建单例了。</p><h1 id="集成测试优化"><a href="#集成测试优化" class="headerlink" title="集成测试优化"></a>集成测试优化</h1><p>同时还优化了集成测试，支持了 server 的集群版测试。</p><p><a href="https://github.com/crossoverJie/cim/blob/4c149f8bda78718e3ecae2c5759aa9732eff9132/cim-client-sdk/src/test/java/com/crossoverjie/cim/client/sdk/ClientTest.java#L210">https://github.com/crossoverJie/cim/blob/4c149f8bda78718e3ecae2c5759aa9732eff9132/cim-client-sdk/src/test/java/com/crossoverjie/cim/client/sdk/ClientTest.java#L210</a></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Test</span>  </span><br><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">testReconnect</span><span class="params">()</span> <span class="keyword">throws</span> Exception &#123;  </span><br><span class="line">    <span class="built_in">super</span>.startTwoServer();  </span><br><span class="line">    <span class="built_in">super</span>.startRoute();  </span><br><span class="line">  </span><br><span class="line">    <span class="type">String</span> <span class="variable">routeUrl</span> <span class="operator">=</span> <span class="string">&quot;http://localhost:8083&quot;</span>;  </span><br><span class="line">    <span class="type">String</span> <span class="variable">cj</span> <span class="operator">=</span> <span class="string">&quot;cj&quot;</span>;  </span><br><span class="line">    <span class="type">String</span> <span class="variable">zs</span> <span class="operator">=</span> <span class="string">&quot;zs&quot;</span>;  </span><br><span class="line">    <span class="type">Long</span> <span class="variable">cjId</span> <span class="operator">=</span> <span class="built_in">super</span>.registerAccount(cj);  </span><br><span class="line">    <span class="type">Long</span> <span class="variable">zsId</span> <span class="operator">=</span> <span class="built_in">super</span>.registerAccount(zs);  </span><br><span class="line">    <span class="type">var</span> <span class="variable">auth1</span> <span class="operator">=</span> ClientConfigurationData.Auth.builder()  </span><br><span class="line">            .userName(cj)  </span><br><span class="line">            .userId(cjId)  </span><br><span class="line">            .build();  </span><br><span class="line">    <span class="type">var</span> <span class="variable">auth2</span> <span class="operator">=</span> ClientConfigurationData.Auth.builder()  </span><br><span class="line">            .userName(zs)  </span><br><span class="line">            .userId(zsId)  </span><br><span class="line">            .build();  </span><br><span class="line">  </span><br><span class="line">    <span class="meta">@Cleanup</span>  </span><br><span class="line">    <span class="type">Client</span> <span class="variable">client1</span> <span class="operator">=</span> Client.builder()  </span><br><span class="line">            .auth(auth1)  </span><br><span class="line">            .routeUrl(routeUrl)  </span><br><span class="line">            .build();  </span><br><span class="line">    TimeUnit.SECONDS.sleep(<span class="number">3</span>);  </span><br><span class="line">    ClientState.<span class="type">State</span> <span class="variable">state</span> <span class="operator">=</span> client1.getState();  </span><br><span class="line">    Awaitility.await().atMost(<span class="number">10</span>, TimeUnit.SECONDS)  </span><br><span class="line">            .untilAsserted(() -&gt; Assertions.assertEquals(ClientState.State.Ready, state));  </span><br><span class="line">  </span><br><span class="line">  </span><br><span class="line">    AtomicReference&lt;String&gt; client2Receive = <span class="keyword">new</span> <span class="title class_">AtomicReference</span>&lt;&gt;();  </span><br><span class="line">    <span class="meta">@Cleanup</span>  </span><br><span class="line">    <span class="type">Client</span> <span class="variable">client2</span> <span class="operator">=</span> Client.builder()  </span><br><span class="line">            .auth(auth2)  </span><br><span class="line">            .routeUrl(routeUrl)  </span><br><span class="line">            .messageListener((client, message) -&gt; client2Receive.set(message))  </span><br><span class="line">            .build();  </span><br><span class="line">    TimeUnit.SECONDS.sleep(<span class="number">3</span>);  </span><br><span class="line">    ClientState.<span class="type">State</span> <span class="variable">state2</span> <span class="operator">=</span> client2.getState();  </span><br><span class="line">    Awaitility.await().atMost(<span class="number">10</span>, TimeUnit.SECONDS)  </span><br><span class="line">            .untilAsserted(() -&gt; Assertions.assertEquals(ClientState.State.Ready, state2));  </span><br><span class="line">  </span><br><span class="line">    Optional&lt;CIMServerResVO&gt; serverInfo2 = client2.getServerInfo();  </span><br><span class="line">    Assertions.assertTrue(serverInfo2.isPresent());  </span><br><span class="line">    System.out.println(<span class="string">&quot;client2 serverInfo = &quot;</span> + serverInfo2.get());  </span><br><span class="line">  </span><br><span class="line">    <span class="comment">// send msg  </span></span><br><span class="line">    <span class="type">String</span> <span class="variable">msg</span> <span class="operator">=</span> <span class="string">&quot;hello&quot;</span>;  </span><br><span class="line">    client1.sendGroup(msg);  </span><br><span class="line">    Awaitility.await()  </span><br><span class="line">            .untilAsserted(() -&gt; Assertions.assertEquals(String.format(<span class="string">&quot;cj:%s&quot;</span>, msg), client2Receive.get()));  </span><br><span class="line">    client2Receive.set(<span class="string">&quot;&quot;</span>);  </span><br><span class="line">  </span><br><span class="line">  </span><br><span class="line">    System.out.println(<span class="string">&quot;ready to restart server&quot;</span>);  </span><br><span class="line">    TimeUnit.SECONDS.sleep(<span class="number">3</span>);  </span><br><span class="line">    Optional&lt;CIMServerResVO&gt; serverInfo = client1.getServerInfo();  </span><br><span class="line">    Assertions.assertTrue(serverInfo.isPresent());  </span><br><span class="line">    System.out.println(<span class="string">&quot;server info = &quot;</span> + serverInfo.get());  </span><br><span class="line">  </span><br><span class="line">    <span class="built_in">super</span>.stopServer(serverInfo.get().getCimServerPort());  </span><br><span class="line">    System.out.println(<span class="string">&quot;stop server success! &quot;</span> + serverInfo.get());  </span><br><span class="line">  </span><br><span class="line">  </span><br><span class="line">    <span class="comment">// Waiting server stopped, and client reconnect.  </span></span><br><span class="line">    TimeUnit.SECONDS.sleep(<span class="number">30</span>);  </span><br><span class="line">    System.out.println(<span class="string">&quot;reconnect state: &quot;</span> + client1.getState());  </span><br><span class="line">    Awaitility.await().atMost(<span class="number">15</span>, TimeUnit.SECONDS)  </span><br><span class="line">            .untilAsserted(() -&gt; Assertions.assertEquals(ClientState.State.Ready, state));  </span><br><span class="line">    serverInfo = client1.getServerInfo();  </span><br><span class="line">    Assertions.assertTrue(serverInfo.isPresent());  </span><br><span class="line">    System.out.println(<span class="string">&quot;client1 reconnect server info = &quot;</span> + serverInfo.get());  </span><br><span class="line">  </span><br><span class="line">    <span class="comment">// Send message again.  </span></span><br><span class="line">    log.info(<span class="string">&quot;send message again, client2Receive = &#123;&#125;&quot;</span>, client2Receive.get());  </span><br><span class="line">    client1.sendGroup(msg);  </span><br><span class="line">    Awaitility.await()  </span><br><span class="line">            .untilAsserted(() -&gt; Assertions.assertEquals(String.format(<span class="string">&quot;cj:%s&quot;</span>, msg), client2Receive.get()));  </span><br><span class="line">    <span class="built_in">super</span>.stopTwoServer();  </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>比如在这里编写了一个客户端重连的单测，代码有点长，但它的主要流程如下：</p><ul><li>启动两个 Server：Server1，Server2</li><li>启动 Route</li><li>在启动两个 Client 发送消息<ul><li>校验消息发送是否成功</li></ul></li><li><strong>停止 Client1 连接的 Server</strong></li><li><strong>等待 Client 自动重连到另一个 Server</strong></li><li>再次发送消息<ul><li>校验消息发送是否成功</li></ul></li></ul><p>这样就可以验证在服务端 Server 宕机后整个服务是否可用，消息收发是否正常。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">startTwoServer</span><span class="params">()</span> &#123;  </span><br><span class="line">    <span class="keyword">if</span> (!zooKeeperContainer.isRunning())&#123;  </span><br><span class="line">        zooKeeperContainer.start();  </span><br><span class="line">    &#125;    zookeeperAddr = String.format(<span class="string">&quot;%s:%d&quot;</span>, zooKeeperContainer.getHost(), zooKeeperContainer.getMappedPort(ZooKeeperContainer.DEFAULT_CLIENT_PORT));  </span><br><span class="line">    <span class="type">SpringApplication</span> <span class="variable">server</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">SpringApplication</span>(CIMServerApplication.class);  </span><br><span class="line">    String[] args1 = <span class="keyword">new</span> <span class="title class_">String</span>[]&#123;  </span><br><span class="line">            <span class="string">&quot;--cim.server.port=11211&quot;</span>,  </span><br><span class="line">            <span class="string">&quot;--server.port=8081&quot;</span>,  </span><br><span class="line">            <span class="string">&quot;--app.zk.addr=&quot;</span> + zookeeperAddr,  </span><br><span class="line">    &#125;;    <span class="type">ConfigurableApplicationContext</span> <span class="variable">run1</span> <span class="operator">=</span> server.run(args1);  </span><br><span class="line">    runMap.put(Integer.parseInt(<span class="string">&quot;11211&quot;</span>), run1);  </span><br><span class="line">  </span><br><span class="line">  </span><br><span class="line">    <span class="type">SpringApplication</span> <span class="variable">server2</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">SpringApplication</span>(CIMServerApplication.class);  </span><br><span class="line">    String[] args2 = <span class="keyword">new</span> <span class="title class_">String</span>[]&#123;  </span><br><span class="line">            <span class="string">&quot;--cim.server.port=11212&quot;</span>,  </span><br><span class="line">            <span class="string">&quot;--server.port=8082&quot;</span>,  </span><br><span class="line">            <span class="string">&quot;--app.zk.addr=&quot;</span> + zookeeperAddr,  </span><br><span class="line">    &#125;;    <span class="type">ConfigurableApplicationContext</span> <span class="variable">run2</span> <span class="operator">=</span> server2.run(args2);  </span><br><span class="line">    runMap.put(Integer.parseInt(<span class="string">&quot;11212&quot;</span>), run2);  </span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">stopServer</span><span class="params">(Integer port)</span> &#123;  </span><br><span class="line">    runMap.get(port).close();  </span><br><span class="line">    runMap.remove(port);  </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这里的启动两个 Server 就是创建了两个 Server 应用，然后保存好端口和应用之间的映射关系。</p><p>这样就可以根据客户端连接的 Server 信息指定停止哪一个 Server，更方便做测试。</p><p>这次重启 <a href="https://github.com/crossoverJie/cim">cim</a> 的维护后会尽量维护下去，即便更新时间慢一点。</p><p>后续还会加上消息 ack、离线消息等之前呼声很高的功能，感兴趣的完全可以一起参与。</p><p>源码地址：<br><a href="https://github.com/crossoverJie/cim">https://github.com/crossoverJie/cim</a></p>]]></content>
    
    
    <summary type="html">&lt;p&gt;&lt;img src=&quot;https://s2.loli.net/2024/10/13/PW1J2bXx39cfpnC.png&quot;&gt;&lt;/p&gt;
&lt;h1 id=&quot;SDK-设计&quot;&gt;&lt;a href=&quot;#SDK-设计&quot; class=&quot;headerlink&quot; title=&quot;SDK 设计&quot;&gt;&lt;/a&gt;SDK 设计&lt;/h1&gt;&lt;p&gt;&lt;img src=&quot;https://s2.loli.net/2024/09/17/Ck6AfdGOPISDrVN.png&quot;&gt;&lt;/p&gt;
&lt;p&gt;在之前提到了 &lt;a href=&quot;https://github.com/crossoverJie/cim&quot;&gt;cim&lt;/a&gt; 在做集成测试的时候遇到的问题，需要提供一个 SDK 来解决，于是我花了一些时间编写了 SDK，同时也将 cim-client 重构了。&lt;/p&gt;</summary>
    
    
    
    <category term="cim" scheme="http://crossoverjie.top/categories/cim/"/>
    
    
    <category term="cim" scheme="http://crossoverjie.top/tags/cim/"/>
    
  </entry>
  
  <entry>
    <title>StarRocks 开发环境搭建踩坑指北</title>
    <link href="http://crossoverjie.top/2024/10/09/ob/StarRocks-dev-env-build/"/>
    <id>http://crossoverjie.top/2024/10/09/ob/StarRocks-dev-env-build/</id>
    <published>2024-10-09T09:20:19.000Z</published>
    <updated>2024-10-08T14:21:33.221Z</updated>
    
    <content type="html"><![CDATA[<h1 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h1><p>最近这段时间在处理一个 <code>StarRocks</code> 的关于物化视图优化的一个问题，在此之前其实我也没有接触过 <code>StarRocks</code> 这类主要处理数据分析的数据库，就更别提在这上面做优化了。</p><p>在解决问题之前我先花了一两天时间熟悉了一下 <code>StarRocks</code> 的一些概念和使用方法，然后又花了一些时间搭建环境然后复现了该问题。</p><p>之后便开始阅读源码，大概知道了相关代码的执行流程，但即便是反复阅读了多次代码也没有找到具体出现问题的地方。</p><p>所以便考虑在本地 Debug 源码，最终调试半天之后知道了问题所以，也做了相关修改，给社区提交了 PR，目前还在推进过程中。</p><span id="more"></span><h1 id="环境搭建"><a href="#环境搭建" class="headerlink" title="环境搭建"></a>环境搭建</h1><p>这里比较麻烦的是如何在本地 debug 代码。<br><img src="https://s2.loli.net/2024/09/16/uqKGRIJXZB3pbMy.png"><br>根据官方的架构图会发现 <code>StarRocks</code> 主要分为两个部分：</p><ul><li>FE：也就是常说的前端部分，主要负责元数据管理和构建执行计划。</li><li>BE：后端存储部分，执行查询计划并存储数据。</li></ul><p>其中 FE 是 Java 写的，而存储的 BE 则是 C++ 写的，我这次需要修改的是 FE 前端的部分，所以本篇文章主要讨论的是 FE 相关的内容。</p><p>好在社区已经有关于如何编译和构建源码的教程，这里我列举一些重点，FE 首先需要安装以下一些工具：</p><ul><li>Thrift</li><li>Protobuf</li><li>Python3</li><li>JDK8+</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">brew install alberttwong/thrift/thrift@0.13</span><br><span class="line">$ thrift -version  </span><br><span class="line">Thrift version 0.13.0</span><br><span class="line"></span><br><span class="line">brew install protobuf</span><br></pre></td></tr></table></figure><p>以上默认是在  Mac 平台上安装的流程，所以全程使用 <code>brew</code> 最方便了，如果是其他平台也是同理，只要安装好这些工具即可。</p><p>紧接着便是编译 FE，我们需要先下载源码，然后进入 FE 的目录：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">git <span class="built_in">clone</span> https://github.com/StarRocks/starrocks.git</span><br><span class="line"><span class="built_in">cd</span> fe</span><br><span class="line">mvn install -DskipTests</span><br></pre></td></tr></table></figure><p>然后直接使用 <code>maven</code> 编译安装即可。</p><p>这里需要注意⚠️，因为编译过程中需要使用 <code>Python3</code> 来执行一些构建任务，新版本的 Mac 都是内置 <code>Python3</code> 的，但如果是老版本的 <code>Mac</code> 内置的则是 Python2。</p><p>这时就需要我们将 Python3 的命令手动在构建任务里指定一下：</p><p><img src="https://s2.loli.net/2024/09/16/ouLglsXJEm1TpSh.png"></p><p>比如我这里的 Python3  命令为 <code>python3</code></p><p>我们需要在 <code>fe/fe-core/pom.xml</code> 目录里修改下 Python 的命令名称：<br><img src="https://s2.loli.net/2024/09/16/tcfwoilyDdTQpxX.png"></p><p>修改之后再 <code>mvn install</code> 编译一次，如果一切顺利的话便会编译成功。</p><h2 id="搭建本地集群"><a href="#搭建本地集群" class="headerlink" title="搭建本地集群"></a>搭建本地集群</h2><h3 id="启动-FE"><a href="#启动-FE" class="headerlink" title="启动 FE"></a>启动 FE</h3><p>我的最终目的是可以在本地 IDEA 中启动 FE 然后再配合启动一个 BE，这样就可以在 IDEA 中调试 FE 的源码了。</p><p>在启动 FE 之前还需要创建一些目录：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cp</span> -r conf fe/conf</span><br><span class="line"><span class="built_in">cp</span> -r bin fe/bin</span><br><span class="line"><span class="built_in">cp</span> -r webroot fe/webroot</span><br><span class="line"></span><br><span class="line"><span class="built_in">cd</span> fe  </span><br><span class="line"><span class="built_in">mkdir</span> <span class="built_in">log</span>  </span><br><span class="line"><span class="built_in">mkdir</span> meta</span><br></pre></td></tr></table></figure><p>主要就是要在 FE 的目录下创建配置文件、执行脚本、日志、元数据等目录。</p><p>接着便可以打开 <code>com.starrocks.StarRocksFE</code> 类在 IDEA 中运行了，在启动之前还需要配置一下环境变量：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 修改为自己的目录</span></span><br><span class="line"><span class="built_in">export</span> PID_DIR=/Users/smith/Code/starrocks/fe/bin</span><br><span class="line"><span class="built_in">export</span> STARROCKS_HOME=/Users/smith/Code/starrocks/fe</span><br><span class="line"><span class="built_in">export</span> LOG_DIR=/Users/smith/Code/starrocks/fe/log</span><br></pre></td></tr></table></figure><p>同时需要配置下 <code>fe.conf</code> 中的 <code>priority_networks</code> 网络配置：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">priority_networks = 10.10.10.0/24</span><br></pre></td></tr></table></figure><p>这个 IP 得是<strong>宿主机的 IP</strong>，后续我们使用 docker 启动 BE 的时候也需要用到。</p><p><img src="https://s2.loli.net/2024/09/16/Lgrl4YSaD1GdzIZ.png"></p><p>如果启动失败，可以在日志目录下查看日志：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">2024-09-16 21:21:59.942+08:00 ERROR (main|1) [NodeMgr.getCheckedSelfHostPort():642] edit_log_port 9010 is already in use. will exit.</span><br></pre></td></tr></table></figure><p>碰到这个异常：提示端口被占用，那可以尝试关闭代理之后再试试。</p><p>启动成功后我们便可以使用 <code>MySQL</code> 兼容的客户端进行连接了，这里我使用的是 <code>tableplus</code>:<br><img src="https://s2.loli.net/2024/09/16/8XMI1DdjGkOKVPy.png"></p><p>然后我们使用以下 sql  可以查询 fe 的节点状态：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SHOW</span> PROC <span class="string">&#x27;/frontends&#x27;</span>;</span><br></pre></td></tr></table></figure><p><img src="https://s2.loli.net/2024/09/16/Jg5TIMtpKoknq4Z.png"></p><p>看到类似的输出则代表启动成功了。</p><h3 id="启动-BE"><a href="#启动-BE" class="headerlink" title="启动 BE"></a>启动 BE</h3><p>之后我们便可以使用 Docker 来启动 BE 了，之所以用 docker 启动，是因为 BE 是 C++ 编写的，想要在 Mac 上运行比较麻烦，最好是得有一台 <code>Ubuntu22</code> 的虚拟机。</p><p>如果我们不需要调试 BE 的话，只使用 docker 启动是再合适不过了。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker run -p 9060:9060 -p 8040:8040 -p 9050:9050 -p 8060:8060 -p 9070:9070 -itd --<span class="built_in">rm</span> --name be -e <span class="string">&quot;TZ=Asia/Shanghai&quot;</span> starrocks/be-ubuntu</span><br></pre></td></tr></table></figure><p>我们需要将 FE 需要连接 BE 的端口暴露出来，启动成功后该镜像并不会直接启动 BE，我们需要进入容器手动启动。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker <span class="built_in">exec</span> -it be bash</span><br></pre></td></tr></table></figure><p>在启动之前我们依然需要修改下 be.conf 中的 <code>priority_networks</code> 配置：</p><p><img src="https://s2.loli.net/2024/09/16/mcFCo24Kyxui8gt.png"><br>修改为和 fe.conf 中相同的配置。</p><p>之后使用以下命令启动 be:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/start_be.sh --daemon</span><br></pre></td></tr></table></figure><p>启动日志我们可以在 logs 目录中查看。</p><h3 id="绑定-FE-和-BE"><a href="#绑定-FE-和-BE" class="headerlink" title="绑定 FE 和 BE"></a>绑定 FE 和 BE</h3><p>接下来还有最后一步就是将 FE 和 BE 绑定在一起。</p><p>我们在 fe 中执行以下 sql：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">ALTER</span> <span class="keyword">SYSTEM</span> <span class="keyword">ADD</span> BACKEND &quot;127.0.0.1:9050&quot;;</span><br></pre></td></tr></table></figure><p>手动添加一个节点，之后再使用：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SHOW</span> PROC <span class="string">&#x27;/backends&#x27;</span>;</span><br></pre></td></tr></table></figure><p>可以查询到 BE 的节点状态：</p><p><img src="https://s2.loli.net/2024/09/16/YMCXQDoch3NlA1L.png"></p><p>如果出现以下结果代表连接成功，这样我们就可以创建数据库和表了。</p><h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>这部分内容（本地 FE 联结 docker 里的 FE）官方文档并没有提及，也是我踩了不少坑、同时还咨询了一些大佬才全部调试成功。</p><p>还有一点需要注意的事：如果我们网络环境发生了变化，比如从家里的 Wi-Fi 切换到了公司的，需要手动删除下 <code>FE/meta</code> 下的所有文件再次启动，BE 则是需要重启一下容器。</p><p>参考链接：</p><ul><li><a href="https://docs.starrocks.io/zh/docs/developers/development-environment/IDEA/">https://docs.starrocks.io/zh/docs/developers/development-environment/IDEA/</a></li><li><a href="https://docs.starrocks.io/zh/docs/deployment/deploy_manually/#%E7%AC%AC%E5%9B%9B%E6%AD%A5%E6%90%AD%E5%BB%BA%E9%9B%86%E7%BE%A4">https://docs.starrocks.io/zh/docs/deployment/deploy_manually/#%E7%AC%AC%E5%9B%9B%E6%AD%A5%E6%90%AD%E5%BB%BA%E9%9B%86%E7%BE%A4</a></li></ul>]]></content>
    
    
    <summary type="html">&lt;h1 id=&quot;背景&quot;&gt;&lt;a href=&quot;#背景&quot; class=&quot;headerlink&quot; title=&quot;背景&quot;&gt;&lt;/a&gt;背景&lt;/h1&gt;&lt;p&gt;最近这段时间在处理一个 &lt;code&gt;StarRocks&lt;/code&gt; 的关于物化视图优化的一个问题，在此之前其实我也没有接触过 &lt;code&gt;StarRocks&lt;/code&gt; 这类主要处理数据分析的数据库，就更别提在这上面做优化了。&lt;/p&gt;
&lt;p&gt;在解决问题之前我先花了一两天时间熟悉了一下 &lt;code&gt;StarRocks&lt;/code&gt; 的一些概念和使用方法，然后又花了一些时间搭建环境然后复现了该问题。&lt;/p&gt;
&lt;p&gt;之后便开始阅读源码，大概知道了相关代码的执行流程，但即便是反复阅读了多次代码也没有找到具体出现问题的地方。&lt;/p&gt;
&lt;p&gt;所以便考虑在本地 Debug 源码，最终调试半天之后知道了问题所以，也做了相关修改，给社区提交了 PR，目前还在推进过程中。&lt;/p&gt;</summary>
    
    
    
    <category term="StarRocks" scheme="http://crossoverjie.top/categories/StarRocks/"/>
    
    
    <category term="StarRocks" scheme="http://crossoverjie.top/tags/StarRocks/"/>
    
  </entry>
  
</feed>
